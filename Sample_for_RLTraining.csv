Id,Title,Body,DesignTagList
55972746,Queuing Emails in MVC Application,"I am part of a team building a proprietary Learning Management System for our organization.  When a user is enrolled into an online course, we are sending an email to the user with instructions on logging in to take their course.  When enrolling users en masse, obviously this is causing some performance issues.  I am looking into developing a framework for queuing emails and then sending them asynchronously.
Our platform is deployed via an Azure web app and Azure SQL database.  It is written in .NET MVC and we are sending emails via SMTP.
Does anyone have any recommendations on best practice or what would be the most effective way to accomplish this?  I've looked into Azure Service Bus, third-party open source solutions (such as Hangfire), and writing a standard console application that processes a database table of the emails to be sent.
",['mvc']
48710606,Ethernet device requesting data using RESTful API (JSON) and sending string to defined IP?,"Would appreciate any tips/help. 
I have a security system that uses a controller and a video monitoring software, both of which are connected to a LAN (direct ethernet from controller to a POE switch and monitoring software also on same network). 
The problem I have is that the security controller can't push strings to an IP address, which is what is required with the video monitoring software. 
I need to create a separate device that requests data from the security controller's IP and then takes what the IP address returns (a JSON object) and converts it into a string to send to the video monitoring software's IP address.
Example of the device I need to create
The device needs to request data from controller 192.168.1.9 address
<URL>
This will return a JSON object
{
description Sensor 1,
type NO,
alarm false
}
(If the alarm is triggered, alarm will be true.)
Then I need to take that JSON object, and convert it into a string (.stringify?)
Then I have to take that string and send it to my video monitoring software's address 
‚Äú<URL>
This seems uniquely complicated and simple at the same time and I apologize if I left out any information required to solve my problem. Basically, I am wondering if there is a device that I can connect to my network (hard-wired ethernet) that requests data from the security controller and then converts the data (JSON) to a string, and sending it to a different IP (the monitoring service))
",['rest']
17433046,Integration Test of REST APIs with Code Coverage,"We have built a REST API that exposes bunch of business services - a business service may invoke other platform/utility services to perform database read and writes, to perform service authorization etc.
We have deployed these services as WAR files in Tomcat.
We want to test this whole setup using a integration test suite which we would like to also treat as regression test suite.
What would be a good approach to perform integration testing on this and any tools that can speed up the development of suite?  Here are few requirements we think we need to address

Ability to define integration test cases which exercise business scenarios.
Set up the DB with test data before suite is run.
Invoke the REST API that is running on a remote server (Tomcat)
Validate the DB post test execution for verifying expected output
Have code coverage report of REST API so that we know how confident we should be in the scenarios covered by the suite. 

",['rest']
12331693,How to pass permission/authorization data to client side Javascript?,"I have a javascript web application almost totally rendered client side. 
The data is exchanged between client and server using models through a REST interface, then rendered using client side templates.
I have now the need to conditionally render some parts of the UI (or execute some operations) based on the user role/permission (authorization is server side model based ACL).
What is the best way to communicate permission data from server to client, taking into account that

The models exchanged may have other embedded models with their
specific permission
I need to know also READ and CREATE permissions on different models (so the model object is  not yet available client side)
Should minimize REST calls and DB calls

",['rest']
46171533,Calling Micro service inside a micro service,"Microsoft - Micro service architecture
Could it be reliable to call multiple micro services from a single micro service?
If I have developed 2 different micro services of customers and orders with their own database (i.e. customer db and order db), and if I would like to get combined data of customers and orders, what would be the best option to do that?
We want simply call one microservice which will call 2 separate microservices of customers and orders and combined their data and return a response of our choice. Is this usage is true?
In another way, we will call 2 separate micro services from our application side and combined data there.
I would like to get an option with the best performance, reliable and standard approach to do this process.
Can anyone tell me what would be options ?
and one more thing performance would be better in both side like in micro service response and in application side as well,
If other options are available then also please specify.
",['microservices']
24226529,Set token client side with Rest API in Symfony2,"I made a Rest API with symfony2 on one server (S1). 
I made an application with symfony2 on one server (S2).
S1 
Works well. It gives json response of user's informations, depends of url given.
S2 
Works well. Ask url with curl. Use wsse in the http header for retrieve important user's informations.
I want log in my users (from S2) using S1 database.
But when i am in S2, after the json response with user's informations, i don't know what i need to do and how do it...
Application side 
- Symfony2
API side 
- Symfony2
- FOSUserBundle
- FOSRestBundle
- JMS
It's the first time i try to make an Rest API, so maybe i don't understand well how it works.
Thank's in advance.
EDIT  For more details.

1  User 1 use a log in form and send it.
2  S2 Create a http header with x-wsse parameter (Nonce / Timestamp / Username / Password...)
3  S2 send this header to S1 with curl
4  S1 retrieve datas and if the header have good informations, send back the user's informations (in json) or make some actions
5  S2 retrieve jsons informations of the user from S1.
6  I can display the page like i want to the User 1

Now my problem is that i need to do the same thing for a new page, but i don't want ask my user for a password and a username a second time because for him, he is log in.
Hope it's more clear.
EDIT 2  My problem resume in one sentence.
In Symfony2, with wsse authentication, how can i get a user's token and send it to client side after authentication on the API.
p
",['rest']
4244437,Modifying a class to encapsulate instead of inherit,"The codebase I've been handed to work with features a databse class that inherits from MDB2. This forms the basis for the MVC framework in use (a custom built affair) and the models in turn inherit from db.
As I'm sure some of you have noticed, this leads to a rather big problem. Every time you instantiate a model, the result is a new database connection being created. This is obviously quite wasteful. It also means that I'm unable to use transactions as intended, because if a transaction starts in one instance of a model, its effects are invisible to the other instances until a commit occurs.
My plan is to change the db class to encapsulate MDB2 instead of inheriting from it, and then have it maintain a single instance of MDB2 via its singleton functionality.  
However, MDB2 is a big library with a lot of methods, and a lot of stuff higher up in the code base depends on being able to access MDB2 methods.  
Is there a way to encapsulate the MDB2 class and pass calls to it without modifying the higher layers, and without having to write a wrapper method for every method in MDB2?  
",['singleton']
15302901,Authentication with CAS for rest service call,"In our current setup we have about a dozen web applications that deploy to a single Tomcat server. One of these applications is CAS which is used for all authorization.
This works pretty well and in our jRuby web application we use the rubycas-client gem, point to CAS and we're done.
Now we have a requirements where, in a Java component, we need to be able to call out to another web application via a rest service that resides on the same server. My first thought was to use CAS proxy tickets but the web application we have to hit currently doesn't have this enabled and, due to the nature of the environment, this cannot be changed.
So as far as I can tell we're left trying to impersonate the user by using an iframe in our web application that points to the other one (we're all on the same domain and server) and scrape its sessionid for impersonation and pass it down to the Java layer. But I really, really don't want to do this.
Am I missing anything? Is there any better ways of doing this? Is there a way to get the sessionid without an iframe maybe?
Thanks!
",['rest']
9774067,Performance of a REST service proxy vs WCF SOAP proxy,"I've been getting performance results that I cannot explain, when comparing a client that consumes a REST service and a SOAP service. What I did is create a service proxy as follows
REST
WebHttpBinding webBinding = new WebHttpBinding();
webBinding.AllowCookies = true;
webBinding.MaxReceivedMessageSize = int.MaxValue;

CustomBinding custom = new CustomBinding(webBinding);

WebMessageEncodingBindingElement webMEBE = custom.Elements.Find();

webMEBE.ContentTypeMapper = new MyMapper();
webMEBE.ReaderQuotas.MaxArrayLength = int.MaxValue;

var abstract-abstract-factory = new WebChannelabstract-abstract-factory(custom, new Uri(<URL>
var proxy = abstract-abstract-factory.CreateChannel();

SOAP
endPointAddr = net.tcp// + textBox2.Text +
8909/MyService;
tcpBinding = new NetTcpBinding();
tcpBinding.MaxReceivedMessageSize = int.MaxValue;
tcpBinding.ReaderQuotas.MaxArrayLength = int.MaxValue;
tcpBinding.TransactionFlow = false;
tcpBinding.Security.Transport.ProtectionLevel =
    System.Net.Security.ProtectionLevel.EncryptAndSign;
tcpBinding.Security.Transport.ClientCredentialType =
    TcpClientCredentialType.Windows;
tcpBinding.Security.Mode = SecurityMode.None;

endpointAddress =
    new EndpointAddress(endPointAddr);

IService1 proxy =
    Channelabstract-abstract-factory.CreateChannel(tcpBinding, endpointAddress);

Both IService1 and ITest have one method that I use, GetRequest(), which returns an ~300Kb object. IService1.GetRequest() is an OperationContract, ITest.GetRequest() is a WebGet.
Once I open the channels in both cases I ran a tight loop of proxy.GetRequest(), to figure out how many Requests / s each can handle. The results were that if the test was on a local machine SOAP outperformed REST at 51, and over a network SOAP still outperformed REST by about 50%.
I do not understand why there is such a big difference.
",['rest']
30126720,RESTful way to upload file along with some data in django,"I am creating a webservice with django using django rest framework. 
Users are able to upload some images and videos. Uploading media is a two step action, first user uploads the file and receives an ID then in a separate request uses that ID to refer to the media (for example (s)he can use it as profile picture or use it in a chat message). 
I need to know who is uploading the media for both HMAC authentication middleware and setting owner of media in database. All other requests are in JSON format and include a username field that it used by HMAC middleware to retrieve the secret shared key.
It first came to my mind that media upload api may look like this
{
  usernamemjafar,
  datetime2015-05-08 1905,
  media_typephoto,
  media_data /* base64 encoded image file */
}

But i thought that base64 encoding may have significant overhead for larger files like videos; or there may be some restrictions on size of data that can be parsed in json or be created in user side. (This webservice is supposed to communicate with a Android/iOS app, they have limited memory)! Is this a good solution? Are my concerns real problems or i shouldn't worry? Better solutions?
",['rest']
10213307,How to save data into DataTable in MVC3?,"I have mvc3 application in this i have used two partial views 1.controls 2.webgrid
inside controls i'm populating dropdownlists from actual database tables. using EF
On index.cshtml i have one form in which need to select values from these dropdown lists and when press insert button these values should have to go to Temp DataTable and also show it in webgrid...I'm newbie to MVC3 and dont know how to do this.
Controls.cshtml
@model Mapping.Models.SecurityIdentifierMappingViewModel
@using (Html.BeginForm())
{
    @Html.ValidationSummary(true)
    
        Mapping
        
            @Html.Label(Pricing SecurityID)
        
        
            @Html.HiddenFor(model => model.MappingControls.Id)
            @Html.DropDownListFor(model => model.MappingControls.PricingSecurityID,
         new SelectList(Model.PricingSecurities, Value, Text),
         Select SecurityID
            )
            @Html.ValidationMessageFor(model => model.MappingControls.PricingSecurityID)
        
        
            @Html.Label(CUSIP ID)
        
        
            @Html.DropDownListFor(model => model.MappingControls.CUSIP,
         new SelectList(Model.CUSIPs, Value, Text),
            Select CUSIP
            )
            @Html.ValidationMessageFor(model => model.MappingControls.CUSIP)
        

        
            @Html.Label(Calculation)
        
        
            @Html.TextBoxFor(model => model.MappingControls.Calculation)
            @Html.ValidationMessageFor(model => model.MappingControls.Calculation)
        
        
            

        
    
}

HomeController.cs
public class HomeController  Controller
    {
        //
        // GET /Home/

        mydataEntities dbContext = new mydataEntities();
        DataRepository objRepository = new DataRepository();

        //GET

        public ActionResult Index(string userAction , int uid = 0)
        {
            var mappingobj = new SecurityIdentifierMappingViewModel();
            mappingobj.MappingWebGridList = dbContext.SecurityIdentifierMappings.ToList();

                mappingobj.MappingControls = new SecurityIdentifierMapping();
                mappingobj.MappingControls.PricingSecurityID = 0;
                mappingobj.MappingControls.CUSIP = string.Empty;

            mappingobj.PricingSecurities = objRepository.GetPricingSecurityID();
            mappingobj.CUSIPs = objRepository.GetCUSIP();

            return View(mappingobj);
        }


        //POST

        [HttpPost]
        public ActionResult Index(SecurityIdentifierMappingViewModel objModel)
        {


            if (objModel.MappingControls.Id > 0)
            {
                if (ModelState.IsValid)
                {
                    dbContext.Entry(objModel.MappingControls).State = EntityState.Modified;
                    try
                    {
                        dbContext.SaveChanges();
                        //objModel = new SecurityIdentifierMappingViewModel();
                        //return RedirectToAction(Index, Home);
                    }
                    catch (System.Data.Entity.Validation.DbEntityValidationException ex)
                    {
                        throw;
                    }
                }

            }

            //insert code
            else
            {
                if (ModelState.IsValid)
                {
                    dbContext.SecurityIdentifierMappings.Add(objModel.MappingControls);
                    try
                    {
                        dbContext.SaveChanges();
                    }
                    catch (System.Data.Entity.Validation.DbEntityValidationException ex)
                    {
                        throw;
                    }
                }

            }

            return RedirectToAction(Index);
        }
    }

public class SecurityIdentifierMappingViewModel
{
    public IEnumerable MappingWebGridList { get; set; }
    public SecurityIdentifierMapping MappingControls { get; set; }

    public List PricingSecurities { get; set; }
    public List CUSIPs { get; set; }
}

Currently using SecurityIdentifierMapping as a 3rd table from database in which inserting my form data ... but need to insert it into DataTable 
",['mvc']
39922562,CakePHP 3 Rest API,"I'm implementing an API using CakePHP3 with a MySQL database.
Everything works fine. The endpoints are a secured with a Basic Authentication.
Now I have noticed that the performance is dreadful. I started some speed tests with loader.io and noticed that the response times are around 400ms.
I don't know why, but at one point i deactivated the AuthComponent of CakePHP and suddenly I only had a response time of 120ms.
So I started digging around. I then implemented my own BasicAuthentication by just reading the header and comparing the user amp; password with my users table in the database. I still have ~120ms response time. Is the CakePHP3 AuthComponent just bloated up? I also noticed while having the AuthComponent activated that my php-fpm uses a large amount of CPU. Without The AuthComponent it's practicly nothing. 
I implemented the BasicAuth exactly as described in the CakePHP Documentation. I just don't know what is going on. I would prefer to use the actual CakePHP methods than implementing my own check. Has anybody else ever had this issue? I just don't understand what is going on. 
",['rest']
8357464,Authentication in an n-layer Web solution (Web + REST services),"Background
I've a set of WCF REST services and an ASP.NET client application.
Everything about business, data, process and validation occurs in the services' infrastructure.
ASP.NET client application is a consumer of these WCF REST services.
In the near future, these WCF REST services will be consumed by mobile applications (Android, iOS and Windows Phone).
Problem
Optimal way of implementing authentication.
Possible approaches

Token authentication. First successful login generates an authentication token, which is transmitted over the wire back to the client. Next requests will send the authentication token stored in a cookie, because service layer maintains an authentication token store. Tokens will expire in an arbitrary time.
Session-state authentication store. First successful login marks a session in some session state store as an authenticated session. Since Web client stores its session identifier in a cookie, next requests will transport it and service layer checks if session for given identifier is authenticated. Sessions will expire in an arbitrary time.

Question
In my case, I would go for first option token authentication.
Anyway, I'm worried about security issues, because if someone steals token or session identifier, this may be able to supplant owner's identity.
Summary what would be your choice?. I'll appreciate that you talk about security concerns.
Note if you've another approach, you can talk about it, I'm open to other possible solutions.
Thank you.
",['rest']
56138840,Is it OK to specify a schema in `table_name_prefix`?,"TL;DR Is it OK to specify a schema in table_name_prefix?
We have a large Rails application that is not quite a traditional multi-tenant app. We have a hundred clients, all supported by one app, and that number will never grow more than 1-2 per year. Currently, every client has their own Postgresql database.
We are addressing some infrastructure concerns of having so many distinct databases...most urgently, a high number of simultaneous database connections when processing many clients' data at the same time.
The app is not visible, even to clients, so a lot of traditional multi-tenant web site philosophies don't apply here neatly.

Each tenant has a distinct Postgres database, managed in
database.yml.  
Each database has a schema, named for the tenant. 
We have a model specific to each tenant with notably different code. 
Each model uses establish_connection to select a different database and schema.
Each model uses a distinct table_name_prefix with the client's unique name.

The tables vary extensively for each tenant. There is no hope or desire to normalize the clients together. Clients are not provisioned dynamically -- it is always a new code release with migrations.
We intend to move each of the client schemas into one database, so fewer distinct connection pools are required. The unique names we currently have at the database, schema, and table names mean there is no possibility of name collisions. 
We've looked at the Apartment gem, and decided it is not a good fit for what we're doing. 
We could add all hundred schemas to schema_search_path, so all clients could share the same connection pool and still find their schema. We believe this would reduce our db connection count one-hundred-fold. But we're a bit uneasy about that. I've found no discussions of how many are too many. Perhaps that would work, and perhaps there would not have a performance penalty finding tables.
We've found a very simple solution that seems promising, by adding the schema in the table_name_prefix.  We're already setting this like
def self.table_name_prefix
  'client99_'
end

Through experimenting and looking within Rails 4 (our current version) and Rails 5 source code, this works to specify the schema ('tenant_99') as well as the traditional table prefix ('client99') 
def self.table_name_prefix
  'tenant_99.client99_'
end

Before that change, queries looked like this
SELECT COUNT(*) FROM 'client99_products'

After, they include the schema, as desired
SELECT COUNT(*) FROM 'tenant_99.client99_products'

This seems to answer our needs, with no downsides. I've searched the Interwebs for people encouraging or discouraging this practice, and found no mention of it either way. 
So through all this, here are the questions I haven't found definitive answers for

Is there a concern of having too many schemas listed in schema_search_path?
Is putting a schema name in table_name_prefix okay? 

",['activerecord']
13555242,Safe polymorphism practice?,"I am abit unsure what to title this question as, so other people might have use of it, but I have this simple example of polymorphism from my teacher, which I attempted to modify abit.
But I am unsure whether my modification is safe or not.
public class AppSystem {
   ...
   private DataPersistenceInterface DataDAO;
   private DataController DataController;
   ...

   public void createConnection(String username, String password) 
                                throws ClassNotFoundException, SQLException {

      if(username.isEmpty() || password.isEmpty()) {
           DataDAO = new DataDAO();
           DataController = new DataController(DataDAO);
         } else {
           DataDAO = new DataDAO(url, username, password, driver);
           DataController = new DataController(DataDAO);
         }
      }

   public void closeConnection() {
        DataDAO.closeConnection();
   }

We have a controller and an DAO. The DAO implements an interface called DataPersistenceInterface, which hosts a few methods needed to do some communication with the database. Since the datacontroller handles all the logic, and we don't want it to know about anything else, we pass it a reference of the DAO in the type of the interface.
This is what my teacher did. However, the below method closeConnection would not work because of this, since the reference to DataDAO does not point to any closeConnection method in the DAO class...
[closeConnection method does not work in the above code, obviously]
Now, my idea was to just change...
   private DataPersistenceInterface DataDAO;

to
   private DataDAO DataDAO;

Since the datacontroller takes an argument of DataPersistenceInterface in it's constructor, it doesn't get to know about anything else from the DAO object. And now I would be able to call closeConnection on the DAO.
But I am not sure if this is safe to do? Something just tells me it isn't.
Thank you for your time.
",['mvc']
8148702,SOA and shared databases,"I don't understand SOA (Service-oriented Architecture) and databases. While I'm attracted by the SOA concept (encapsulating reusable business logic into services) I can't figure out how it's supposed to work if data tables encapsulated in a service are required by other services/systems---or is SOA suitable at all in this scenario?
To be more concrete, suppose I have two services

CustomerService contains my Customers database table and associated business logic. 
OrderService contains my Orders table and logic. 

Now what if I need to JOIN the Customers and Orders tables with an SQL statement? If the tables contain millions of entries, unacceptable performance would result if I have to send the data over the network using SOAP/XML. And how to perform the JOIN?
Doing a little research, I have found some proposed solutions

Use replication to make a local copy of the required data where needed. But then there's no encapsulation and then what's the point of using SOA? This is discussed on StackOverflow but there's no clear consensus.
Set up a Master Data Service which encapsulates all database data. I guess it would get monster sized (with essentially one API call for each stored procedure) and require updates all the time. To me this seems related to the enterprise data bus concept.

If you have any input on this, please let me know.

Edit A year has passed, and my interest in SOA has diminished, as has the concept's popularity in general. Nowadays, people seem to want to focus on RESTful services instead.
",['soa']
41039280,RESTful and J2EE,"I have developed a web application with Java EE, which connects to a DB. The app is deployed on Tomcat 8. The app is divided in three layers db layer, business layer, and presentation layer.
Now I need to develop a RESTful API that will use the business layer and will provide most of the functions that the presentation layer provides. Clients will have two options to choose from open a browser, connect to the APP and use it or consume the RESTful web services from their own software.
My question is should I deploy the RESTful API on the same server where the APP is deployed or separately? What are your suggestions?
And, what kind of authentication would you suggest for the REST web services?
Thanks!
",['rest']
20172357,How can I make this pub/sub code more readable?,"I am investigating the pub/sub pattern because I am reading a book that highly advocates event driven architecture, for the sake of loose coupling.  But I feel that the loose coupling is only achieved by sacrificing readability/transparency.
I'm having trouble understanding how to write easily-understood pub/sub code.  The way I currently write my code results in a lot of one-to-one channels, and I feel like doing so is a bad practice.
I'm using require.js AMD modules, which means that I have many smaller-sized files, so I feel like it would be very difficult for someone to follow the flow of my publishes.
In my example code below, there are three different modules

The UI / Controller module, handling user clicks
A translator module
A data storage module

The gist is that a user submits text, it gets translated to english, then stored into a database.  This flow is split into three modules in their own file.
// Main Controller Module
define(['pubSub'] function(pubSub) {

    submitButton.onclick(function() {
        var userText = textArea.val();
        pubSub.publish(userSubmittedText, userText);
    });

});

// Translator module
define(['pubSub'] function(pubSub) {

    function toEnglish(text) {
        // Do translation
        pubSub.publish(translatedText, translatedText);
    };

    pubSub.subscribe(userSubmittedText, toEnglish);

});


// Database module
define(['pubSub'] function(pubSub) {

    function store(text) {
        // Store to database
    };

    pubSub.subscribe(translatedText, store);

});

For a reader to see the complete flow, he has to switch between the three modules.  But how you would make clear where the reader should look, after seeing the first pubSub.publish(userSubmittedText, userText);?
I feel like publishes are like a cliff hanger, where the reader wants to know what is triggered next, but he has to go and find the modules with subscribed functions.
I could comment EVERY publish, explaining what modules contain the functions that are listening, but that seems impractical.  And I don't think that is what other people are doing.
Furthermore, the above code uses one-to-one channels, which I think is bad style, but I'm not sure.  Only the Translator module's toEnglish() function will ever subscribe to the pubSub channel userSubmittedText, yet I have to create the new channel for what is basically a single function call.  While this way my Controller module doesn't have to have Translator as a dependency, it just doesn't feel like true decoupling.
This lack of function flow transparency is concerning to me, as I have no idea how someone reading such source code would know how to follow along.  Clearly I must be missing something important.  Maybe I'm not using a helpful convention, or maybe my publish event names are not descriptive enough?
Is the loose coupling of pub/sub only achieved by sacrificing of flow transparency?
",['publish-subscribe']
44696108,Calling a secured (authentication required) REST from django,"I need to call a REST service from django where authentication (username + password) is required . I can get the password from request.user.password but it is not there in clean-text format but 
pbkdf2_sha256$36000$rOpm97qpHsy4$NFKCCfMmve1Z6c1U/grizJ6TyQck3bE/Fe+Gy3Gi+c8=
(which is good from security point of view)
However as far as I know a secured REST service needs the clean-text password to perform the authentication so I cannot call it. I wouldn't be a big fan of storing the password when the user logs in. 
How can a secured REST service be called from Django?
////////////////////////////////////////////////////// UPDATE //////////////////////////////////////////////////////    
I have a Django web application where the users can log in to (the REST has to be called from here).
Also I have a completely separate Spring Boot application that provides the REST interface. At the moment it is not secured but I want to implement authentication here. 
",['rest']
36721212,Spring Boot Custom Authentication Provider with Java Configuration not working,"I am trying to setup a REST based web application, where the frontend is using Reactjs and the backend is using Spring Boot. I am also trying to setup a custom authentication provider, and this is where my problems start. When trying to test the login API call, the CustomAuthenticationProvider is never called, and instead the default DaoAuthenticationProvider is used. This causes the login to report Bad credentials.
I have upload a small sample application to github spring-boot-auth-demo
To test the login API I use the following curl
curl -H Content-Type application/json -X POST -d '{usernameadmin,passwordadmin}' <URL>

The CustomAuthenticationProvider does a simple username/password check and returns an UsernamePasswordAuthenicationToken object.
package no.bluebit.demo;

import org.slf4j.Logger;
import org.slf4j.Loggerabstract-abstract-factory;
import org.springframework.security.authentication.AuthenticationProvider;
import org.springframework.security.authentication.UsernamePasswordAuthenticationToken;
import org.springframework.security.core.Authentication;
import org.springframework.security.core.AuthenticationException;
import org.springframework.security.core.GrantedAuthority;
import org.springframework.security.core.authority.SimpleGrantedAuthority;
import org.springframework.stereotype.Component;

import java.util.ArrayList;
import java.util.List;

@Component
public class CustomAuthenticationProvider implements AuthenticationProvider {

private static final Logger logger =     Loggerabstract-abstract-factory.getLogger(CustomAuthenticationProvider.class);

public CustomAuthenticationProvider() {
    logger.info(*** CustomAuthenticationProvider created);
}

@Override
public Authentication authenticate(Authentication authentication) throws AuthenticationException {

    if(authentication.getName().equals(admin)  amp;amp; authentication.getCredentials().equals(admin)) {
        List grantedAuths = new ArrayList<>();
        grantedAuths.add(new SimpleGrantedAuthority(ROLE_USER));
        grantedAuths.add(new SimpleGrantedAuthority(ROLE_ADMIN));
        return new UsernamePasswordAuthenticationToken(authentication.getName(), authentication.getCredentials(), grantedAuths);
    } else {
        return null;
    }

}

@Override
public boolean supports(Class> authentication) {
    return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication);
}

}

The CustomAuthenticationProvider is wired up using the SecurityConfiguration class. When stepping through the code, I can see that the CustomAuthenicationProvider is not in the list of providers used to authenticate the incoming request.
package no.bluebit.demo;

import org.springframework.beans.abstract-abstract-factory.annotation.Autowired;
import org.springframework.context.annotation.Configuration;
import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;
import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;

@Configuration
@EnableWebSecurity
@EnableGlobalMethodSecurity(prePostEnabled = true, securedEnabled = true)
public class SecurityConfiguration extends WebSecurityConfigurerAdapter {
    @Autowired
    private CustomAuthenticationProvider customAuthenticationProvider;

    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        auth
            .authenticationProvider(this.customAuthenticationProvider);
    }

    @Override
    protected void configure(HttpSecurity <URL> throws Exception {
        http
            .authorizeRequests()
                .antMatchers(/api/users/login).permitAll()    // Permit access for all to login REST service
                .antMatchers(/).permitAll()                   // Neccessary to permit access to default document
            .anyRequest().authenticated().and()                 // All other requests require authentication
            .<URL>
            .logout().and()
            .csrf().disable();
    }
}

Why is this not working?
",['rest']
27737290,Finding latest TeamCity Backup via REST API,"I found plenty of information and example about triggering TeamCity 8.1.2 backups via the REST API.
But leaving the backup files on the same server is pretty useless for disaster recovery.
So I'm looking for a way to copy over the generated backup file to another location.
My question is about finding the name of the latest available backup file via the REST API - 
The Web GUI includes this information under Last Backup Report under the Backup page of the Server Administration.
I've dug through <URL> and the /<URL> on my server. I didn't find any mention of a way to get this info through the REST API.
I also managed to trigger a backup with a hope that perhaps the response gives this information, but it's not there - the response body is empty and the headers don't include this info.
Right now I intend to fetch the HTML page and extract this information from there, but this feels very hackish and fragile (the structure of the web page could change any time).
Is there a recommended way to get this information automatically?
Thanks.
",['rest']
10105093,Service Oriented Architecture suggestions,"For personal and university research reasons I am thinking of building a simple CRM using a service oriented architecture. Its meaning is just to explain the architecture itself, not commercial use.
I was thinking of implementing a CRM that offers a simple analytics service and customer care (user storing, personal comments, and few other things).
The architecture that I'm designing defines
 - WebGUI (a client of the other services)
 - AnalyticsService (a service that receives data, analyzes and collect it)
 - CustomerCareService (a service that uses RESTful APIs to apply CRUD operations).
Each service has it own database, being completely independent from others. They expose a public interface. The interface of course must provide some sort of authentication, to deny unautorized requests.
The advantages I'd like to explain in this kind of architecture is the possibility to have all things indepentent and the ability to combine them to offer new services (for example if there was an OrderService to handle orders it would be easy to combine it with Customer using the public APIs). The big advantage to me is that it'd be easy enough to build other clients that use these services.
I don't know what is some good Authentication method, that could be easy to implement, I'm also not sure about how to make this APIs (use XML or plain REST APIs with GET/POST data). I've worked with Amazon, PayPal and other company APIs, they seem to use REST services (paypal uses an ugly _cmd GET parameter while Amazon uses better URI) to know what to do, but reading something about SOAs it appears that people also use XML. Of course I also need to take into account that the web interface must be able to recognize the logged in user, get the permissions (token or whatever else) and use it with services to show information.
So I'm not sure SOA is the kind of architecture I'm really building up... is it SaaS instead of SOA?
I think it would be better to use RESTful applications, with JSON or something like that to implement it (I'm not a big fan of XML, I find it to be too verbose).
For clarity I'm listing here my questions

Is this kind of architecture called SOA or SaaS (or both)?
What is a good implementation for what I want to obtain? (please explain it as more detailed as possible)
What sort of authentication is more suitable for a client (user token vs OAuth or similiar)
Do you have some suggestion for this kind of project?

I've about 3 months to do it, so I cannot do something real complex (beside the fact that it would not be realistic for a single programmer).
I know Python (WSGI frameworks), Ruby on Rails, C/C++ and other languages (.net excluded) and I'd like to develop it under a Linux environment (MySQL or Postgres, or even a NoSQL if you have any suggestion for the right choice), I could also combine several languages being these services independent programs.
What I'd like here is to have some good point of view and some good suggestion.
Thanks!
","['rest', 'soa']"
33883088,Castle Windsor resolve ienumerable and name,"I'm new to Castle Windsor (actually to DI) and trying to solve a scenario using windsor and i'm kind of stuck. To give an idea, there are 2 different remote sources from where I need to get some order info for a given customer no on the first attempt which is bit time consuming. The order info will never change in the future hence i would like to store that data in my local database for any subsequent use(s) which will increase the performance of my application. 
It seems like the decorator pattern is a good candidate for this and below is my initial attempt. 
public interface IOrderRepository
{
    IEnumerable Get(string customerNo);
    void Save(string customerNo, IEnumerable orders);
}

public class RealTimeRepo1  IOrderRepository
{
     public IEnumerable Get(string customerNo)
     {
       /// Fetch the data from remote source 1
     }
     public void Save(string customerNo, IEnumerable orders)
     {
         /// You cannot update the order info in remote source
         throw new NotImplementedException();
     }
 }

public class RealTimeRepo2  IOrderRepository
{
     public IEnumerable Get(string customerNo)
     {
       /// Fetch the data from remote source 2
     }
     public void Save(string customerNo, IEnumerable orders)
     {
         /// You cannot update the order info in remote source
         throw new NotImplementedException();
     }
 }

 public LocalOrderRepo  IOrderRepository
 {
     public IEnumerable Get(string customerNo)
     {
       /// Fetch the data from local data source

     }
     public void Save(string customerNo, IEnumerable orders)
     {
         /// Save the data on local data source
     }
 }

 public CacheOrderRepo  IOrderRepository
 {
     private readonly IEnumerable realTimeRepos;
     private readonly IOrderRepository localRepo;

     public CacheOrderRepo(IEnumerable realTime, IOrderRepository localRepo)
     {
           this.realTimeRepos = realTime;
           this.localRepo = localRepo;
     }

     public IEnumerable Get(string customerNo)
     {
         List orders = this.localRepo.Get(customerNo);
         if(orders == null) amp;amp; (!orders.Any()
         {
             foreach(var r in this.realTimeRepos)
             {
                List t = r.Get(customerNo);
                if(t.Any())
                {
                  orders.AddRange(t);
                }
             }
             if(orders.Any())
             {
                 this.localRepo.save(customerNo, orders);
             }
         }
         return orders;
     }
     public void Save(string customerNo, IEnumerable orders)
     {
         /// Save the data on local data source
     }
 }

I hope the above code snippet gives an idea. My struggle is how to register this using windsor.
//regsiter
this._container.Kernal.Resolver.AddSubResolver(new  
    CollectionResolver(this._container.Kenrnal));

this._container.Register(
    Component.For.ImplementedBy().LifeStyle.Transient,
    Component.For.ImplementedBy().LifeStyle.Transient
 );

Using the collection subresolver i was able to register an ienumerable of RealTime repos 1 amp; 2. How i should register the local repo (i.e. my constructor parameter 2)?
Appreciate your help. I'm also open for suggestions with my understanding of the decorator pattern or castle windsor...
",['decorator']
43530030,Error 400 using REST APIs to IBM Watson IoT platform,"I'm attempting to transmit a json formatted message using the REST APIs from an embedded system to the IBM Watson IoT Platform. I've tested the REST APIs using another program (postman) and it works fine however an identical string transmitted from my embedded system returns an error 400. Is there so extra security certificate I need in my embedded system to make this work? Or is there something else I am missing?
Here's a link to the REST API for messaging <URL>
The following is the string output from my embedded system (via socket connection) where typeID, deviceID, eventName, and orgID are correctly entered and encode64(name token) is the correct authorization string of the concatenation of the name and token encoded in base64. 
POST /api/v0002/device/types/typeID/devices/deviceID/events/eventName HTTP/1.1
Host orgID.messaging.internetofthings.ibmcloud.com80
Content-Type application/json
Authorization Basic encode64(name token)

{random JSON formatted message}

The socket connection is made by first resolving the IP address of the following URI orgID.messaging.internetofthings.ibmcloud.com 
then employing standard socket connection function to the IP address and port 80.
While the IoT Platorm API make no mention of using port 80, I can transmit my JSON formatted message to my IoT Platform using port 80 through Postman. 
",['rest']
38464606,Rails - Issue with multiple remote database in production/staging,"I‚Äôm currently running a Rails app which uses 2 databases its own and one from another (not running anymore) app on a different server. The thing is locally everything goes just smooth, but on our staging server after a few requests the page load hangs forever and then returns PGConnectionBad error  could not connect to server Connection timed out Is the server running on host *** and accepting TCP/IP connections on port ***, which is the second database (running on a different server). I use the second (remote) database for devise authentication. I think it is something related to the connection pool related to the remote database not properly releasing after use, but I really have no clue at the moment.
Rails version 5.0.0
Postgres version 9.3
Passenger version 5.0.29

This is the error thrown
PGConnectionBad - could not connect to server Connection timed out Is the server running on host ********.cloudapp.net (********) and accepting TCP/IP connections on port ****?

As I said that happens after a while, so I really think it has to be something related to ActiveRecord connection pool or the connection with the remote database, which is by the way logging this
2016-07-19 164940 UTC LOG  could not receive data from client Connection reset by peer
2016-07-19 164940 UTC LOG  incomplete startup packet
2016-07-19 165005 UTC LOG  could not receive data from client Connection reset by peer
2016-07-19 165005 UTC LOG  incomplete startup packet

More of it, this is the status of the remote Postgres, retrieved by running SELECT * FROM pg_stat_activity;
 datid |       datname       | pid  | usesysid |   usename   |                        application_name                         |   client_addr   | client_hostname | client_port |         backend_start         |          xact_start           |          query_start          |         state_change          | waiting | state  |                                           query
-------+---------------------+------+----------+-------------+-----------------------------------------------------------------+-----------------+-----------------+-------------+-------------------------------+-------------------------------+-------------------------------+-------------------------------+---------+--------+-------------------------------------------------------------------------------------------
 16733 | ******************* | 7620 |    16584 | *********** | Passenger RubyApp /var/www/**********/current/public (staging) | *************** |                 |        1336 | 2016-07-19 165107.955763+00 |                               | 2016-07-19 165108.015955+00 | 2016-07-19 165108.016093+00 | f       | idle   | SELECT  users.* FROM users WHERE users.id = $1 ORDER BY users.id ASC LIMIT $2
 12035 | postgres            | 7673 |       10 | postgres    | psql                                                            |                 |                 |          -1 | 2016-07-19 165208.773491+00 | 2016-07-19 165211.052339+00 | 2016-07-19 165211.052339+00 | 2016-07-19 165211.052343+00 | f       | active | SELECT * FROM pg_stat_activity;
(2 rows)

As you can see, the first query, coming from my Rails app, remains in idle state, and even if it is one more clue pointing in the connection pool direction I really have no idea how to fix this. Any suggestion would be REALLY appreciated! Restarting Postgres server on the remote server make things work again, so I'm really pointing at Postgres or Rails not releasing connections.
This is the model (User) whose connections are creating trouble
class RemoteBaseModel < ActiveRecordBase
  self.abstract_class = true
  establish_connection other_db_env
end

class User < RemoteBaseModel
  # model logic
end

And this is database.yml
##### database.yml
default amp;default
  adapter postgresql
  encoding unicode
  pool 25

development
  << *default
  database db_development

staging
  << *default
  database db_staging
  username ********
  password ********

other_db_default amp;other_db_default
  adapter postgresql
  encoding unicode
  pool 25

fanta_users_development
  << *other_db_default
  database other_db_development

other_db_staging
  << *other_db_default
  host ********
  port 1972
  database other_db_staging
  username ********
  password ********
  protocol md5

",['activerecord']
37589737,Enable Basic Authentication Codeigniter rest API,"Hello i am having a problemm to understand how to enable basic authentication using CodeIgniter and using the <URL> The rest.php
|--------------------------------------------------------------------------
| REST Login
|--------------------------------------------------------------------------
|
| Set to specify the REST API requires to be logged in
|
| FALSE     No login required
| 'basic'   Unsecure login
| 'digest'  More secure login
| 'session' Check for a PHP session variable. See 'auth_source' to set the
|           authorization key
|
*/
$config['rest_auth'] = 'basic';

i enable the basic auth and below i have this
/*
|--------------------------------------------------------------------------
| REST Login Usernames
|--------------------------------------------------------------------------
|
| Array of usernames and passwords for login, if ldap is configured this is ignored
|
*/
$config['rest_valid_logins'] = ['admin' => '1234'];

if i use admin as username and 1234 as password the login is fine. My question is how can i register users to my database and also update the valid logins config? When the user registers i dont have to go to rest.php and add the record to $config['rest_valid_logins'] but it will be done automatically?
Any help will be appreciated!!!
",['rest']
14360122,A peer-to-peer and privacy-aware data mining/aggregation algorithm is it possible?,"Suppose I have a network of N nodes, each with a unique identity (e.g. public key) communicating with a central-server-less protocol (e.g. DHT, Kad). Each node stores a variable V. With reference to e-voting as an easy example, that variable could be the name of a candidate.
Now I want to execute an aggregation function on all V variables available in the network. With reference to e-voting example, I want to count votes.
My question is completely theoretical (I have to prove a statement, details at the end of the question), so please don't focus on the e-voting and all of its security aspects. Do I have to say it again? Don't answer me that a node may have any number identities by generating more keys, IPs can be traced back etc. because that's another matter.
Let's see the distributed aggregation only from the privacy point of view.
THE question
Is it possible, in a general case, for a node to compute a function of variables stored at other nodes without getting their value associated to the node's identity? Did researchers design such a privacy-aware distributed algorithm?
I'm only dealing with privacy aspects, not general security!
Current thoughts
My current answer is no, so I say that a central server, obtaining all Vs and processes them without storing, is necessary and there are more legal than technical means to assure that no individual node's data is either stored or retransmitted by the central server. I'm asking to prove that my previous statement is false )
In the e-voting example, I think it's impossible to count how many people voted for Alice and Bob without asking all the nodes, one by one Hey, who do you vote for?
Real case
I'm doing research in the Personal Data Store field. Suppose you store your call log in the PDS and somebody wants to find statistical values about the phone calls (i.e. mean duration, number of calls per day, variance, st-dev) without being revealed neither aggregated nor punctual data about an individual (that is, nobody must know neither whom do I call, nor my own mean call duration).
If a trusted broker exists, and everybody trusts it, that node can expose a double getMeanCallDuration() API that first invokes CallRecord[] getCalls() on every PDS in the network and then operates statistics on all rows. Without the central trusted broker, each PDS exposing double getMyMeanCallDuration() isn't statistically usable (the mean of the means shouldn't be the mean of all...) and most importantly reveals the identity of the single user.
",['p2p']
41308883,How to increase cpu usage and performance in MVC or IIS,"I have website and dedicated server for my website.
In my project there is 10^6 loop witch import record from xml file and finally save in database.
The for loop section is not fast as windows application version of this project.
the question is
Q1 is there any way to increase cpu usage for loop section of my project?
Q2 is there any way to allow highly cpu usage in IIS for my website?
Thank you
Code
foreach (var row in records)// about 150,000 record
{
    string cs = row.Field(tsb);
    try
    {
        int rowCount = row.Table.Columns.Count - 6;


        string rowUserName = row.Field(UserName).Trim();

        if (rowUserName != userName) 
        {
    task.taskStatus = (int)taskStatus.failed;
    task.details += Languages.Properties.Resources.task_eror_user_unique +  + cs; 
    TaskHelper.edit(task);
    return Json(new { success = false, message = Languages.Properties.Resources.task_eror_user_unique +  + cs }); 
        }


        long drh = Convert.ToInt32(row.Field(drh));

        var gm = db.gms.AsNoTracking().FirstOrDefault(g => g.number == drh amp;amp; g.id_gmState == 1);

        if (gm == null || gm.rowCount != rowCount)    
        {
    task.taskStatus = (int)taskStatus.failed;
    task.details += Languages.Properties.Resources.task_eror_gm_count +  + cs; 
    TaskHelper.edit(task);
    return Json(new { success = false, message = Languages.Properties.Resources.task_eror_gm_count +  + cs }); 
        }


        int ck = 0;
        int cj = 0;

        try
        {
    ck = Convert.ToInt32(row.Field(_txtcodnakol));
    cj = Convert.ToInt32(row.Field(_txtcodnajoz));
        }
        catch
        {
    task.taskStatus = (int)taskStatus.failed;
    task.details += Languages.Properties.Resources.task_erorr_code +  + cs; 
    TaskHelper.edit(task);
    return Json(new { success = false, message = Languages.Properties.Resources.task_erorr_code +  + cs });
        }


        if (db.Cards.AsNoTracking().Any(c => c.id_user == user.Id amp;amp; c.cs == cs amp;amp; c.id_gm == gm.id amp;amp; c.ck == ck amp;amp; c.cj == cj))
        {
    task.taskStatus = (int)taskStatus.failed;
    task.details += Languages.Properties.Resources.task_eror_card_unique +  + cs; 
    TaskHelper.edit(task);
    return Json(new { success = false, message = Languages.Properties.Resources.task_eror_card_unique +  + cs }); 
        }


        string value = ;
        string rowContent = gm.gmRow.gmRowTitles.FirstOrDefault()?.rowContent; 
        int countOption = Regex.Matches(rowContent, ch=).Count;


        var coefficientValue = gm.CoefficientValues.Any() ? gm.CoefficientValues.FirstOrDefault().value  1; 
        int realCost = 0;            

        for (int i = 1; i <= gm.rowCount; i++) // at least 15 rows
        {
    string option = row.Field(j + i);

    var distinctOption = option.Distinct().ToArray();

    if (string.IsNullOrEmpty(option) || option.Length != distinctOption.Length)
    {
        task.taskStatus = (int)taskStatus.failed;
        task.details += Languages.Properties.Resources.task_error_option_null +  + i +  + cs;
        TaskHelper.edit(task);
        return Json(new { success = false, message = Languages.Properties.Resources.task_error_option_null +  + i +  + cs });
    }

    for (int j = 0; j < distinctOption.Length; j++)// under 4 count loop
    {
        int item = Convert.ToInt32(distinctOption[j].ToString());
        if (item < 1 || item > countOption)
        {
            task.taskStatus = (int)taskStatus.failed;
            task.details += Languages.Properties.Resources.task_error_option_null +  + i +  + cs;
            TaskHelper.edit(task);
            return Json(new { success = false, message = Languages.Properties.Resources.task_error_option_null +  + i +  + cs });
        }
    }

    for (int j = 1; j <= countOption; j++) // under 4 count loop
    {
        if (option?.Contains(j + ) ?? false)
            value += 1,;
        else
            value += 0,;
    }

    if (realCost == 0 amp;amp; i == 1)
        realCost = 1;
    realCost *= (option.Length * coefficientValue);
        }

        long cost = Convert.ToInt32(row.Field(tmvs)); 


        if ((realCost != cost amp;amp; (realCost > gm.minCardValue)) || (realCost > gm.maxCardValue)) 
        {
    task.taskStatus = (int)taskStatus.failed;
    task.details += Languages.Properties.Resources.task_eror_card_cost_invalid +  + cs;
    TaskHelper.edit(task);
    return Json(new { success = false, message = Languages.Properties.Resources.task_eror_card_cost_invalid +  + cs }); 
        }

        if ((realCost != cost amp;amp; (realCost <= gm.minCardValue))) 
        {
    if (cost != gm.minCardValue)
    {
        task.taskStatus = (int)taskStatus.failed;
        task.details += Languages.Properties.Resources.task_eror_card_cost_invalid +  + cs;
        TaskHelper.edit(task);
        return Json(new { success = false, message = Languages.Properties.Resources.task_eror_card_cost_invalid +  + cs }); 
    }
        }


        Card card = new Card
        {
    id_gm = gm.id,
    id_user = user.Id,
    id_cardStates = 1,
    value = value,
    Cost = cost,
    cj = cj,
    ck = ck,
    cs = cs
        };
        db.Cards.Add(card);

        progress += perPercent;
        if ((int)progress > task.percentCompleted)
        {
    task.percentCompleted = (int)progress;
    TaskHelper.edit(task);
        }
    }
    catch (Exception ex)
    {
        task.taskStatus = (int)taskStatus.failed;
        task.details += ex.InnerException +  + cs;
        TaskHelper.edit(task);
        return Json(new { success = false, message = ex.InnerException +  + cs });
    }
}

",['mvc']
39686227,Handling database schema creation and migrations when launching multiple instances of a containerized microservice,"I want to deploy my microservices in docker containers. I want these microservices to be as stateless as possible, only persisting state to a database.
This means that there are these requirements

These services are deployed as docker containers and orchestrated using kubernetes.
Each service can be deployed and scaled to multiple instances.
Each instance of a service will be identical. This means that they must all have the same environment variables and configurations passed to it.
Each instances should not care or know about another instance.
The instances should be stateless and should not elect a leader or have a quorum.

That leads to my problem with handling schema creation and migrations

If I have a service that uses MySQL or Postgres as the data store, how do I create the tables/schemas on first launch? Should I just use CREATE IF NOT EXIST statements and let the instances fight it out during boot? I am not able to set an environment variable to ask for table/schema creation for just 1 of the instances.
How do I handle schema migrations with the above constraints? There are numerous actions like dropping/adding columns that cannot be encapsulated in a transaction.

",['microservices']
54020783,How do I type a decorated property which type is changed by the decorator?,"Here's some code that works perfectly in JS
import Component from '@ember/component';
import {task} from 'ember-concurrency';

class Foo extends Component {
  currentRecordId! string; // passed from template

  @task
  fetchRecord *(id) {
    return yield this.store.findRecord('foo', id);
  }

  async fetchCurrentRecord() {
    return this.fetchRecord.perform(this.currentRecordId);
  }
}

Ember Concurrency is an alternative to promises that allows cancelling and managing them similar to Observable from RxJS. Since JS promises don't allow cancelling, Ember Concurrency uses yield instead of async/await.
The task decorator used above converts a generator function into a TaskProperty instance that has a .perform() method.
Please note, that, though weird, this pattern has proven its handiness and reliability in non-typed JS apps.
But typing it presents a challenge.

Here are
export declare function task(generatorFn () => Iterator) Task TaskInstance>;

export declare function task(
  generatorFn (a A) => Iterator
) Task TaskInstance>;

export declare function task(
  generatorFn (a A) => Iterator>
) Task TaskInstance>;

export declare function task(
  generatorFn (a1 A1, a2 A2) => Iterator
) Task TaskInstance>;

// More variants of arguments skipped

export interface TaskInstance extends PromiseLike {
  readonly error? any;
  readonly hasStarted ComputedProperty;
  readonly isCanceled ComputedProperty;
  readonly isDropped ComputedProperty;
  readonly isError boolean;
  readonly isFinished ComputedProperty;
  readonly isRunning ComputedProperty;
  readonly isSuccessful boolean;
  readonly state ComputedProperty;
  readonly value? T;
  cancel() void;
  catch() RSVP.Promise;
  finally() RSVP.Promise;
  then(
    onfulfilled? ((value T) => TResult1 | RSVP.Promise) | undefined | null,
    onrejected? ((reason any) => TResult2 | PromiseLike) | undefined | null
  ) RSVP.Promise;
}

interface Task extends TaskProperty {
    readonly isIdle boolean;
    readonly isQueued boolean;
    readonly isRunning boolean;
    readonly last? TaskInstance;
    readonly lastCanceled? TaskInstance;
    readonly lastComplete? TaskInstance;
    readonly lastErrored? TaskInstance;
    readonly lastIncomplete? TaskInstance;
    readonly lastPerformed? TaskInstance;
    readonly lastRunning? TaskInstance;
    readonly lastSuccessful? TaskInstance;
    readonly performCount number;
    readonly state TaskState;
    perform(...args any[]) TaskInstance;
    cancelAll() void;
}

export interface TaskProperty extends ComputedProperty {
    cancelOn(eventNames string[]) this;
    debug() this;
    drop() this;
    enqueue() this;
    group(groupPath string) this;
    keepLatest() this;
    maxConcurrency(n number) this;
    on(eventNames string[]) this;
    restartable() this;
}

These types aren't official and can be customized.

I struggle with properly typing the topmost code sample.
The error I'm getting is

Property perform does not exist on type () => IterableIterator.

It is understandable, since fetchRecord is defined as a generator.
Moreover, TypeScript officially does not support decorators that change the type of decorated property.
So the question is how to work around the limitation and type such a decorator without reverting to @ts-ignore?
In addition to typing the fetchRecord property, I would like to properly type the arguments that I pass into this.fetchRecord.perform() and which are received by the generator.
Thank you. ^__^
",['decorator']
33348620,after(each) vs after(all) in Rails rspec,"In rails rspec, I am writing test cases that do this
after(each) do
    DatabaseCleaner.clean_with(truncation)
  end

I need the database to be cleaned after each test is run. But will this affect the performance of my tests and make them slower?
",['activerecord']
12661110,Apache can't send request to localhost8080 (to use Mule Esb Flow),"I'm trying to use a sample web application that use Ajax to send a request to a php REST service.
I need to use Mule ESB to do this, so i fix my ajax function to send request to ESB on localhost8080. But the browser said that i can't do this for security reason.
So, there are any way to use mule ESB with a web app (local appache server) locally ?
",['rest']
39340609,Safe to store complete user info in session with Sails.js?,"I'm building a Sails.js app that includes a user login. As the documentation instructs, when a user signs in, the session records her id in the session accordingly
req.session.userId = createdUser.id;

In most of the examples, each route performs a lookup on this ID, if it's present, and sends the authenticated user to the view if found. This strikes me as very inefficient. EVERY view needs to know if there's a signed-in user in order to display her name in the upper left corner. So, if I understand right, every view includes a trip to the database to look up the user, even if I reduce the amount of code by creating a policy that performs this lookup for every route.
What I would rather do is record the user's information in the session so that, once she is authenticated, that information is automatically present to every view
req.session.userId = createdUser.id;
createdUser.loggedIn = true;
req.session.user = createdUser;
// the createdUser object does NOT contain the encrypted password or other sensitive info

This then allows me to just check in the template for a signed-in user like so from the layout parent template (and any child template). (I'm using server-side views.)
{% if (session.user amp;amp; session.user.loggedIn) %}
Hi there, {{ session.user.username }}
{% else %}
Sign In (if you want)
{% endif %}

My question is whether this poses a security risk of any kind. It seems MUCH more efficient than looking up the User in every view, but perhaps there's a reason that documentation seems to advise this?
",['mvc']
34139090,Issue reading lists from Sharepoint listdata.svc from another REST service,"all.
I have created a REST ApiController that, among other things, attempts to call the  /_vti_bin/listdata.svc of a Sharepoint site to get the contents of one or more Sharepoint lists.
The ApiController's web.config uses Windows authentication with no impersonation. In the code, I am using System.Net.CredentialCache.DefaultNetworkCredentials for the DataContext.Credentials.
When I run the service locally using Visual Studio, the ApiController is able to call the listdata.svc without any issue and is able to retrieve the full contents of the list(s).
However, when I deploy the ApiController to an actual IIS server that is running under a system account, the call to listdata.svc doesn't retrieve any results. From what I can see in my ApiController's logging, there are no exception beings thrown. According to the logs, the list(s) just appear empty (0 items).
I have checked to make sure the IIS system account has proper access to the Sharepoint site.
Any ideas about why the difference in behavior?
",['rest']
21132728,Neo4j - Using Java plugins to REST api to improve performance?,"I am building an application that requires a lot of data constantly being extracted from a local MongoDB to be put into Neo4j. Seeing as I am also having many users access the Neo4j database, from both a Django webserver and other places, I decided on using the REST interface for Neo4j.
The problem I am having is that, even with batch insertion, the Neo4j server is active over 50% of the time with just trying the insert all the data from the mongoDB. As far as I can see there might be some waiting time because of the HTTP requests but I have been trying to tweak but have only gotten so far.
The question is, if I write a Java plugin (<URL> that can handle inserting the mongoDB extractions directly, will I then go around the REST API? Or will the java plugin commands just convert to regular REST API requests? Furthermore, will there be a performance boost by using the plugin?
The last question is how do I optimize the speed of the REST API (So far I am performing around 1500 read/write operations which includes many get_or_create_in_index operations)? Is there a sweet spot where the number of queries appended to one HTTP requests will keep Neo4j busy until the next HTTP request arrives?
Update
I am using Neo4j version 2.0 
The data that I am extracting consists of bluetooth observations, where the phone that is running the app i created scans all nearby phones. This single observation is then saved as a document in MongoDB and consists of the users id, the time of the scan and a list of the phones/users that he has seen in that scan.
In Neo4j I model all the users as nodes and I also model an observation between two users as a node so that it will look like this
(user1)-[observed]->(observation_node)-[observed]->(user2)
Furthermore I index all user nodes.
When moving the observation from mongoDB to Neo4j, I do the following for each document

Check in the index if the user doing the scan already has a node assigned, else create one
Then for each observed user in the scan A) Check in index if the observed user has a node else create one B) Create an observation node and relationships between the users and the observation node, if this doesn't already exist C) Make a relationship between the observation node and a timeline node (the timeline just consists of a tree of nodes so that I can quickly find observations at a certain time) 

As it can be seen I am doing quite a few lookups in the user index (3), some normal read (2-3) and potentially many writes for each observation.
Each bluetooth scan average around 5-30 observations and I batch 100 scans in a single HTTP request. This means that each request usually contains 5000-10000 updates.
",['rest']
8864240,How to update a remote ms access database?,"i need to create a webapp to show and allow editing for a set of data.
This data is contained in an Access Database file, used by another application (a desktop application).
I'm evaluating the best way to carry out this job.
Unfortunatly my purpose to migrate to another database solution (rdbms such as MySQL or Postgres) was rejected by the customer.
The issue here is how to keep data integrity and syncronized between the server and the desktop that executes the application that also uses this data.
All I need to do is, read data, store edited or new data, give to authorized users an interface to review this new inserted data -thus validating it-, and import this to the original access database.
I've found the following possible solutions (to update the desktop mdb copy), but each of them has pros and cons

remote access to the windows machine

exposes the machine to unauthorized access

use rsync to keep files syncronized (once a day)

if the mdb on the client has been edited with the desktop application there will be data loss
can be update only when all data has been validated
there won't be real syncronized data (until rsync will run)

client-server applications

can use secure layers to protect data against attackers
a 3rd application (on the desktop) is required
syncronization requires authorized users to use this 3rd application to import data (that will query the remote db and update the local mdb)


Do you know some other way that could help me to get this done?
I'm oriented on the client-server model, also if this would be more expensive, but it's the only way I see to make this work.
Do you see some other pros/cons of the purposed solution?
I didn't choose the PL to develop this, but I was thinking to use either PHP and/or Python.
The remote environment (for the server) can either be Windows or *nix (preferred).
Thanks.
",['client-server']
49216909,ActiveAdmin bcrypt users password on update or insert rails,"I am using ActiveAdmin as a admin panel, so I can create users through ActiveAdmin. 
The Issue I'm having is when updating or inserting a users password, I need the value I entered in the ActiveAdmin form to hash the password with bcrypt and then work with rails has_secure_password authentication 
Is there anyway I can get ActiveAdmin to include something like this?
BCryptPassword.create(params[password]) 
before saving to the database?
this is my users.rb
ActiveAdmin.register User do
permit_params email, password_digest, session_token, session_key, 
rank, profileColour

index do
selectable_column
id_column
column email
column password_digest
column session_token
column session_key
column rank
column profileColour
actions
 end

filter email
filter session_token
filter session_key
filter rank
filter profileColour

form do |f|
  f.inputs Admin Details do
  f.input email
  f.input password_digest
  f.input rank
  end
  f.actions
end

end
Any advice would be greatly appreciated
Thanks!
",['activerecord']
12060965,MVC Where should I put this data access logic?,"I've been trying to adhere to a strict interpretation of MVC in rebuilding a personal web application at home, but I'm having some issues.
The application is a financial tracking application. I'm stuck at the first page, which is just a list of the bank account transactions for the month. The transaction list is my Model. The Controller and View are easy enough to envision at this point.
However, I also have two buttons at the top of the page. They are arrows, one corresponding to the previous month, and the other corresponding to the next month's transaction list. I don't want these buttons enabled if there are no transactions for the previous/next month, so I need to talk to the database to figure out whether each button should actually link somewhere.
From most of what I've read, to the largest extent possible database access should be encapsulated in models, with little to no database access in Controllers and Views.
However, these buttons essentially need to ask the database, Are there any transactions for the next/previous months? The answer will determine whether or not their links are disabled, as well as where to send the user.
Strictly speaking, putting their logic into the Transaction List model does not seem appropriate, as whether or not transactions exist outside the requested range is beyond the concern of the Transaction List Model.
I guess I could also make another Model that would correspond to all Year-Month combinations where transactions exist. I could then pass this Model and the Transaction List on to the proper View.
Or should I deviate from the no-database-access-outside-the-model paradigm, and just throw some quick DB querying into the View (since the result is essentially a UI concern, making navigation easier)?
What do you guys think about this conceptual issue?
BTW, I am not using any framework. This is pet project designed to get me more familiar with the nuts and bolts of the MVC pattern.
",['mvc']
49612067,Have Yii2 ActiveRecord operate on memory instead of database,"I have an application doing calculations that uses Yii2 ActiveRecord to read and write to the database in various places. I need to rerun part of the calculation (for testing and integrity check purposes) without touching the database.
Is there a standard way to make ActiveRecord work on a data structure in memory? The data structure would consist of arrays with objects of the data models. I know this is a long shot, but the intention would be to avoid plan B which is having to locate all the places that interact with the database and refactor them so they can operate in dual mode (either memory structure or database).
$customer = new Customer();
$customer->name = 'ABC';
$customer->save();

In the above example, I would need a way to make save() add the new Customer to the memory data structure instead of the database.
",['activerecord']
11695109,Session-based Server Side Data Setting and Retrieval,"I have a theoretical question about how to approach a current project. It is a fairly simple matching quiz using JS + PHP. I am simply taking care of business logic on the server (answer checking, score updating) such as to roughly follow MVC conventions.
My current setup

HTML + JS page to allow the user to drag and drop answers onto questions. On a successful drop, the question + answer combo is sent to the following
A server-side PHP page to check the answer correctness based on an XML file. I return a few pieces of data in some XML client, such as true/false and number of attempts at a certain question. In addition, if the answer is correct, I increment a Session Variable on the server to keep track of the user's score.

My question revolves around best practices for setting the above mentioned session variable for tracking the score. I understand that a more persistent setup is most likely preferable, in case of computer shut-off, accidental browser closing, etc...but strictly based on this setup - 

Is this a secure method for storing a score for a final insertion into the database?
I eventually will have to pull the score down from the server at the end of the game (or even mid game, for that matter), as well. Should I create a simple 'getter' PHP page to pull the score down, and just access the session variable and send it to the client?
Currently, the user actually has access to the php server-side page becuase it resides in the same folder as the actual quiz. This is moooost likely a no-no - but what is the common practice for hiding this server-only file from the user's prying eyes (without having to use authentication)?

",['mvc']
3663900,PHP singleton class structure - Am I doing it right?,"I have a really big script.
It has a database class, a base class, a user authentication class, a resellers authentication class, paypal ipn class, a downloads class, and a plugins class
The Base class extends database class like this
    

class Base extends database
{
    var $userid;
    var $root;
    var $config

    function Base($username, $password, $host, $database)
    {
        // Init DB
        $this -> database($hostname, $database, $username, $password);
        $this -> config = $this -> fetch(...);
        // and the code goes on
    }
    function anyFunction()
    {
        $this -> Downloads -> dloadFunction();
    }
}
class users extends Base
{
    var $userData;

    function users()
    {
        // initialize user, check if he is logged in, if he has cookies, load the user vars in $this -> userData
    }
    function userFunction1()
    {
        $this -> anyFunction();
    }
}
class resellers extends Base
{
    var $resellerData;

    function resellers()
    {
        // initialize resellers, check if he is logged in, if he has cookies, load the user vars in $this -> resellerData
    }
}
class IPN extends Base
{

}
class Downloads extends Base
{
    function dloadFunction()
    {

    }
}
class Plugins extends Downloads
{

}
?>

And I call my code like this 
 user = $user;
    $reseller = new reseller();
    $Base -> reseller = $reseller;
    $downloads = new Downloads();
    $downloads -> Plugins = new Plugins();
    $Base -> Downloads = $downloads;

    $Base -> users -> updateEmail();
    // and the code goes on..
?>

I think the structure is really bad.
Thats why I want to implement singleton method.
how can I achieve this ?
Please help.
",['singleton']
27314907,Is it good idea to use encrypted database ID instead of UUID in the web service URL?,"Good day, I'v implemented a REST service. In the URL of resource end-point I use ID's which are primary keys of tables of the database. For example <URL> I'v learned using the database ID in the URL is a bad practice and I should use UUID instead. On the other hand I'v learned that using UUIDs in indexes is a performance issue if there's many records in the database because they are not sequential (1,2,3,...). So I'v got an idea to encrypt the database ID. This is how it could work
1) Client POSTs an item to `<URL>
2) The back-end creates a new item in the database.
3) Autoincremented ID '4' is generated by the database.
4) The back-end encrypts the ID '4' to 'fa4ce3178a045b2a' using a cipher key and returns encrypted ID of a created resource.

And then
5) Client sends a request to GET `<URL>
6) The back-end decrypts 'fa4ce3178a045b2a' to '4' using an cipher key.
7) The back-end fetches item with primary key '4' and sends it to the client.

What are the cons of such solution? Will the encryption/decryption will be fast enough so that it's not worse then using UUID? And what encryption algorithm should I use so that it is fast and doesn't consume much resources? Could someone more experienced advise or recommend a better solution? Thank you in advance. Vojtech
",['rest']
28628822,Why does Sidekiq not close old connections?,"My Rails 4.1 application uses Sidekiq to run measurements in Celluloid actors. It continously runs out of database connections. It appears that Sidekiq opens 2 connections per job, and old connections  never get closed properly.
What the system does

Every 15 minutes, I start a MeasurementWorker. By calling MeasurementWorker.perform_async(measurement.id). It does this

    class MeasurementWorker
      include SidekiqWorker
      sidekiq_options retry false, backtrace true

      def perform(measurement_id, force = false)
        ActiveRecordBase.connection_pool.with_connection do
            Measurement.find(measurement_id).run
        end
      end
    end


Inside this measurement, when I call .run, it does this

    # various checks if measurement can be run at all, using AR
    # ...
    begin
      ActiveRecordBase.connection_pool.with_connection do
      # (I used to have a Timeout.timeout here, but removed it for the
      # sake of simplification)
        @connection = MeasurementConnection.new do |event_info|
          event = Event.new
          event.assign_attributes(event_info)
          event.save
        end
        while @connection.measuring?; end
      end # with_connection
    rescue Exception => e
      # an exception happened, e.g. something during the measurement itself
      # log error (left out here for brevity)
    else
      # all went fine, 
      # save this measurement via AR
    ensure
      # Close and terminate the actor to free up the websocket,
      # if it is still actively measuring something.
      if @connection
        if @connection.alive? and @connection.measuring?
          @connection.close
        end
        while @connection.alive?
          @connection.terminate
          sleep(0.01)
        end
      end
    end


The MeasurementConnection is a simple Celluloid actor. There is no AR-related code inside this actor.

Configuration

Unicorn concurrency set to 3
Sidekiq 3.3.0 concurrency set to 50, and in the initializer

    Sidekiq.configure_server do |config|
      if defined?(ActiveRecordBase)
        config = Rails.application.config.database_configuration[Rails.env]
        config['pool']              = Sidekiq.options[concurrency] + 2
        config['reaping_frequency'] = ENV['DB_REAP_FREQ'] || 5
        ActiveRecordBase.establish_connection(config)
      end
    end


database.yml pool set to 60, reaping frequency 5
PostgreSQL 9.3 maximum connections are 2000, no other modifications

The problem too many connections open
When I check SELECT * FROM pg_stat_activity;, I see that there are some old connections open with no Sidekiq workers busy, and some new where they are
16661 measurement 6354  16384 measurement unicorn worker[0] -c /home/web...E production -D -l0.0.0.08080 127.0.0.1   50775 2015-02-20 125248.572551+01   2015-02-20 130505.773178+01 2015-02-20 130505.773565+01 f idle  SELECT COUNT(*) FROM measurements
16661 measurement 6406  16384 measurement unicorn worker[2] -c /home/web...E production -D -l0.0.0.08080 127.0.0.1   50776 2015-02-20 125359.636414+01   2015-02-20 130453.930305+01 2015-02-20 130453.931+01  f idle  SELECT COUNT(*) FROM measurements
16661 measurement 6687  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50801 2015-02-20 130005.14621+01    2015-02-20 130449.558589+01 2015-02-20 130449.558835+01 f idle  COMMIT
16661 measurement 7042  16384 measurement unicorn worker[1] -c /home/web...E production -D -l0.0.0.08080 127.0.0.1   50997 2015-02-20 130034.874675+01   2015-02-20 130035.376593+01 2015-02-20 130035.376979+01 f idle  SELECT COUNT(*) FROM measurements
16661 measurement 6668  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50781 2015-02-20 130004.883553+01   2015-02-20 130419.108365+01 2015-02-20 130419.108567+01 f idle  COMMIT
16661 measurement 6669  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50782 2015-02-20 130004.908349+01   2015-02-20 130357.683036+01 2015-02-20 130357.683236+01 f idle  COMMIT
16661 measurement 6672  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50786 2015-02-20 130004.962251+01   2015-02-20 130432.395137+01 2015-02-20 130432.395344+01 f idle  COMMIT
16661 measurement 6674  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50788 2015-02-20 130004.98456+01    2015-02-20 130432.396335+01 2015-02-20 130432.39652+01  f idle  COMMIT
16661 measurement 6676  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50790 2015-02-20 130005.006847+01   2015-02-20 130419.059628+01 2015-02-20 130419.059831+01 f idle  COMMIT
16661 measurement 6678  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50792 2015-02-20 130005.029448+01   2015-02-20 130423.730293+01 2015-02-20 130423.730523+01 f idle  COMMIT
16661 measurement 6680  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50794 2015-02-20 130005.051932+01   2015-02-20 130449.557435+01 2015-02-20 130449.557633+01 f idle  COMMIT
16661 measurement 6684  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50798 2015-02-20 130005.124225+01   2015-02-20 130351.693799+01 2015-02-20 130351.694034+01 f idle  COMMIT
16661 measurement 6690  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50804 2015-02-20 130005.168099+01   2015-02-20 130454.849239+01 2015-02-20 130454.849459+01 f idle  COMMIT
16661 measurement 6693  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50807 2015-02-20 130005.189661+01   2015-02-20 130418.688459+01 2015-02-20 130418.688732+01 f idle  COMMIT
16661 measurement 6696  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50810 2015-02-20 130005.210659+01   2015-02-20 130357.68424+01  2015-02-20 130357.684483+01 f idle  COMMIT
16661 measurement 6699  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50813 2015-02-20 130005.231641+01   2015-02-20 130404.962397+01 2015-02-20 130404.96258+01  f idle  COMMIT
16661 measurement 6701  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50815 2015-02-20 130005.252357+01   2015-02-20 130441.685372+01 2015-02-20 130441.685594+01 f idle  COMMIT
16661 measurement 6706  16384 measurement sidekiq 3.3.0 measurement [0 of 50 busy]  127.0.0.1   50820 2015-02-20 130005.273301+01   2015-02-20 130423.733488+01 2015-02-20 130423.733681+01 f idle  COMMIT
16661 measurement 7003  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50967 2015-02-20 130009.004487+01   2015-02-20 130202.036429+01 2015-02-20 130202.036696+01 f idle  COMMIT
16661 measurement 7005  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50969 2015-02-20 130011.118961+01   2015-02-20 130248.341078+01 2015-02-20 130248.341294+01 f idle  COMMIT
16661 measurement 7006  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50970 2015-02-20 130012.245408+01   2015-02-20 130304.300372+01 2015-02-20 130304.300575+01 f idle  COMMIT
16661 measurement 7007  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50971 2015-02-20 130012.648636+01   2015-02-20 130301.855616+01 2015-02-20 130301.85588+01  f idle  COMMIT
16661 measurement 7008  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50972 2015-02-20 130012.956139+01   2015-02-20 130313.840023+01 2015-02-20 130313.840466+01 f idle  COMMIT
16661 measurement 7009  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50973 2015-02-20 130013.02424+01    2015-02-20 130250.115996+01 2015-02-20 130250.116259+01 f idle  COMMIT
16661 measurement 7010  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50974 2015-02-20 130013.0909+01   2015-02-20 130309.968+01  2015-02-20 130309.968284+01 f idle  COMMIT
16661 measurement 7014  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50976 2015-02-20 130014.929822+01   2015-02-20 130320.183195+01 2015-02-20 130320.183467+01 f idle  COMMIT
16661 measurement 7020  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50980 2015-02-20 130022.498892+01   2015-02-20 130329.887257+01 2015-02-20 130329.887599+01 f idle  COMMIT
16661 measurement 7021  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50981 2015-02-20 130022.898087+01   2015-02-20 130339.689939+01 2015-02-20 130339.69798+01  f idle  COMMIT
16661 measurement 7022  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50982 2015-02-20 130023.215846+01   2015-02-20 130303.918339+01 2015-02-20 130303.918613+01 f idle  COMMIT
16661 measurement 7023  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50983 2015-02-20 130023.930861+01   2015-02-20 130351.504525+01 2015-02-20 130351.512786+01 f idle  COMMIT
16661 measurement 7025  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50985 2015-02-20 130024.409999+01   2015-02-20 130316.000375+01 2015-02-20 130316.006178+01 f idle  COMMIT
16661 measurement 7027  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50986 2015-02-20 130025.786321+01   2015-02-20 130322.631091+01 2015-02-20 130322.631353+01 f idle  COMMIT
16661 measurement 7045  16384 measurement sidekiq 3.3.0 measurement [15 of 50 busy] 127.0.0.1   50998 2015-02-20 130048.004036+01   2015-02-20 130339.717124+01 2015-02-20 130339.722956+01 f idle  COMMIT

In total, there are 34 connections, but I only ran 15 measurements.
In sidekiq.log, they all show as done
2015-02-20T120004.879Z 6235 TID-osgop8md0 MeasurementWorker JID-1cdcd44bf41fefe9ddca21ac INFO start
2015-02-20T120004.907Z 6235 TID-osgoox8hg MeasurementWorker JID-79f4d1ff6692248682ba93dd INFO start
2015-02-20T120004.939Z 6235 TID-osgoos38k MeasurementWorker JID-09f95fbccd2438d17916d425 INFO start
2015-02-20T120004.940Z 6235 TID-osgoorlmo MeasurementWorker JID-be1a57871f26146e9884107e INFO start
2015-02-20T120004.959Z 6235 TID-osgoow16k MeasurementWorker JID-e296efec897c23629b96e99f INFO start
2015-02-20T120004.968Z 6235 TID-osgoouytg MeasurementWorker JID-c6a57700872b7fe427e33664 INFO start
2015-02-20T120004.984Z 6235 TID-osgooz63k MeasurementWorker JID-f7448eaffe109882130497ca INFO start
2015-02-20T120004.998Z 6235 TID-osgoozvzs MeasurementWorker JID-c55c04f3424268fba50ec048 INFO start
2015-02-20T120005.014Z 6235 TID-osgooyr6c MeasurementWorker JID-01bd303e953fd2998fe3f8d1 INFO start
2015-02-20T120005.030Z 6235 TID-osgon0ums MeasurementWorker JID-6949c5c81b4c254046f0c585 INFO start
2015-02-20T120005.042Z 6235 TID-osgomw0g8 MeasurementWorker JID-cc03b717f81dd6fb0f58a946 INFO start
2015-02-20T120005.111Z 6235 TID-osgomlno8 MeasurementWorker JID-10eebcd76113f3565d8265ca INFO start
2015-02-20T120005.113Z 6235 TID-osgomjzzw MeasurementWorker JID-b0536d9a029faed0ba8eb5d3 INFO start
2015-02-20T120005.114Z 6235 TID-osgomhyms MeasurementWorker JID-1f6624314afd8e0ae611599f INFO start
2015-02-20T120005.115Z 6235 TID-osgolgzoc MeasurementWorker JID-24e87960d7e7fbd871037dd3 INFO start
2015-02-20T120202.333Z 6235 TID-osgomw0g8 MeasurementWorker JID-cc03b717f81dd6fb0f58a946 INFO done 117.291 sec
2015-02-20T120248.983Z 6235 TID-osgoox8hg MeasurementWorker JID-79f4d1ff6692248682ba93dd INFO done 164.077 sec
2015-02-20T120250.688Z 6235 TID-osgomlno8 MeasurementWorker JID-10eebcd76113f3565d8265ca INFO done 165.577 sec
2015-02-20T120302.429Z 6235 TID-osgolgzoc MeasurementWorker JID-24e87960d7e7fbd871037dd3 INFO done 177.314 sec
2015-02-20T120304.581Z 6235 TID-osgoorlmo MeasurementWorker JID-be1a57871f26146e9884107e INFO done 179.641 sec
2015-02-20T120309.453Z 6235 TID-osgop8md0 MeasurementWorker JID-1cdcd44bf41fefe9ddca21ac INFO done 184.573 sec
2015-02-20T120310.362Z 6235 TID-osgoouytg MeasurementWorker JID-c6a57700872b7fe427e33664 INFO done 185.394 sec
2015-02-20T120314.232Z 6235 TID-osgomjzzw MeasurementWorker JID-b0536d9a029faed0ba8eb5d3 INFO done 189.118 sec
2015-02-20T120316.347Z 6235 TID-osgoos38k MeasurementWorker JID-09f95fbccd2438d17916d425 INFO done 191.408 sec
2015-02-20T120320.398Z 6235 TID-osgoow16k MeasurementWorker JID-e296efec897c23629b96e99f INFO done 195.439 sec
2015-02-20T120322.947Z 6235 TID-osgomhyms MeasurementWorker JID-1f6624314afd8e0ae611599f INFO done 197.833 sec
2015-02-20T120330.212Z 6235 TID-osgooz63k MeasurementWorker JID-f7448eaffe109882130497ca INFO done 205.228 sec
2015-02-20T120339.931Z 6235 TID-osgooyr6c MeasurementWorker JID-01bd303e953fd2998fe3f8d1 INFO done 214.918 sec
2015-02-20T120339.936Z 6235 TID-osgon0ums MeasurementWorker JID-6949c5c81b4c254046f0c585 INFO done 214.906 sec
2015-02-20T120351.694Z 6235 TID-osgoozvzs MeasurementWorker JID-c55c04f3424268fba50ec048 INFO done 226.696 sec

So, for every measurement, Sidekiq seems to open 2 connections, but it never closes them. What should I do?
",['activerecord']
27752928,OAuth  OpenID - Need confirmation,"This question has already be asked 20 times and i read a lot about it... but i need confirmation about something. I just want know if i understood good.
The first part is about definitions 
Identification  To identify the client, know who it is exactly.
Authorization  To allow access to some ressources. No identity here.
Authentication  Combine Identification and Authorization.
My first question is  Reasoning good or not ?

Then, my second part is about OAuth amp; OpenId 
At the beginning, for the basic implementation, OpenId is only for the Identification part and OAuth is for the Authorization part.
But now, after upgrading, the both tend towards an Authentication part.
For example, OAuth basically can just allow one application to access to another without the password or critical informations of the user through the network. It just do it one time and generate a token which can be revoke or refresh and need to be given for each request.
Now, with the basic implementation of OAuth, if S1 allow S2 to get users informations, i can access to these url  path_to_s1/api/users/foo - path_to_s1/api/users/bar and i will get the informations (email - contacts... for example) of the user foo when i will be on the first url and of the user bar when i will be on the second url. I just have here the Authorization and not the Identification. For the identification, i can for example implement an API Key or OpenId Connect on the top of OAuth.
My second question is  Reasoning good or not ?
Thank you in advance )
",['rest']
17642224,validate OAuth 2.0 access token from a Spring RESTful resource server,"I want to secure my Spring RESTful backend. One way (the right?) is to use OAuth 2.0 like shown here
<URL>
Within my architecture the resource server and authorization server ARE NOT the same entity. I really just provide some JSON REST services. No UI. If I read the OAuth2 RFC they just say

The interaction between the authorization server and resource server
     is beyond the scope of this specification.  The authorization server
     may be the same server as the resource server or a separate entity.
     A single authorization server may issue access tokens accepted by
     multiple resource servers.

I found a good diagram on cloudfoundry.com (related to the above youtube video) which I'm using to illustrate my view

token provider This could/should be google or facebook for example.
RESTful backend This is actually my code. Spring RESTful services like
@Controller
@RequestMapping(/api/v1)
public class MyResourceToProtect {

    @Autowired
    private MyService service;

    @RequestMapping(value = /resource/delete/{name},
                    method = RequestMethod.DELETE,
                    consumes = MediaType.APPLICATION_JSON_VALUE,
                    headers = Content-Type=application/json)
    @ResponseStatus(HttpStatus.OK)
    public void delete(@PathVariable(name) String name) {
        service.delete(name);
    }
}

(This is just some sample code)
Now my question Is it somehow possible to validate the access tokens which are generated by the AuthServer (Facebook, Google)? I know that I need to have a token to user mapping (database) somewhere on my ResourceServer. Basically I'd like to design my RESTful API like to one from PayPal
<URL>
But how can I handle the steps 1 amp; 2 if I want to use Facebook or Google as auth providers? Is this even possible?
Additional thought Probably I need to provide my own /oauth2/token endpoint and then delegate to the underlying AuthProvider.
",['rest']
53497899,How to maintain http sessions in an API deployed in Kubernetes?,"I am designing an API which will receive requests from customers and will interact with a cloud backend such as AWS on behalf of the customer. This API has to be scalable so a bit of research led me to believe that I can put the API inside containers and let scale it through Kubernetes. I am planning to use Flask for writing this API. I have three questions in this regard

Is flask a suitable choice for this? It seems so through my research.
How should the API handle the user authentication to the backend? Should it simply take the username/password from the user, make a connection to the backend based on these credentials, and maintain the resulting connection in memory/database somehow? Is there any other way?
If we take the second approach for user authentication, then the question is I don't want the API to make a new connection to the backend on every user request. This means I would need to maintain connection state somehow all the while making sure that the API is supposed to work in a decentralized fashion. e.g a user A was served by docker instance 1 of the API previously but now her request gets routed to docker instance 2, in this case I want to use the same connection of the user to the backend, which was established by docker 1 API instance. So how do I maintain this connection? Is it against the principles of a REST API which should be stateless? What is another option to design the system, then? Thanks.

",['rest']
4395963,loosely coupled development,"I'm reading Sanderson's Pro ASP.NET MVC Framework.
I'm confused a little with decoupling implementation.
He uses LinqToSql in the code sample and repository pattern to interact with database.
[Table(Name = Products)]
public class Product 
{
 [Column(IsPrimaryKey = true, IsDbGenerated = true, AutoSync=AutoSync.OnInsert)]
 public int ProductID { get; set; }
 [Column] 
 public string Name { get; set; }
 [Column] 
 public string Description { get; set; }
 [Column] 
 public decimal Price { get; set; }
 [Column] 
 public string Category { get; set; }
}

public class SqlProductsRepository  IProductsRepository
{
 private Table productsTable;
 public SqlProductsRepository(string connectionString)
 {
  productsTable = (new DataContext(connectionString)).GetTable();
 }
 public IQueryable Products
 {
  get { return productsTable; }
 }
}

SqlProductsRepository is dataLayer here as it interacts with database.
1.However it is located in DomainModel project. Maybe it is just for demo?
So where is domain logic here? 
2.I can't see full decoupling as Products property return IQueryable.
Is it assumed that if we change a component, it must contain Product class?
I seem that it is required to have one more project with abstractions
Repository Interfaces such as IProductRepository and MappingClasses interfaces such as IProduct.
DataLayer component must implement these abastractions.
Is it right?
Maybe it is diffucult to explain it shortly, however how it is usually work in live projects?
",['mvc']
13772177,Where to implement Automapper in a DDD + layered architecture,"Background
For my own clarity / self education, I am trying to implement a simple Order Entry application using TDD + DDD.  My primary goal is to keep the architecture clean by separating concerns.  
I have four layers (for now) ... 

Persistence/DAL with a CustomerRepository class that can perform GetById, Save, operations on the aggregate root, a Customer and its related Orders and OrderItems.  In order to allow for poor man's dependency injection
Domain/BLL layer containing business entity classes that perform fine-grained operations to help create new Orders, applying Tax, Discounts, Shipping logic based on order size and customer location.
Application Facade (App services / orchestration) containing chunky, coarser-grained classes to orchestrate the business entities and reduce the chatter with the presentation (and potentially a WebServices layer).
Presentation layer

Furthermore, I want to pass POCO DTO's between key layers ... particularly between Persistence=>Domain layers, and ApplicationFacade=>Presentation layers.  So, I have CustomerDto, OrderDto, OrderItemDto with the appropriate relationships defined in a shared package.
I want to inject an implementation of the ICustomerRepository into the Customer business entity class using Constructor Injection, then call a Customer.Save() on the business entity to kick off the create/update process, ultimately calling the Save method on the CustomerRepository.  After all, the Customer is the aggregate root and has all the information needed to save ... it also is the keeper of the injected CustomerRepository.
Problem
This is where I hit a snag.  I want to keep the Domain/BLL Layer as pure as possible and avoid coupling it to any third-party frameworks and APIs, but the Customer.Save() method needs to translate the Customer aggregate root and all its Orders and OrderItems into their DTO versions for transport to the injected Persistence layer CustomerRepository ... and that is a job for Automapper.  
The problem is ... If I don't put Automapper in the Domain/BLL layer, I'm not really sure where it should go.  
It doesn't feel right to put it in the ApplicationFacade even though it's job is orchestration.
It definitely doesn't feel right to put it in the Domain/BLL layer because I want to keep it pristine.
Therefore, I feel like I've missed something ... that I'm approaching this with a fundamental misunderstanding of how the working parts should all come together to complete this task.  Any suggestions?  (Please be gentle, I'm new to all this, and new to SO.  Let me know if I need to show some code of what I have so far.)
",['ddd']
33453269,Jhipster + REST client + authentication,"I need to understand how to authenticate a REST client (could be Paw, could be an android app, an iOs app using AFNetworking with jHipster and I think, more in general, with spring-boot of which I am no expert).
While I am able to obtain a token when logged in a browser, and subsequently use this token in the following requests, I do not understand how I can authenticate in the first place using RESTful best practices.
For example, in Paw.app, I can pass a Basic authentication, or Oauth2, but I don't understand how to get the session token simply authenticating as I do on a web browser.
Similarly, in AFNetworking I am able to pass basic authentication, e.g.
NSString*auth=[NSString stringWithFormat@%@%@, @admin, @admin];
NSString *authValue = [NSString stringWithFormat@Basic %@, [auth base64EncodedString]];
[manager.requestSerializer setValueauthValue forHTTPHeaderField@Authorization];

But I struggle to understand how to authenticate with the session security which is bundled in jHipster/spring boot.
",['rest']
34218135,Spring Security with basic authentication,"I'm using Spring to secure my Rest API and to deal with the authentication I've chosen the Basic Authentication method. 
When I test my method, I use to send a header parameter Authentication  basic loginpassword.
This works very well with GET method but not with POST, is it normal ? 
Some Details. 
This test uses a get method --> works correctly 
@Test
public void testListAll() throws Exception {
    Assert.assertNotNull(mockMvc);

    String userName = user1;
    String userPassword = user1;
    String userAuthorisation = Basic  +
            Base64.getEncoder().encodeToString((userName +  + userPassword).getBytes());

    String response = mockMvc.perform(get(/api/persons)
            .header(Authorization, userAuthorisation))
            .andExpect(status().isOk())
            .andReturn().getResponse().getContentAsString();
    Assert.assertNotNull(response);
    Assert.assertFalse(response.isEmpty());

    List persons = (new ObjectMapper()).readValue(response, List.class);
    Assert.assertNotNull(persons);
    Assert.assertTrue(persons.size() >= 14);
}

... but not this one which is using POST 
@Test
public void shouldCreatePerson() throws Exception {
    String firstName = Tools.generateValidString((int)(Math.random()*100) + 1 );
    String lastName = Tools.generateValidString((int) (Math.random() * 100) + 1);

    String editorName = user2;
    String editorPassword = user2;
    String editorAuthorisation = Basic  +
            Base64.getEncoder().encodeToString((editorName ++ editorPassword).getBytes());

    String response = mockMvc.perform(post(/api/persons/create)
            .header(Authorization, editorAuthorisation)
            .param(firstName, firstName)
            .param(lastName, lastName)
            .param(isMale, true))
            .andExpect(status().isOk())
            .andReturn().getResponse().getContentAsString();
    Assert.assertNotNull(response);
    Assert.assertFalse(response.isEmpty());

    Person person = (new ObjectMapper()).readValue(response, Person.class);
    Assert.assertNotNull(person);
    Assert.assertTrue(person.getFirstName().equals(firstName));
    Assert.assertTrue(person.getLastName().equals(lastName));

    person = personRepository.findOne(person.getId());
    Assert.assertNotNull(person);
    personRepository.delete(person.getId());
}

spring security configurations (I'm using H2 embedded database for user details)  
    
        
    

    

.... and 

       
       
       
   

   

The RequestMapping class of the update method
@RestController
@RequestMapping(/api/persons) 
public class PersonUpdateController {
@Qualifier(personService)
@Autowired
private PersonService personService;
@Qualifier(errorCodeReader)
@Autowired
private ErrorCodeReader codeReader;

@RequestMapping(value = /create, method = RequestMethod.POST)
public Person createSimplePerson(
        @RequestParam String firstName,
        @RequestParam String lastName,
        @RequestParam boolean isMale
) {
    Person person;
    try {
        if (isMale) {
            person = personService.create(firstName,lastName,Person.MALE);
        }else {
            person = personService.create(firstName,lastName,Person.FEMALE);
        }
        return person;
    } catch (IncorrectGenderException | InvalidPersonNameException e) {
        e.printStackTrace();
        throw new RestException(codeReader.getError(InvalidPersonName),Invalid Person Names,
                First name or last name is invalid);
    }
}

}
the class RestAuthenticationEntryPoint
@Component( restAuthenticationEntryPoint )
public class RestAuthenticationEntryPoint implements AuthenticationEntryPoint {

@Override
public void commence( HttpServletRequest request, HttpServletResponse response,
                      AuthenticationException authException ) throws IOException {
    response.sendError( HttpServletResponse.SC_UNAUTHORIZED, Unauthorized );
}

}
I receive this error 
java.lang.AssertionError Status 

Expected 200
Actual   403
By just changing the method from POST to GET, it works correctly (Status 200) !!
thanks in advance.
",['rest']
57240164,Trying to share access token granted by identity server to a client app using resource owner password grant,"We have legacy applications in .net framework which have their own separate authentication mechanism going through the database to validate credentials and generating an access token. Now we are trying to use Identity Server to generate an access token , and trying to implement single sign on using this token.
Since all our client applications and api resources are in house, we intend to share this token amongst all our applications.
The web app where user logs in passes the credentials to a rest api. The rest api then talks to IDentityServer4 (using resource owner password grant) to authenticate and get an access token . This token is returned by the rest api to the web app, which then passes it to another web app , which then tries to access another streaming api . The streaming api now needs to validate the token with IS4 , and then allow access to web app2.
The problem we are facing is that 
1) the access token has a limited validity period , after which it will be invalid. The web app2 cannot refresh the access token , as only the initiator of the token ( rest api) is allowed to do that .
2) Even if the rest api takes care of refreshing the access token when its about to expire by using refresh token, a new access token is granted which is not the same as the old token which was shared with other clients.  Is there any way for the web app2 to keep the token alive which was initially granted to the rest api. 
I have tried refreshing the token on web app2 , which fails as it is different from the client who owns the token.
I am aware that this is not the best way to use IS4 , and ideally the client apps should be talking to IS4 and authenticating through IS4, and also getting grants to access the api and identity resources , but since we do not want to change all our applications  at once , we are trying to make the api resource talk to IS4 to generate a token. 
Is there any way to keep the same access token alive until revoked by the initiator client  ?
",['rest']
8703263,How to bypass the authentication page while using LinkedInDeveloper Toolkit(which uses OAuth),"I have been using LinkedIn Developer toolkit for accessing the Linked In data , like network updates , profile photo URL etc.
Everything seems to work fine , except that i need to get rid of the Authentication page, which appears for the first time.
I need the implementation to look something like <URL>
Could someone assist me in implementing this? May be simulating the authentication on the server side.
Thanks,
Vijay
",['rest']
3177088,Question about use of Controllers,"I was given a Use Case for a Quizz Application. The Use Case is only for creating new Quizzes. I am having trouble deciding which design is better
a)
alt text <URL>
b)
alt text <URL>
Although this might look like a Domain Model, it is in fact a Class Diagram (I was lazy to put the methods/attribtues in the diagrams ( ).
The idea behind all this is that I have a QuizCatalog that has Quizzes. Each Quiz has a set of Questions, that must be created through a Questionabstract-abstract-factory(a Question is an abstract class, and QuestionA, QuestionB, etc are the concrete classes). Each Question has a set of PossibleAnswers.
The difference in terms of associations between Design A and Design B is that in the first I am considereing that CreateQuizController will simply delegate every task it has to QuizCatalog. If QuizCatalog needs to do something, it will delegate everything it might need down the hierarchy. This is actually nice, as it seems to reduce coupling.
Design B, on the other hand, follows a different philosophy. The associations seen in Design A still exist (as a QuizCatalog still has Quizzes, a Question PossibleAnswers, etc) but now I've made CreateQuizController have access basically to every kind of object in the domain it might need to create in the process(I've signaled those kind of associations with d). The idea is that instead of asking the QuizCatalog to create a Quiz, CreateQuizController will create a Quiz by itself (and if it needs to create Questions for the Quiz, it will by itself, the same happening for Question's PossibleAnwsers, etc). 
There are 2 things that bother me about Design A
1.
If I need to create temporary objects that need to be filled up before being put in the system (for example, a Quiz is only actually added to QuizCatalog after it was filled with all the wanted Questions), following this design I'll have to keep them in some place other than the Controller. 
For example, when I first create a Quiz, I'll have to probably save it under QuizCatalog without actually adding it to the current collection of Quizzes that is accessible to the rest of the system. I find this kind of behaviour a bit awkward. I find it better to keep those kind of temporary objects in a Controller, as if anything wrong happens then the System is kept just as it was before, with no problems associated.
The problem is that it makes the Controller have to know about almost everything, which might be undesirable. On the other hand, there is no difference in how coupled the rest of the classes in the System are.
2.
If I am going to use Design A, I actually don't see a big point in having a CreateQuizController, as basically everything can be done by just having a reference to QuizCatalog. In my eyes, it is just delegating all its work to QuizCatalog, so why have it in the first place?
Also, using Design A, I'd probably consider Questionabstract-abstract-factory to be a Singleton, while if using Design B I'd probably just have CreateQuizController's constructor accept an instance of a Questionabstract-abstract-factory instead.

What are your thoughts about this?
Thanks
PS Only after drawing the diagrams I noticed that Quizz has 2 z's ( My bad.
",['mvc']
18351134,Token based Authentication mechanism for REST API,"I have a network device (running c++) in my local network which runs a <URL> server and provides a Restlike webservice interface to provide an API to control the device.
Now my question is, how can i authorize the user (an android smartphone in the same network) for using the Rest api?
The scenario is as like this The user on the smartphone has to enter a PIN cod (4-digits) in order to get access to the api from then on it should be possible to call all the other REST API methods.
My idea 
1) the pin code will be send to the device via <URL> POST body, the device checks if it is okay.
2) if the PIN is right, the device will generate a token, which has to be used on every future request.
so my questions are
* how should i generate such a token (what algorithm) on the device using c++
* how should the token be transmitted on every request? As a query parameter? Or in the POST body? or in the Header?
EDIT i also read about http basic authentication. could this be used in my setup too?
kind regards
",['rest']
6068932,NHibernate second level cache performance issue,"I am developing a MVC application with NHibernate using the session per request pattern. Most of the time users just read data and therefore i am trying to make use of NHibernate's second level cache in the following manner I've setup SysCache and have made all my persistant entities cacheable (cache usage=nonstrict-read-write) and on application start I make calls to load all commonly used entities from the database like so 
var all = Session.QueryOver().Cacheable().List()

For evaluation purposes I trace the execution time for the above call and for approximately 50000 results it's ~5 seconds the first time and ~2.5 seconds for any subsequent calls to the cached query.... NHibernate Profiler says the query to the database takes less than 100ms, what takes so much time then? I tried switching providers but got similar (if not worse) results with Velocity and Memcached... I read virtually all I could find regarding NHibernate and its use of the second level cache and I think, though I may not be entirely correct, that in the above statement what happens is 50000 objects are constructed and their data is stored in the entity and query caches and the session timestamp saved in the timestamp cache. How could that take 5 seconds on an i5 machine? Even if that is normal how just reading the cached data take 2.5 seconds in the subsequent calls with no changes inbetween? Since I am relatively new to NHibernate, can any of you help me figure out what I am doing wrong? Any help would be greatly appreciated...I've been banging my head against the wall for a week now...
",['mvc']
24438769,How do I use REST API in embedded JavaScript without a Firebase Library?,"I'm trying to access the Nest API using REST from an embedded controller that doesn't have a Firebase library installed. There is NO way to install a Firebase library and the Nest docs seem to indicate that I should use REST API.
I've gotten pretty far through the authorization process even though I receive a ton of HTTP page data and no json that I can discern.
The docs talk about a wss web socket but there's sparse information.
How can I use REST API to send <URL> data (I'm using POST) and get the pertinent json data back rather than a huge web page?
I hope this question is clear. Basically, I don't have a web browser, I have to build everything myself in the embedded system.
",['rest']
47856019,Why are throughput and latency inversely proportional on pub/sub systems?,"When reading a paper (not free) comparing Kafka and RabbitMQ, I came across the following (emphasis mine)

Latency. In any transport architecture, latency of a packet/message is
  determined by the serial pipeline (i.e., sequence of processing steps)
  that it passes through. Latency can only be reduced by pipelining the packet transport over resources that can work concurrently on the same packet in a series architecture (multiple processing cores, master DMA engines in case of disk or network access,‚Ä¶) . It is not infuenced by scaling out resources in
  parallel.
Throughput. Throughput of a transport architecture is the number of
  packets (or alternatively,bytes) per time unit that can be transported
  between producers and consumers. Contrary to latency,throughput can
  easily be enhanced by adding additional resources in parallel.
For a simple pipeline throughput and latency are inversely
  proportional.

Why is it so? Isn't that the contrary of saying that (latency) is not influenced by scaling out resources in parallel? If I add more machines to increase the throughput, how is the latency reduced? 
",['publish-subscribe']
6387933,"System consuming WCF services from another system, when underlying databases have relationships","This is an issue that I have struggled with in a number of systems but this one is a good example. It is to do with when one system consumes WCF services from another system, and each system has their own database, but there are relationships between the two databases.
We have a central database that holds a record of all documents in the company. This database includes Document and Folder tables and it mimicks a windows file structure. NHibernate takes care of data access, a domain layer handles logic (validating filenames/no identical filenames in the same folder etc.) and a service layer sits on that, with services named 'CreateDocument(bytes[])', 'RenameDocument(id, newName) ', 'SearchDocuments(filename, filesize, createdDate)' etc. These services are exposed with WCF.
An HR system consumes these services. The HR database has a separate database that has foreign keys to the Document database it contains an HRDocument table that has a foreign key DocumentId, and then HR specific such as EmployeeId and ContractId.
Here are the problems amonst others
1) In order to save a document, I have to call the WCF service to save it to the central db, return the ID and then save to the HRDocument table (along with the HR specific information). Because of the WCF call and all Document specific data access being done within the Document application, this can't be done all within one transaction, resulting in a possible loss of transaction integrity.
2) In order to search on say, employeeId and createdDate, I have to call the search service passing in the createdDate (Document database specific fields) and then search the HRDocument database on the Id's of the returned records to filter the results returned. This feels messy, slow and just wrong.
I could duplicate the NHibernate mapping files to the Document database in the DAL of the HR application. This means I could specify the relationship between HRDocument and Document. This means I could join the tables and search like that but would also mean I would have to duplicate domain logic and violate the DRY principle, and all that entails.
I can't help feeling I'm doing something wrong here and have missed something simple.
","['ddd', 'soa']"
11821453,Does if-match HTTP header require two-phase commits?,"I'm trying to design a RESTful web API, so I've been studying rfc2616. I like the idea of using ETags for optimistic concurrency and was trying to use it to make a safe way to add resources without race-conditions. However, I noticed the following two statements in section 14.24

If the request would, without the If-Match header field, result in anything other than a 2xx or 412 status, then the If-Match header MUST be ignored.
A request intended to update a resource (e.g., a PUT) MAY include an If-Match header field to signal that the request method MUST NOT be applied if the entity corresponding to the If-Match value (a single entity tag) is no longer a representation of that resource.

I'm using a RDBMS and don't know whether a transaction will successfully commit until I try it, so I think the first requirement seems a bit onerous. Consider a case where somebody supplies an If-Match header with mismatched ETags If the commit would succeed, then I should heed the If-Match header, NOT attempt the commit, and return 412. If the commit would fail, then a request without the If-Match header would have resulted in a non-2XX/412 response, so I MUST ignore the If-Match header, meaning I should attempt the commit.
As far as I can figure out, I have 2 options

Use 2-phase commits to gain foresight into whether the commit will succeed before attempting it.
Ignore the first requirement above, and return 412 even if ignoring If-Match would have resulted in a non-2XX/412 response. (this is the one I'm leaning towards)

Any other ideas? Am I misinterpreting the specs?
",['rest']
6133254,What is Rails ActiveRecord find(x) method that is equivalent to a lazy-evaluated-scope? How to refactor ActiveRecord finder?,"Is Rails' find(x) method on a model lazy? If not, what is the equivalent?
I am new to Rails, so I found myself writing scopes like this
class Course < ActiveRecordBase
  scope by_instructor_id, lambda { |instructor_id| where(instructor_id => instructor_id) }
  scope by_course_template_id, lambda { |course_template_id| where(course_template_id => course_template_id ) }
  scope by_company_id, lambda { |company_id| joins(instructor).merge(CompanyUser.by_company_id(company_id)) }
end

It's not a lot of work, but now I'm asking myself... if Rails provided these with a scope, I wouldn't have to write them.
So, does Rails offer them? Can I do something like the below code and only make it do 1 database call?
Company.find(params[id]).instructors.courses

instead of
Course.by_company_id(params[id])

Which is correct? I know Course.by_company_id(params[id]) is only 1 database call. It is very familiar to writing SQL or queries in Hibernate. But if you can write it the other way, maybe one should?
However, I don't want to write Company.find(params[id]).instructors.courses if it results in more than 1 database call. I can see the advantage though because it means never having to write the 3 scopes I showed you above, but I am worried that Company.find(x) is not lazy. Is it?
",['activerecord']
43834191,Framework to build API REST service for Redis database?,"We start buliding an application like Tinder but not exactly the same ) We want to make a Rest service with API for Redis database to get the best performance for multiple queries going from client app. Which framework we can use? Which can offer the best performace with lowest latency?
Programming language is irrelevant for us. We will be appriciated if someone can give us advice. We must use the best technology.
Best regards for all of You )
",['rest']
20644672,Rails adapter solutions for MySQL Cluster (NDB)?,"I'm setting up a high-availability environment for a customer. There are a pair of load-balanced hosts serving http requests to our Rails application, which is deployed in parallel on both hosts.
Additionally, there are two MySQL hosts available. I want to run MySQL Cluster (NDB) on both hosts (i.e., multi-master) to have a fully redundant configuration. I'm specifically trying to avoid a master-slave configuration based on database replication; I feel like that makes the writable node a single point of failure.
I'm looking for some guidance on how best to interface our Rails app to a multi-master MySQL cluster like this. Almost all of the database adapters I can find are for master-slave setups. Failover_adapter sounds very promising, but it's woefully outdated. I haven't managed to turn up anything similar developed in the last five years.
Is anyone aware of any gems to use or approaches to take to serve as an adapter between a Rails application and a multi-master MySQL cluster like I've described?
",['activerecord']
7856827,Zend_DB and MVC models matching database tables,"I've been reading something from Bill Karwin (creator of Zend_DB) about models not being directly to do with database tables. (I think some devs have their models a direct extension of Zend_tables or so which makes it harder for adding memcached caching of objects, which makes sense.)
So what Bill Karwin was saying is that a Model has tables and isn't a table but I'm still thinking the way I have it is correct as its designed in an object oriented manner.
For instance (just an example)
A Monster has 1M Mouth. a Mouth has 1M Tooth. 

So in my database I'd have 5 tables 
Monster id, name, type
MonsterMouth id, monster_id, mouth_id
Mouth id, size
MouthTeeth id, mouth_id, tooth_id
Tooth id, size, shape, sharpness

Then the 3 classes
class Model_Monster { 
    private $id, $name, $type, $mouths = array();
    public function __construct ($id) {
        // Set properties from DB for supplied ID
        // Go through DB and add the mouths based on monster ID
    }

    public function countTeeth () {
        // Loop through each $mouths as $mouth and call $mouth->getTotalTeeth();
    }
} 
class Model_MonsterMouth { 
    private $id, $size, $teeth = array(); 
    public function __construct($id) {
        // Set properties from DB for supplied ID
        // Go through DB and add the types of teeth for this mouth ID
    }

    public function getTotalTeeth () {
        // return sizeof($teeth);
    }

}
class Model_Tooth {
    private $id, $size, $shape, $sharpness;
    public function __construct($id) {
        // Populate details based on ID passed
    }
}

Then I guess methods for counting teeth and stuff...
$monsterId = 1;
$monster = new Monster($monsterId);
// Count total teeth
$totalTeeth = $monster->countTeeth();

So a monster can have many different mouths and 1 mouth can have many different types of teeth.
After writing out this lengthy post I think I've got it right and that Bill Karwin is talking about those who have 5 Models rather than 3...
I have 5 Tables but only 3 Models as two tables are there to solve MM table relationships.
2 of the 3 Models use composition to store many of the other type of object.
If a monster had 10 mouths of between 9-10k of about 10 different types of teeth... would this be a performance issue? I mean would PHP see it like a,a,a,a,a,b,b or 5*a and 2*b. If having 1-100k of an object and iteratively adding them to a composite item is slow then I guess I should only have one occurance of it with a number property to say how many there are of that type.
If I've got it correct then maybe it might help some of the other guys who are having problems with this.
Thanks D Dom
",['mvc']
13821028,Best way to iterate a subset of a 2dimensional grid,"I have a 2d rectangular grid and I need to apply different functions to a subset of nodes in this grid. The subset is given by rectangular bounds e.g. row and column delimiters. Since I do not want to code the iteration with 2 for loops over and over again I am considering two approaches to solve this problem
First create a custom iterator provider which is initialized using the rectangle limits and then keeps them while he is iterated. While this is feasible it seems quite some work to make this iterator compliant e.g. with standard stl aglorithms.
The second approach is to pass a function pointer into the function the traverses both for loops and execute it in the inner loop. This is feasible as well but might create quite ugly syntax since i have to pass member functions.
Which way is usually preferable ? And are there any clean examples for such a use case, to keep me from reinventing the wheel ?
Note The operation is quite performance critical since the code is frequently executed
",['iterator']
10388235,restful WCF service authentication,"I have an application which exposes service which is consumed by the web application via Jquery POST and other applications (IPad, Android, etc). I have to create an authentication system which is highly safe but still fast enough. 
I thought of making a token which will be passed to the application on login and which will be used for a specific amount of time (say 30 mins) post which it should refresh itself and not expire the session. So I thought of making a token being sent to service and which will generate token. It will accept 

UserId
Password (both encrypted with public key)
AppId

The server will decrypt the request by the private key and generate a token which will be valid for a specific time. Now since this would highly depend on the private key (which will be same and thus someone from within system can leak it and misuse it) so i want the private key to be refreshed after a specific time (say 2 hrs).
Question - 

How do refresh Private key and ensure that the currently issues tokens will not be rejected.
Is there a better way of doing it

",['rest']
34700593,Does Ruby ActiveRecord support time-to-live or record expiration?,"Just an example to facilitate the question
Assume I have a class Authorizations which has thousands of persistant records, but I also want to assert numerous non-persistent records.  In other words, I want to derive additional Authorizations, but I am concerned the derived authorizations will be subject to changing conditions so I only want that authorization to 'live' for a short period of time; 5 minutes or an hour.
I have searched the Ruby on Rails ActiveRecord documentation and Googled 'Ruby ActiveRecord time to live' and 'Ruby ActiveRecord record expire'.
One consideration is to have a different class AuthorizationCache associated with an in-memory ActiveRecord while Authorization class is associated with my database server.  But, that would require my code to first look at the AuthorizationCache then Authorization and I'm sure that would make me crazy.
",['activerecord']
21141746,"In Layman's Terms, What Purpose Does the Warning Header Field in HTTP/1.1 Serve?","Related Questions

HTTP 403 Response vs HTTP 401 Response 
Is it Possible to Send an HTTP 401 and HTTP 302 Redirect with a Location Header?

Background
I'm developing a PHP web application that will redirect clients to custom error pages based on the semantic errors encountered. The specific one related to my question is which error to serve when a client that is logged out attempts to access a resource that is protected.
I've read people doing the following

Just use the PHP function header() to redirect using a standard HTTP 302 to your error page
Have a PHP script call a custom function that checks the permissions of the client and serves the appropriate error page as an included template
Utilize the existing Basic or Digest authentication built into HTTP.

The Dilemma
Since I'm using a PHP form-based methodology with sessions to authenticate users, and the HTTP 1.1 spec calls for a mandatory WWW-Authenticate header, I don't want to send a HTTP 401 response back ( even though it looks the most attractive to just send and deviate from spec ).
Question
I noticed an optional Warning Header under general headers that perhaps I could use to send also with my request. Can I use the warning header to show to a client that my particular response is semantically different than an assumed generic response?
",['client-server']
10221273,DangerousAttributeError in OmniAuth Railscast Tutorial create is defined by ActiveRecord,"I've looked at ActiveRecordDangerousAttributeError and other similar threads on SO, but they don't address the same issue.
I'm following the omniauth tutorial <URL>
I'm able to authenticate via oauth with Twitter and return the user's data (auth). The problem is that I'm not able to create/save it in the database (sqlite3) because of this error message.
Error
ActiveRecordDangerousAttributeError in AuthenticationsController#create

create is defined by ActiveRecord
Rails.root /beta/devise-omniauth1

Application Trace | Framework Trace | Full Trace
app/controllers/authentications_controller.rb15in `create'

Authentications_Controller
  def create
    auth = request.env[omniauth.auth] 
    current_user.authentications.create(provider => auth['provider'], uid => auth['uid'])
    flash[notice] = Authentication successful.
    redirect_to authentications_url
  end

Models
class Authentication < ActiveRecordBase
belongs_to user
end


class User < ActiveRecordBase
has_many authentications

  # Include default devise modules. Others available are
  # token_authenticatable, encryptable, confirmable, lockable, timeoutable and     omniauthable
  devise database_authenticatable, registerable,
         recoverable, rememberable, trackable, validatable

  # Setup accessible (or protected) attributes for your model
  attr_accessible email, password, password_confirmation, remember_me
end

How do I work past this error? Googling on this site and others doesn't help me understand what's going on in order to fix it. Thanks
",['activerecord']
23456736,Options for securing REST based service for iOS/Android app,"I am working on a web application implementing online shopping functionality. I am using Struts2 + Spring + Hibernate. I am using Spring security to implement authorization and authentication.
Now my client wants to develop an iOS/Android App for the same where users of my web application can login and use some of the functionality using the app.
Mobile App will access the REST based web services on JSON which will be implemented using Jersey. Here are my questions    

Users are going to have a role from three of the roles. Depending on the role they should be able to access the specific resources. I am thinking about using Spring Security 2.0 with Jersey and authenticate the users using  OAuth 2.0. Is OAuth 2.0 right applicable choice?  
Also, Jersey doesn't support oAuth 2.0 on server side. Still I guess I should be able to use any other OAuth provider to secure Jersey services right?  
If oAuth is not the right choice then what I can use to provide role based authentication and authorization for Mobile App users to my REST web services.  

",['rest']
19624859,has_many polymorphism/inheritance in Rails,"I am trying to set up a polymorphic relationship in Rails and have been running into some difficulty. Here's my data model
class Order
    has_many order_items
end

class OrderItem
    belongs_to order
end

class PhysicalItem < OrderItem
end

class VirtualItem < OrderItem
end

PhysicalItem and VirtualItem have enough differences in their model to warrant being split out into their own tables. So, I envision there being
an orders table
a physical_items table
a virtual_items table
an order_items table with item_type = [PhysicalItem or VirtualItem] and item_id of the matching row in the corresponding table.
I eventually want to be able to write code like this
order = Order.new
physical_item = PhysicalItem.new
virtual_item = VirtualItem.new

order.order_items << physical_item
order.order_items << virtual_item

puts order.order_items
# Should list out the physical item and then the virtual item.

It seems very simple in theory, but it doesn't look like there's much support for this structure in general. Anyone have any thoughts about implementing this in a postgresql database with ActiveRecord?
",['activerecord']
34303982,How to manage Session in Restful jersey?,"In my application I am validating the user locally by matching the password and email id in local database and creating a session key using the JAVA UUID generator and storing it in Guava Cache and checking it with every request come from user.Now I am also validating the user by the  OpenID authentication using the front end now i want to manage session for users those are login using  OpenID
using the same approach.
In back-end i am using the restful jersey service,hibernate,PostgreSQL and front end is HTML5  and may be android client and so on.
Now I am stuck that when user is validating through front end using the OpenID how I maintain the session using above approach ?
",['rest']
16734363,"PHP, iOS  Android RESTful best practise","I am planning on developing a RESTful web application in PHP, and then use the same web services with iOS and Android apps. On the web application login, I am going to send the user credentials via ajax amp; HTTPS in the authentication header. 

Is this really secure?
Are this credentials going to be remembered in every new request I make and page in the domain I visit?
Do I have to configure anything on my Apache server? 
Where do I have to redirect to the login page if the credentials are wrong or aren't set? 

I plan on checking in my PHP code if the user exists, and if not, return an error code but this won't redirect to the login page. I am a bit lost. 
",['rest']
5361918,encryption algorithms,"I have a P2P backup network where a peer can store data and retrieve it later from another peer. What are the best security measures I can take so that data wont be read by other users which have not created it? I was going to use single key encryption and digital signatures but I am sure whether this is the correct approach.
Thanks in advance for your help 
",['p2p']
3852080,Best way to protect a REST service that will be accessed by mobile and desktop applications,"I have REST services that I was planning on protecting with Windows Integrated Authentication (NTLM), as it should only be accessible to those internal to the company, and it will end up being on a website that is accessible by the public.
But, then I thought about mobile applications and I realized that Android, for example, won't be able to pass the credentials needed, so now I am stuck on how to protect it.
This is written in WCF 4.0, and my thought was to get the credentials, then determine who the user is and then check if they can use the GET request and see the data.
I don't want to force the user to pass passwords, as this will then be in the IIS log, and so is a security hole.
My present concern is for the GET request, as POST will be handled by the same method I expect.
One solution, which I don't think is a good option, would be to have them log into Sharepoint, then accept only forwarded reqests from Sharepoint.
Another approach would be to put my SSO solution in front of these services, which would then force people to log in if they don't have credentials, so the authentication would be done by SSO, and since the web service directory could be a subdirectory of the main SSO page, then I could decrypt the cookie and get the username that way, but, that would be annoying for the mobile users, which would include the senior management.
So, what is a way to secure a REST service so that it is known whom is making the request so that authorization decisions can be made, and will work for iphones, android and blackberry smartphones.
",['rest']
34640611,How do I use an API Gateway in conjunction with microservices and JWTs?,"Afternoon y'all,
Just looking for someone to double check my work. Is the below an effective way to secure microservices?
Premise
Breaking up our monolithic application and monolithic Partner API into microservices oriented around specific business functions. They'll most likely be small expressjs applications running in a docker container, on elastic beanstalk, who knows. They'll live somewhere )
I'm looking into either standing up Kong as my API Gateway or using AWS API Gateway to encapsulate the details of my microservices. Also, it just feels good. 
The JWT plugin for Kong will verify the signature of the JWT and then pass the customer_id along in the header to the microservice. I should also mention that we have 3rd party developers that will be partaking in the integration fun as well. Here's a basic sketch of what I see happening
Implementation

Generate consumers for each platform and 3rd party developer we have. (Web app, mobile app, and the current integration partners we have. Note I'm not looking to create consumers for every user that logs in. While certainly more secure, this adds a lot of work. Also, if you figure out how to get the secret out of my API Gateway I clearly have other issues)
Let Kong verify the request for me. Kind of like a bouncer at the door, there's no authorization, just authentication. 
I don't need to know that the token is valid once it gets to the microservice, I can just use some middleware to decode it and use custom logic to decide if this user really should be doing whatever is they're trying to do. 

Extra Stuff

There's a nice access control plugin for Kong. Our application and mobile app would run with God privileges, but I could definitely lock down the developers to specific routes and methods. 
Revoking 3rd party access will be easy, revoking end users access won't be so simple unless I'm willing to invalidate all JWTs at once by generating a new secret. Perhaps I can limit token time to 10 minutes or so and make our applications check if they're expired, get a new token, and then get on with the original request. This way I can flag them in the database or something and not let the JWT be generated. 
SSL used everywhere, JWT is stored in an SSL only cookie in the web browser and there's no sensitive information stored in any of the claims. 

Thanks guys. 
",['microservices']
43956037,Django REST auth - users stored in external service,"I've been wondering the best way to handle the case where a Django is used in a service-oriented architecture, so individual Django applications do not maintain their own user stores. One service maintains the user store, and others must call it in order to retrieve user information. 
So far example, here is how I was thinking of building a custom authentication class in Django REST to handle this
class SOAAuthentication(authentication.BaseAuthentication)

    def authenticate(self, request)
        token = request.get_token_from_auth_header()

        if not remote_auth_service.is_token_valid(token)
            raise AuthFailed('Token is invalid')

        user_properties = remote_users_service.get_user(token)
        # user_properties is a dict of properties

        if not user_properties
            raise AuthFailed('User does not exist.')

        user = MyCustomUserClass(**user_properties)
        return (user, 'soa')

So no user info would get persisted in the Django application's database, and permission classes could interrogate the instance of MyCustomUserClass to figure out what groups a user belongs to. 
Would this approach work for simple group-based authorization? My think is that I don't need object-level permissions, so there's no need to create rows for my users in the Django database. 
",['soa']
14710068,Yii saving many MANY_MANY relationships,"Info
I'm having some issues with saving a model that has many MANY_MANY relationships. I have a page where you can add product attributes as well as product attribute levels. What I now want to do is add support for this on the update-page on the product. So when I enter the update-page, I will see all product attributes, and for each product attribute, there will be a drop-down list with the related product attribute levels for that specific product attribute.
Database
Product

id
etc

ProductAttribute

id
etc

ProductAttributeLevel

id
product_attribute_id ## FK
etc

ProductProductAttributeLevel -- This is the pivot-table

product_id ## FK PK
product_attribute_level_id ## FK PK

ActiveRecords
Product
class Product extends S360ActiveRecord {

    public function behaviors() {
        return array('CAdvancedArBehavior' => array(
            'class' => 'application.extensions.CAdvancedArBehavior')
        );
    }

    public function rules() {
        return array(
            array('attributeLevels', 'safe'),
        );
    }

    public function relations() {
        return array(
            'attributeLevels' => array(selfMANY_MANY,
                'ProductAttributeLevel',
                'product_product_attribute_level(product_id,product_attribute_level_id)'
            ),
        );
    }

}

ProductAttribute
class ProductAttribute extends S360ActiveRecord {

    public function relations() {
        return array(
            'levels' => array(selfHAS_MANY, 'ProductAttributeLevel', 'product_attribute_id'),
        );
    }

}

ProductAttributeLevel
class ProductAttributeLevel extends S360ActiveRecord {

    public function relations() {
        return array(
            'productAttribute' => array(selfBELONGS_TO, 'ProductAttribute', 'product_attribute_id'),
            'products' => array(selfMANY_MANY, 'Product', 'product_product_attribute_level(product_attribute_level_id,product_id)'),
        );
    }
}

ProductProductAttributeLevel
class ProductProductAttributeLevel extends S360ActiveRecord {

    public function relations()
    {
        return array(
            'productAttributeLevel' => array(selfBELONGS_TO, 'ProductAttributeLevel', 'product_attribute_level_id'),
            'product' => array(selfBELONGS_TO, 'Product', 'product_id'),
        );
    }

}

My ProductController method that updates a product looks like this
public function actionUpdate($id) {

    $model = $this->loadModel($id);
    $this->performAjaxValidation($model);

    if (isset($_POST['Product'])) {
        $model->attributes = $_POST['Product'];

        if ($model->save()) {
            $this->redirect(array('index'));
        }
    }

  $this->render('update', array('model' => $model));

}

Relevant part in my form-view
beginWidget('S360ActiveForm', array(
        'id' => 'product-form',
        'enableAjaxValidation' => true,
    )); 
?>

findAllByAttributes(array('survey_id' => $model->parent_id)); if ($attributes) ?>

    dropDownListRow($model, 'attributeLevels',
            CMapmergeArray(
                array('0' => Yiit('backend','No attribute level')),
                CHtmllistData($attribute->levels, 'id', 'label')
            ),
            array('class' => 'span5')
        );
    }?>



Issue
I get this CDBException

CDbCommand failed to execute the SQL statement SQLSTATE[23000] Integrity constraint violation 1452 Cannot add or update a child row a foreign key constraint fails (product_product_attribute_level, CONSTRAINT product_product_attribute_level_ibfk_2 FOREIGN KEY (product_attribute_level_id) REFERENCES product_attribute_level (id) ON DELE). The SQL statement executed was insert into product_product_attribute_level (product_id, product_attribute_level_id) values ('5', '0')

Problem is though that product_attribute_level with id 0 does not exist, the id's starts at 1. How would I change it so that it inserts the correct id-number?
Example of what I want
Let's say I have 2 product attributes; Attribute1 and Attribute2.
Attribute1 have product attribute levels Attribute1_Level1 and Attribute1_Level2.
Attribute2 have product attribute levels Attribute2_Level1, Attribute2_Level2 and Attribute2_Level3.
When I go to my Product edit-/update -page, I want to see this
Attributes <URL>

Attribute2 Dropdown <URL>
The Product belongs to a Survey. The Product Attribute's belongs to a Survey as well so fetching all the Product Attributes that the Product can have is easy
$attributes = ProductAttributemodel()->findAllByAttributes(array('survey_id' => $product->survey_id));

After this I need to fetch all Product Attribute Levels that belongs to each attribute, which is quite easy as well
foreach ($attributes as $attribute) {

    echo $form->dropDownList($attribute, 'label',
        CHtmllistData($attribute->levels, 'id', 'label'),
        $htmlOptions
    );

}

The problem is how to connect it with the Product and have its $product->attributeLevels relationship update accordingly based on what I select from the different dropdowns. $product->attributeLevels should be a list of ProductAttributeLevel and should be stored via the table product_product_attribute_level.
",['activerecord']
35118390,How do I allow users to authenticate with my REST API?,"I am trying to create a REST API for my next project. I think I understand most of the concepts, but am a little unsure about security. Obviously security is the one thing you don't want to get wrong even from the first release of production code.
I understand that REST is stateless, so instead of having a user log in and their session be stored on the server and restarted whenever they make a request, they send the server their unique API key and the server authenticates them on every request.
So how does a user logging into a system look under the hood? Is it something like

The user enters their username and password
These are sent via POST (or PUT) to an API endpoint
If the credentials are valid, a unique API key is generated and returned to the client
If the credentials are not valid, an error is returned to the client

It is then the client's responsibility to store the API key and submit it with each request. This key is stored on the server in a database and used to identify the user and their permissions etc. on each request.
This sounds reasonable, but also breaks the true statelessness of the application because most requests require the initial make me an API key request to have been sent.
Thanks in advance for helping me understand!
",['rest']
47414830,How to query and persist static objects in MySQL Database with Spring Boot?,"I am working on a Restful service built with Java Spring and I have some issues modeling the data. I want to store shelfs with books. The books belong to a given category. I have a POST request to store shelfs to a mysql database (via service and CrudRepository). However I am not able to store more than one book of the same category. Here are my (simplified) entities.
A Shelf with an id and a collection of books.
@Entity
public class Shelf{
    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;
    @OneToMany(cascade = CascadeType.ALL, fetch = FetchType.EAGER, mappedBy = shelf)
    private List books= new ArrayList<>();
    ...
}

The class Book is defined as follows
@Entity
public class Book{

    @Id
    @GeneratedValue(strategy = GenerationType.AUTO)
    private Long id;

    @ManyToOne(cascade = CascadeType.ALL, fetch = FetchType.EAGER)
    @JoinColumn(name = category_id)
    private Category category;

    @OneToOne(fetch = FetchType.EAGER, cascade = CascadeType.ALL)
    @JsonIgnore
    private Shelf shelf;

Each book belongs to a category(e.g. thriller, fiction, etc.). Here is the category entity
@Entity
public class Category {

    private Long id;
    private String name;

And finally my Controller
@RestController
public class ShelfController {

    @Autowired
    private ShelfService shelfService;

    @PostMapping(/shelfs)
    public Shelf addShelf(@RequestBody Shelf shelf) {

        return shelfService.addShelf(shelf);
    }

Now here is my problem The categories will be given and there will be no option to change these, I would therefore like to have them stored in the database or hard code them as static objects. In the Post request for new shelfs I would like to provide only the category id and make the controller find the corresponding object itself.
What I did so far was to treat the categories as a usual Entity, so whenever I added a new shelf with books having a category_id, the category was created with the given id and an empty name. But as soon as I used the same category id again, the application threw a com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException Duplicate entry '1' for key 'PRIMARY' exception. I don't want the controller to create new category objects, but instead want it to fetch the corresponding objects from a service or a static Collection.
So my question is How can I achieve this?
Hints for solutions/tricks to improve the design are most welcome, I am new to the topic.
","['rest', 'mvc']"
27551109,"Entity Framework with 3-tier architecture, different entities across domains","I know the title sounds like a duplicate of quite a few existing posts, but I've read quite a few of them and my situation is actually quite different. I would really appreciate it if anyone experienced with Entity Framework could offer some advice on the best architecture for the following scenario.
I have a wpf application with a 3-tier layout, Data Access Layer, Business Logic Layer, and UI Presentation Layer. The UI uses MVVM. DAL uses Entity Framework. UI and Data Access Layer each have their own models, UIModel and DataModel.
The current design uses a global DbContext for Entity Framework across the application. For a simple update operation, an entity is retrieved from the database as a DataModel, converted into a GUIModel, wired to the ViewModel and View for updates, and converted back into a DataModel to update in the database. And here's the problem when the new DataModel is created from the conversion, it is no longer related to the original entity retrieved, and Entity Framework cannot perform the update because it now has two duplicate models of the same primary key attached to the same DbContext.
I did a little bit of research and found a couple of possible ways to fix this. One is to use a single model entity across all layers instead of separating GUIModel and DataModel, and break the global DbContext into unit of work. This seems to be a very common design, but my concerns with this approach is that the merge of GUIModel and DataModel violates the separation of responsibilities, and using unit of work required Business Layer to control the lifetime of DbContext, which also blurs the boundary between BLL and DAL.
The second alternative would be to use a local DbContext for every database query with a using block. This seems most memory efficient. But doing it this way makes lazy loading not possible, and eager loading all navigation properties in every query would likely affect performance. Also the short lived DbContexts require working completely in disconnected graph, which becomes quite complicated in terms of change tracking.
A third possibility would be to cache all original DataModels and update on those entities after the update.
I am new to Entity Framework and I'm sure there should be other ways to fix this issue too. I'll really appreciate it if anyone could offer some insights on the best way to approach this.
",['mvvm']
54244210,Sharing same identity between existing MVC website and ReactNative app,"Aim I have an existing ASP.NET MVC website built a couple of years ago, which I would like to share the identity management with a new ReactNative app that I am building.
I would like users to be able to log in to both web and app and have a seamless integration by using the same user on both interchangeably. It also should support login with Facebook and Google+ which the ASP.NET MVC website currently supports using the out of the box Oauth2 OWIN login.
To keep costs down I would like to utilise Azure Function for as much/all if possible of the calls used on the ReactNative app.
Problem
I am a bit stumped on how this is going to work, with it being so tied in with the ASP.NET MVC project, with all parts (login, registration, change password, forgotten password etc) is using the built in ASP.NET authentication methods using SignInManager etc.
Plan
My plan was to do the following, but I would be really appreciative of anyone who can give me any ideas, in particular.

Tell me of a better way to do this 
Tell me if/why I am being stupid/insecure with my current plan
Will this even work
Any other suggestions on how to solve the problem in a more elegant way

My plan is as follows

Use Azure Functions for everything, e.g. Login, Register etc, this making it scalable as well as very cheap and not requiring another server set up somewhere
Add a login azure function which takes a username and password, the function does a hash of the password provided and does a check against the database for the corresponding username, if the password matches then provide a JWT which will allow any further calls to pass this in as a bearer token for authenticated requests.
Add a register azure function, this will take in the usual details, username, email etc. The function will check the DB to see if a user already exists, if so throw an exception, if not it will manually add the record into the asp_users table, then send back a JWT with the token needed for any future authenticated requests.
With regards to the Facebook and Google+ authentications, I was planning on using their JavaScript SDKs to authenticate, then send up the access code provided to an azure function. This can then be used to query the Facebook/Google API's to get the email addresses, if the email address exists then give their details back in a JTW token, if not create the user and then send back the token. I don't know if this will work with the MVC setup however if the user then tries to login using the web?
All JTW tokens will hold the username of the user so that any actions taken can be audited/recorded against that user for the period the token is valid, or they log out and will require logging in again.

Thanks very much in advance, I have been scratching my head for nearly 2 months with this and have yet to make the plunge in actually doing the coding.  My aim was to get my app finished by Spring but need to figure out this crucial part before I can move any further.
Thanks so much in advance.
",['mvc']
24544707,"Rails polymorphic association, different options depending on type?","I'm building a diet analysis app in Rails 4.1. I have a model, FoodEntry, which at a simple level has a quantity value and references a Food and a Measure
class FoodEntry < ActiveRecordBase
  belongs_to food
  belongs_to measure
end

However I actually have two different types of measures, standard generic measures (cups, teaspoons, grams, etc.) and measures which are specific to a food (heads of broccoli, medium-sized bananas, large cans, etc.). Sounds like a case for a polymorphic association right? e.g.
class FoodEntry < ActiveRecordBase
  belongs_to food
  belongs_to measure, polymorphic true # Uses measure_id and measure_type columns
end

class StandardMeasure < ActiveRecordBase
  has_many food_entries, as measure
end

class FoodMeasure < ActiveRecordBase
  has_many food_entries, as measure
end

The thing is, the food-specific measures come from a legacy database dump. These records are uniquely identified by a combination of their food_id and description - they aren't supplied with a single-column primary key (description is not unique on its own because there are multiple foods with the same measure description but different numeric data). Because I'm importing to my Rails Postgres db, I'm able to add a surrogate primary key - the auto-incrementing integer id column that Rails expects. But I don't want to utilize this id as a reference in my FoodEntry model because it poses a pretty big challenge for keeping referential integrity intact when the (externally-supplied) data is updated and I have to reimport. Basically, those ids are completely subject to change, so I'd much rather reference the food_id and description directly.
Luckily it's not very difficult to do this in Rails by using a scope on the association
class FoodEntry < ActiveRecordBase
  belongs_to food
  belongs_to measure, ->(food_entry) { where(food_id food_entry.food_id) }, primary_key 'description', class_name 'FoodMeasure'
  # Or even           ->(food_entry) { food_entry.food.measures }, etc.
end

Which produces a perfectly acceptable query like this
> FoodEntry.first.measure
FoodMeasure Load (15.6ms)  SELECT  food_measures.* FROM food_measures  WHERE food_measures.description = $1 AND food_measures.food_id = '123' LIMIT 1  [[description, Broccoli head]]

Note that this assumes that measure_id is a string column in this case (because description is a string).
In contrast the StandardMeasure data is under my control and doesn't reference Foods, and so it makes perfect sense to simply reference the id column in that case.
So the crux of my issue is this I need a way for a FoodEntry to reference only one type of measure, as it would in the polymorphic association example I made above. However I don't know how I'd implement a polymorphic association with respect to my measure models because as it stands

an associated FoodMeasure needs to be referenced through a scope, while a StandardMeasure doesn't.
an associated FoodMeasure needs to be referenced by a string, while a StandardMeasure is referenced by an integer (and the columns being referenced have different names).

How do I reconcile these issues?

Edit I think I should explain why I don't want to use the autonumber id on FoodMeasures as my foreign key in FoodEntries. When the data set is updated, my plan was to

Rename the current food_measures table to retired_food_measures (or whatever).
Import the new set of data into a new food_measures table (with a new set of autonumber ids).
Run a join between these two tables, then delete any common records in retired_food_measures, so it just has the retired records.

If I'm referencing those measures by food_id and description, that way I get the benefit that food entries automatically refer to the new records, and therefore any updated numeric data for a given measure. And I can instruct my application to go searching in the retired_food_measures table if a referenced measure can't be found in the new one.
This is why I think using the id column would make things more complicated, in order to receive the same benefits I'd have to ensure that every updated record received the same id as the old one, every new record received a new not-used-before id, and that any retired id is never used again.
There's also one other reason I don't want to do this ordering. The records in the dump are ordered first by food_id, however the measures for any given food_id are in a non-alphabetical but nevertheless logical order I'd like to retain. The id column can serve this purpose elegantly (because ids are assigned in row order on import), but I lose this benefit the moment the ids start getting messed around with.
So yeah I'm sure I could implement solutions to these problems, but I'm not sure it would be worth the benefit?
",['activerecord']
8602387,Linq-to-SQL and WCF service - data transfer objects,"I'm curious about best practice when developing n-tier application with Linq-to-SQL and WCF service. 
In particular, I'm interested, for example, how to return to presentation tier data from two related tables. Suppose next situation (much simplified)
Database has tables 

Orders (id, OrderName) 
OrderDetails (id, orderid, DetailName)

Middle tier has CRUD methods for OrderDetails. So, I need to have way to rebuild entity for attaching to the context for update or insert when it come back from presentation layer.
In presentation layer I need to display list of OrderDetails with corresponding OrderName from the parent table.
There are two approach for classes, that returned from the service

Use DTO custom class that will encapsulate data from both tables and projection
class OrderDetailDTO
{
  public int Id { get; set; }
  public string DetailName { get; set; }
  public string OrderName { get; set; }
}
IEnumerable GetOrderDetails()
{
  var db = new LinqDataContext();
  return (from od in db.OrderDetails
          select new OrderDetailDTO
          {
            Id = od.id,
            DetailName = od.DetailName,
            OrderName = od.Order.OrderName
          }).ToList();
}

Cons need to assign every field which is important for presentation layer in both ways (when returning data and when creating new entity for attaching to context, when data comes back from presentation layer)
Use customized Linq-to-SQL entity partial class
partial class OrderDetail
{
  [DataMember]
  public string OrderName
  {
    get
    {
      return this.Order.OrderName    // return value from related entity
    }
    set {}
  }
}

IEnumerable GetOrderDetails()
{
  var db = new LinqDataContext();
  var loadOptions = new DataLoadOptions();
  loadOptions.LoadWith(item => item.Order);
  db.LoadOptions = options;
  return (from od in db.OrderDetails
          select od).ToList();
}


Cons database query will include all columns from Orders table, Linq-to-SQL will materialize whole Order entity, although I need only one field from it.
Sorry for such long story. May be I missed something? Will appreciate any suggestions.
",['dto']
18434314,Should an API consume itself or call the database directly for other resources?,"
This question is an extension although separate of this question posted earlier.

So we have our basic example of a garage has multiple cars so our endpoints are
/garages
/garages/{id}
/garages/{id}/cars
/garages/{id}/cars/{id}
/cars
/cars/{id}

We can get all cars from multiple garages with /cars?garage[id]=1,2,3
which is cool. But what I am wondering now is on the inside of the API.
There are two ways I can think of to do this
Direct filtering in the /cars endpoint
This means that we in the query to get the cars we do some joins and add in some where's.
The benefit of this approach is that we will end up with the minimum amount of queries.
The con of this approach is that we end up maintaining the garages resource in two places. any time the garage gets a new property we must now support this in the cars endpoint too.
Calling the /garages endpoint from the /cars endpoint
This means we call the /garages endpoint from within the /cars endpoint with /garages returning the id of all cars from the matching garages. We then proceed to get the cars from back within the /cars endpoint.
The benefit of this method is that the resources are self contained.
The con of this approach is that we are going to end up with multiple calls to the database. Also passing around the authentication details could get cumbersome (Let's assume Oauth 2.0)
So what is the most appropriate way to do this? I am leaning towards the second method however I am concerned that this could become a real hassle if we want to do some more advanced queries.
",['rest']
6903515,How to encapsulate web2py business logic?,"I just found web2py a couple days ago, and have been reading the documentation and through the source of a few example applications. I want to start programming more in Python. It seems that my take on MVC is a little skewed from theirs [web2py community]. 
After learning and working with PHP (and the Kohana framework), I'm used to the thin controller - fat model principle, where all business logic is placed in the model and the controller does nothing more than delegate what methods to perform on the model, and then passes data onto the view for rendering. However, it seems that 99% of the applications I've seen for web2py have fat controllers (putting all business logic in the actions), and the models are nothing more than table/constraint definitions.
I'm pretty well set on my view of a model, and I would rather put the business logic in the models (for re-usability and DRY code) but I haven't seen any code online that does this, although, to be fair, I haven't found an ample amount of applications. Can somebody point me in the right direction.
To be clear, I would like to make my models actual classes and encapsulate all business logic and database interactions into explicit methods. Something along the lines of...
class Article(object)
    def get_article(self, id)
        # Retrieve article by id, using db instance
        pass
    def get_latest_articles(self, limit)
        # Retrieve latest articles
        pass
    def get_hot_articles(self, limit)
        # Retrieve hot articles, based on algorithm for hot
        pass
    def create_article(self, data)
        # Insert article
        pass
    def define_tables(self)
        # Define schema the web2py way
        pass

I haven't found the right way to do this.
I'm not very well rehearsed on web2py, but I know there are a lot of features. The DAL, for instance, seems to be a very powerful feature which is tightly integrated with other helpers. I wonder if splitting my business logic as stated above would limit any of these features?
",['mvc']
28879185,Spring Security with JDBC Annotation only,"I am trying to create a Spring Boot Application using the Spring Security. I took the following example from <URL> They use an In Memory Authentification. I want to do the same but use a JDBC-Authentification.
Here is my WebSecurityConfig class
package hello;

import org.springframework.beans.abstract-abstract-factory.annotation.Autowired;
import org.springframework.context.annotation.Configuration;
import org.springframework.jdbc.datasource.DriverManagerDataSource;
import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;
import org.springframework.security.config.annotation.web.builders.HttpSecurity;
import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;
import org.springframework.security.config.annotation.web.servlet.configuration.EnableWebMvcSecurity;

@Configuration
@EnableWebMvcSecurity
public class WebSecurityConfig extends WebSecurityConfigurerAdapter {
    @Override
    protected void configure(HttpSecurity <URL> throws Exception {
        http
            .authorizeRequests()
                .antMatchers(/, /home).permitAll()
                .anyRequest().authenticated()
                .and()
            .formLogin()
                .loginPage(/login)
                .permitAll()
                .and()
            .logout()
                .permitAll();
    }

    @Autowired
    public void configureGlobal(AuthenticationManagerBuilder auth) throws Exception {

        DriverManagerDataSource dataSource = new DriverManagerDataSource();
        dataSource.setDriverClassName(com.mysql.jdbc.Driver);
        dataSource.setUrl(jdbcmysql//localhost3306/test);
        dataSource.setUsername(root);
        dataSource.setPassword(root);

        auth
            .jdbcAuthentication().dataSource(dataSource)
                .usersByUsernameQuery(select * from users where username=?)
                .authoritiesByUsernameQuery(select * from user_roles where username=?);
    }
}

I also set up a MySQL Database test and two tables users and user_roles.
When I run the application and try to sign in I dont't get any Exceptions, but the application somehow can't find the user. 
Can someone help me? What am I doing wrong?
Login page


    
        Spring Security Example 
    
    
        
            Invalid username and password.
        
        
            You have been logged out.
        
        
             User Name   
             Password  
            
        
    


pom.xml


    4.0.0

    org.springframework
    gs-securing-web
    0.1.0

    
        org.springframework.boot
        spring-boot-starter-parent
        1.2.2.RELEASE
    

    
        
            org.springframework.boot
            spring-boot-starter-thymeleaf
        
        
        
            org.springframework.boot
            spring-boot-starter-security
        
        

        
        
            org.springframework
            spring-jdbc
            3.2.8.RELEASE
        

        
        
            mysql
            mysql-connector-java
        
    


    
        
            
                org.springframework.boot
                spring-boot-maven-plugin
            
        
    



",['mvc']
28497835,Building A Social Network,"So, I'm starting out building a social network web app. I'm looking into how to fit the parts of my stack together and I'm looking for some guidance about what various frameworks will allow me to do. My current stack idea is to have

Firebase JSON API serving user, post, comment, and all the other data
EmberFire to plug that API into EmberJS
EmberJS my front-end MVC (because I'm new to MVC and Ember seems the most accessible)

What I'm stumbling on at the moment is how I'm going to implement users with this stack. I've looked at basic authentication stuff but I haven't found anything that would allow me to allow certain actions and views for certain users and not others - the basics of a social network really.
Is it sensible to be doing this stuff in front-end MVC? If so what should I be using to do authentication/personalisation? If not, should I just be doing a PHP/SQL setup? I'd rather avoid that because my skills are all front-end. 
",['mvc']
33434489,How to to increase performance in java web app using Singleton,"I use singleton to increase response for database connection.
But when there is many users that which send request in same time, instances of one connection make a bottle neck, So I use another approach in getInstace() method 
public class jjDatabaseWeb {

    private static final DatabaseType dbType = DatabaseType.MySql;
    private static String password;
    private ResultSet resultSet;
    private static String serverHost = 127.0.0.1; //localhost;
    private static String port = 3306;
    private static String databaseName = db_university;
    static String url2;

    private Connection connection;
    private static jjDatabaseWeb accessor;
    private static jjDatabaseWeb accessor2;
    private static jjDatabaseWeb accessor3;
    private static jjDatabaseWeb accessor4;
    private static jjDatabaseWeb accessor5;
    private static jjDatabaseWeb accessor6;
    private static jjDatabaseWeb accessor7;
    private static jjDatabaseWeb accessor8;
    private static jjDatabaseWeb accessor9;
    private static jjDatabaseWeb accessor10;
    private static int counter = 0;
    private static int counter2 = 0;

    private jjDatabaseWeb() throws ClassNotFoundException, SQLException {
        Class.forName(com.mysql.jdbc.Driver);
        connection = DriverManager.getConnection(jdbcmysql//localhost3306/db_university?characterSetResults=UTF-8amp;characterEncoding=UTF-8amp;useUnicode=yes, root, m123456);        
        //++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
        System.out.println(database driver name is ok);
    }


    public static synchronized jjDatabaseWeb getInstance() throws SQLException, ClassNotFoundException {
        counter++;
        System.out.println(+++++=====>>>> number of connection user + counter);
        if (accessor == null) {
            System.out.println(############################################);
            System.out.println(NEW DB CONNECTION 1 );
            System.out.println(############################################);
            accessor = new jjDatabaseWeb();
        }
        if (counter > 7) {
            System.out.println(------------------------------- + counter2);
            counter2++;
            if (counter2 % 10 == 1) {
                if (accessor2 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 2);
                    System.out.println(############################################);
                    accessor2 = new jjDatabaseWeb();
                }
                return accessor2;
            }
            if (counter2 % 10 == 2) {
                if (accessor3 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 3);
                    System.out.println(############################################);
                    accessor3 = new jjDatabaseWeb();
                }
                return accessor3;
            }
            if (counter2 % 10 == 3) {
                if (accessor4 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 4);
                    System.out.println(############################################);
                    accessor4 = new jjDatabaseWeb();
                }
                return accessor4;
            }
            if (counter2 % 10 == 4) {
                if (accessor5 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 5);
                    System.out.println(############################################);
                    accessor5 = new jjDatabaseWeb();
                }
                return accessor5;
            }
            if (counter2 % 10 == 5) {
                if (accessor6 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 6);
                    System.out.println(############################################);
                    accessor6 = new jjDatabaseWeb();
                }
                return accessor6;
            }
            if (counter2 % 10 == 6) {
                if (accessor7 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 7);
                    System.out.println(############################################);
                    accessor7 = new jjDatabaseWeb();
                }
                return accessor7;
            }
            if (counter2 % 10 == 7) {
                if (accessor8 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 8);
                    System.out.println(############################################);
                    accessor8 = new jjDatabaseWeb();
                }
                return accessor8;
            }
            if (counter2 % 10 == 8) {
                if (accessor9 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 9);
                    System.out.println(############################################);
                    accessor9 = new jjDatabaseWeb();
                }
                return accessor9;
            }
            if (counter2 % 10 == 9) {
                if (accessor10 == null) {
                    System.out.println(############################################);
                    System.out.println(NEW DB CONNECTION 10);
                    System.out.println(############################################);
                    accessor10 = new jjDatabaseWeb();
                }
                return accessor10;
            }
        }
        counter2 = 0;
        return accessor;
    }
}

I never closed connection And use singleton,
it has some benefit.

If there was created connection,new connection dose not makes, so fetching data is faster(making connection is time consuming ) 
In non busy time we have one connection is single tone mode and if there is max 7 request concurrent the program get instance of one connection.
In busy time when there is many requests waited for one connection, it make 9 other connection and share new requests between them.

I test it in wrong condition, and send 40 request in one second from 3 different browser to one method and it takes 2 minutes, but when i use only singleton it takes about 6 minutes.
But when i repeat this test some error occurred for some requests like Heap space error and Java invocation target exception.
note that in output i saw counter=28 (that means there was 28,27 in peak  task waited for connection)
I have not problem for first time running of batch requests , but when i repeat tis test it has some error reason of heap space lake.
",['singleton']
36431145,What is the best way to access Rest services that secured with OAuth security?,"I want to access REST web services written by other vendors. But the problem is the OAuth security. I got username, password, consumer key and consumer secret from them. 
First I call to a service to get refresh token. This is the response
{
   scope PRODUCTION,
   token_type bearer,
   expires_in 3148,
   refresh_token 315381713fc905a8c5f586d5145bd84,
   access_token 46ed281862dc48d2d46372fc2e84e5
}

Got the refresh_token with expire time. Must I keep this token in database or memory until it expires and only call this service again to get refresh token after that refresh token expires.
I don't know how to keep this refresh and access tokens in my side(Database or Memory). Please help me to find a better way to access this services.
",['rest']
4981045,How to design authentication and authorization system for REST backend / Ajax front End Application,"I am starting a new project where we are planing to build a restful back end and an AJAX font end. I am approaching the problem by focusing on Identifying all the resources that I have and what the various HTTP verbs will do them, their URI and the JSON representations of those resources. 
I am looking for the best design for securing the backend. Here is the list of designs I have considered. I am looking for alternative designs not listed below, and pros, cons recommendations. The system will be implemented with Spring 3.0 and possibly Spring Security 3.0, SSL will be used for many parts of the system but not for all of them, so some requests may come on SSL and some might not. 
Option 1 Use the HTTP session
Show a standard login screen, create a server side session and let tomcat send back a jsessionid cookie and have the ajax client include the JSESSIONID cookie on every XHR request. This options just feels like it's the wrong approach for the following reasons. 

The connection becomes statefull which is against the rules of REST
I want to be able to split the bakcend into multiple seperate WAR files which means i could have multiple HTTP sessions on the backend, if that is the case then this approach does not work. While I don't need the ability to split the backend into multiple apps today, I would prefer a design that allows for that possibility.

Option 2 Find an open source Java based security library that does this
Other than Spring security I have not found any other Java libraries, any recommendations are highly appreciated.
Option 3 Try to use an existing protocol like OAuth 
In my very brief look at OAuth it seems that it is designed for authentication across sites where each site has it's own user database. In this system i want a global user database shared across all the backend ajax services.
Option 4 Use SAML and Shiboleth 
This options seems over kill and hugely complex to setup and maintain. 
Option 5 Send the username and password with every request
This requires that user sends their username and password with every request, which means that the front end AJAX app must store the username and password as a JavaScript object and if the user navigates away from the page then back the username/password combo will be gone and the user might be forced to log in again. I don't want the front end to try and put the username and password into cookie as that would comprise security. 
Option 6 Implement my own authentication / Authorization protocol 
Create a REST service that users can present their username/password combination to and then get back and security token, which they must send back to the service with every request. The security token would be digitally signed by the service and would have an expiry time. The token would be only good for most operations high security operations would require a new login screen as port of confirming the operation. 
Problem with this approach is I have to invent yet another security protocol which seems like a total waste of time.
I am sure I am not the only person up against this problem, I hope the stack overflow community can point to some options and tools that I have not found yet.
",['rest']
11943933,Using two different DB (MySQL and Postgres) for a single Rails App,"I have a rails app that uses MySQL for authentication and storing models. I currently am thinking of using PostgreSQL for analytics (by taking advantage of its special data types like arrays and KV pairs). I am just wondering how I would be able to have two types of databases (1 for models and authentication and 1 for analytics) when trying to save records using ActiveRecord. I want to save the model for analytics in Postgres and other models in MySQL.
",['activerecord']
25152900,ASP.Net Identity using a custom auth provider/service,"I am currently developing an ASP.Net MVC web application that requires username and password authentication.  I started looking into using ASP.Net Identity for this however I have a very important requirement, the requirement is that the web application itself has no direct access to any databases, all DB Access is to be exposed to the application via an internal REST service.  This is due to certain security polices we follow.
I realise that ASP.Net identity is capable of supporting external authentication methods but my question is split into 2 parts.
1) How would I configure ASP.Net Identity to use my custom REST service for authentication?
2) How would I go about developing a service that can be used by Identity for authentication ? (what would need to be returned from the service to ASP.Net Identity)
Any help on this would be most appreciated.
",['rest']
7988447,combining spring security 3 with jersey rest api,"I have a scenario where I am trying to combine spring security with jersey for my REST API. 
My need is rather complicated (I think) and it is as follows
Spring security is being used to intercept urls and forcing basic authentication in order to access a REST resource. This seems to be ok as I am using http client to test this.
However what I want to do is somehow access the User object that is loaded to check some additional permissions that hang off the user (a map object with boolean flags to indicate if object properties are visible or not). The code that does the loading works, but after spring authenticates how do I then access the User object in the actual REST Resource method itself?? Is this possible?
So the steps are
1) Client makes a REST API call
2) Spring intercepts URL checks username and password supplied in the http header
3) The rest resource method is then accessed if valid credentials are present
But before step 3, I want to somehow pass on the loaded User object to the actual Resource method itself so I can further apply some logic to restrict what the user can see based on the permissions that I have loaded??? Is this possible? I think I have seen some code somewhere that checks for User Roles before a method is accessed using Spring and REST but if anyone has any links or ideas that would be excellent.
Please help if you can. thank you so much.
",['rest']
1790020,Pitfalls of true client-server architecture in web applications?,"I've been researching on building web applications in a true client-server fashion.  
This type of architecture basically consists of   

A thin server, merely a headless api that 

handles security concerns
processes core business logic
provides data persistence  

A fat client, with a desktop-like design that 

caches data, and makes offline use possible
has gui-templating and rendering capabilities
holds and processes non-critical business logic  


However, at first sight such an architecture wouldn't play nice with how the web works today 

poor or no possible fallback when javascript isn't available (2% of user-agents nowadays, am I right ?)

accessibility concerns (I'm kinda clueless here)
SEO concerns, cloacking is an option but that means one should provide some server-side html rendering, and making that content relevent could be tricky


Anything else I'm missing ?
Which approach would you take to work around those issues ?
",['client-server']
4429684,Rails 3 alias_attribute and Unkown column error,"I am using Devise for authentication, so I've aliased a few columns in my legacy database to accommodate it as follows
class User < ActiveRecordBase

  set_table_name 'my_legacy_user_table'
  set_primary_key 'UserId'
  alias_attribute id, UserId
  alias_attribute username, LoginId
  alias_attribute encrypted_password, PasswordSHA1Hash
  alias_attribute first_name, Name
  alias_attribute last_name, Surname

  devise database_authenticatable, authentication_keys => [username]

  attr_accessible username, password, password_confirmation

  def password_salt=(password_salt)
  end

  def password_salt
  end

  def password_digest(password)
    self.class.encryptor_class.digest(password)
  end

end

When I post to my /users/sign_in form, I get the following exception
Mysql2Error Unknown column 'my_legacy_user_table.username' in 'where clause' SELECT `kms_User`.* FROM `my_legacy_user_table` WHERE (`my_legacy_user_table`.`username` = 'mrichman') LIMIT 1

I suppose I was under the assumption that alias_attribute would instruct ActiveRecord to use the real column name (UserId) and not the alias (username). What am I doing wrong?
",['activerecord']
11908163,What is the Best way to create a secure REST API with Zend?,"I have been looking on a lot of questions about REST API and security and found some interesting informations but there is still one thing I don't understand.
So, I have a REST API developped with Zend Framework with basic authentication over an <URL> channel (so if I understoud what I have read, the login/password are encrypted when they are sent).
The purpose of this API is to be called by Android/iPhones apps and will only be available to people who have a login and a password
SO, currently, to call the API, the login and password are always sent with the call and so, I check them at every call (the result is it makes a call to the database just for authentication at each call to the API).
Is there some kind of session management (as in web developpement) to avoid that?
Thank,
",['rest']
40854777,Determine the HTTP verb of an endpoint based on the URL,"For a project I've worked on in the past, we store a URL in a field in the app's database, so that when a user has to step away, power down their system, or whatever, that they can resume working on something by opening the affected record.  This URL refers to a Controller method defined in our exposed Web API for the application in question, with the requisite parameters provided to open the affected record.
There's an issue, where we're noting that - very rarely - the endpoint that's being stored refers to a POST endpoint, not a GET endpoint.  When this condition is triggered, we get an exception like the following
The parameters dictionary contains a null entry for parameter 'MyParameter' of non-nullable type 'System.Int32' for method 'System.Web.Mvc.ActionResult SomeEndpoint(Int32, Int32)' in 'MyApplication'.  An optional parameter must be a reference type, a nullable type, or be declared as an optional parameter.
Parameter name parameters

We know what we want to do to solve the problem we want to scan the URL and determine the verb.  If the verb is POST, we want to redirect to a specific URL, to prevent our application from getting stuck in this error-prone state.  We want to institute this redirect to occur on the server side, not only for security reasons, but because it's simply not a client code concern.
I've done a cursory Google search on this topic, and have found no articles that talk about ways to reverse-engineer the verb of a given URL.
Question Is there any way, given some URL, to determine what HTTP verb is being referred to in C#?
If there is not - something I would expect, most likely for security reasons - is there any advice on techniques that avoid this sort of problem?  Prior to posting this question, I have done a code audit of the affected application, and have not been able to easily reproduce the condition leading to this question (storing a POST URL in our database), and have found no logic that should lead to a POST URL being saved to our database.
",['rest']
25624368,How to grant access to specific resources?,"The problem
I have a set of informations that some users have to access them through my Web Application. Let's say that I have resources A, B, C of the same type T and the users are X, Y, Z. The business states that a user can access this resources like in the table below.
User    ->  Resources 
X       ->  A
Y       ->  A C
Z       ->  A B C
A real world example will be something like this

User X can see all Hypermarkets from L.A.
User Y can see all Hypermarkets from L.A. and Chicago
User Z can see all Hypermarkets from L.A., Chicago and N.Y.

Another thing to mention is that at any time, to user X could be granted access to see the Hypermarkets from N.Y. too.
The question
How do I implement the authorization system so that it allows me to grant access to a user to a specific set of resources?
My first ideas
Since I am going to use ASP.NET MVC and Web API, my first thoughts were to use Role-Based Authorization. After that, I found this article on how to extend the concept of Role-Based Authorization to a so called Activity-Based Authorization.
But, even this solution is not right for my business because in my code I must have one function called GetAllHypermarkets with no parameters, that will return all the Hypermarkets that the user is allowed to see. For example, for user X it will return only Hypermarkets from L.A. How can I achieve this?
",['rest']
34272521,The ADO.NET provider with invariant name 'System.Data.SqlServerCe.4.0' is either not registered,"We're trying to deploy our MVC solution to a customer, but they're getting an error while trying to log in.
I have searched for similar issues, but have not yet found a solution.

It does have SQL CE 4.0 installed.
I have checked app.config, but it seems fine. It has the lines as suggested here



Could someone shed some light on the following error log?

2015-10-05 095954,259 [  34] FATAL - [] Exception caught
  System.Data.DataException An exception occurred while initializing the database. See the InnerException for details. ---> System.Data.Entity.Core.MetadataException Schema specified is not valid. Errors 
  (0,0)  error 0175 The ADO.NET provider with invariant name 'System.Data.SqlServerCe.4.0' is either not registered in the machine or application config file, or could not be loaded. See the inner exception for details.
     at System.Data.Entity.Core.Metadata.Edm.StoreItemCollection.Loader.ThrowOnNonWarningErrors()
     at System.Data.Entity.Core.Metadata.Edm.StoreItemCollection.Init(IEnumerable1 xmlReaders, IEnumerable1 filePaths, Boolean throwOnError, IDbDependencyResolver resolver, DbProviderManifestamp; providerManifest, DbProviderabstract-abstract-factoryamp; providerabstract-abstract-factory, Stringamp; providerInvariantName, Stringamp; providerManifestToken, Memoizer2amp; cachedCTypeFunction)
     at System.Data.Entity.Core.Metadata.Edm.StoreItemCollection..ctor(IEnumerable1 xmlReaders)
     at System.Data.Entity.Utilities.XDocumentExtensions.GetStorageMappingItemCollection(XDocument model, DbProviderInfoamp; providerInfo)
     at System.Data.Entity.Migrations.Infrastructure.EdmModelDiffer.Diff(XDocument sourceModel, XDocument targetModel, Lazy1 modificationCommandTreeGenerator, MigrationSqlGenerator migrationSqlGenerator, String sourceModelVersion, String targetModelVersion)
     at System.Data.Entity.Migrations.DbMigrator.IsModelOutOfDate(XDocument model, DbMigration lastMigration)
     at System.Data.Entity.Migrations.DbMigrator.Upgrade(IEnumerable1 pendingMigrations, String targetMigrationId, String lastMigrationId)
     at System.Data.Entity.Migrations.DbMigrator.EnsureDatabaseExists(Action mustSucceedToKeepDatabase)
     at System.Data.Entity.MigrateDatabaseToLatestVersion2.InitializeDatabase(TContext context)
     at System.Data.Entity.Internal.InternalContext.PerformInitializationAction(Action action)
     --- End of inner exception stack trace ---
     at System.Data.Entity.Internal.InternalContext.PerformInitializationAction(Action action)
     at System.Data.Entity.Internal.InternalContext.PerformDatabaseInitialization()
     at System.Data.Entity.Internal.RetryAction1.PerformAction(TInput input)
     at System.Data.Entity.Internal.LazyInternalContext.InitializeDatabaseAction(Action1 action)
     at System.Data.Entity.Internal.InternalContext.GetEntitySetAndBaseTypeForType(Type entityType)
     at System.Data.Entity.Internal.Linq.InternalSet1.Initialize()
     at System.Data.Entity.Internal.Linq.InternalSet1.get_InternalContext()
     at System.Data.Entity.Infrastructure.DbQuery1.System.Linq.IQueryable.get_Provider()
     at System.Linq.Queryable.FirstOrDefault[TSource](IQueryable1 source, Expression1 predicate)
     at TWP.Areas.Core.Models.Authorization.DatabaseMembershipProvider.ValidateUser(String userName, String password)
     at TWP.Areas.Core.Models.Account.AccountProvider.Logon(TwpMembershipProvider membership, LogOnViewModel model)
     at TWP.Areas.Core.Controllers.AccountController.LogOn(LogOnViewModel model, String returnUrl)
     at lambda_method(Closure , ControllerBase , Object[] )
     at System.Web.Mvc.ReflectedActionDescriptor.Execute(ControllerContext controllerContext, IDictionary2 parameters)
     at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethod(ControllerContext controllerContext, ActionDescriptor actionDescriptor, IDictionary2 parameters)
     at System.Web.Mvc.ControllerActionInvoker.<>c__DisplayClass15.b__12()
     at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethodFilter(IActionFilter filter, ActionExecutingContext preContext, Func1 continuation)
     at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethodFilter(IActionFilter filter, ActionExecutingContext preContext, Func1 continuation)
     at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethodFilter(IActionFilter filter, ActionExecutingContext preContext, Func1 continuation)
     at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethodFilter(IActionFilter filter, ActionExecutingContext preContext, Func1 continuation)
     at System.Web.Mvc.ControllerActionInvoker.InvokeActionMethodWithFilters(ControllerContext controllerContext, IList1 filters, ActionDescriptor actionDescriptor, IDictionary2 parameters)
     at System.Web.Mvc.ControllerActionInvoker.InvokeAction(ControllerContext controllerContext, String actionName)

Web.config



  
    
    
    
  
  
  
  
    
    
    
    
    
    
  
  
    
    
  
  
    
    
      
        
        
        
        
        
      
    
    
    
    
      
    
    
      
        
        
        
        
        
        
        
      
    
    
  
  
    
    
  
  
    
            
                
                
            
            
                
                
            
            
                
                
            
      
        
        
      
    
  
  
    
    
        (removed)
    
    
    
        (removed)
    
    
    
    
    
      
        
      
      
        
          
          
        
      
    
    
    
      
        
          
          
        
      
      
        
          
        
      
    
  
  
    
    
      
    
  


",['mvc']
34827797,Spring Security + Angular JS + Spring MVC Rest,"I am trying to build a web application with the following frameworks

 Angular JS on the front end
 REST Web Services in the backend using Spring MVC

I want to use Spring Security to authenticate all the requests going from Angular JS to Spring REST Web services. I also need to manage the session timeout/remember password etc. (All of the typical functionalities of a login functionality in a web app)
I have gone over hundreds of articles trying to find out how to do this but none of them is exactly serving the purpose I am asking for.
Any help on this (inline answer or external links) with detailed steps is highly appreciated. 
(Note I don't want to use Spring boot. Many tutorials including the one provided by Spring is using Spring boot.)
",['rest']
5083585,Are there any plans for a standard for connecting two clients (P2P) in web applications?,"This question has been answered
Do websockets allow for p2p (browser to browser) communication?
The answer is no. 
My question is are there any plans for this? Any speculative draft by the W3C or whoever, planning this capability? (I have googled and found nothing, but I'm not sure if I'm searching the wrong thing.)
There is the WebSockets API, which allows you to, for example, transfer files from one user to another quite efficiently (like <URL> and some others I've seen). I believe these work by piping the file through the server - it's very light on the server, as it doesn't have to store each chunk after its sent to the receiving client. But it does use the server's bandwidth twice (down and up) for each file transfer. 
It would be more efficient (for server and both clients) if the server could just pass the IP address (and a port?) of each client to the other, and the entire data transfer could take place between them.
For security, the browser could prompt each user to give permission (This website, example.com, wants to connect you to IP address 1.2.3.4 to receive a file transfer of 23MB. Allow/Refuse?).
If there are no plans to publish a spec on this, why not? 
",['p2p']
2921553,S.O.A. with .NET for scalability,"Anyone know where I can find useful resource for some information for this.
I reckon SOA is the way to go for scalabilty, but are there down sides such as performance and security I should look at.
Overall what architecture should be considered best for enterprise web applications
A good , complete, up to date book would be valuable, any suggestions?
",['soa']
48131440,Consuming a Rest API in Django,"Is it possible to make a model field that consumes a REST API as a foreign key?
I have two projects. The first project has this model in models.py
from django.db import models
from django_countries.fields import CountryField
from django.urls import reverse

class Currency(models.Model)
    name = models.CharField(max_length = 50)
    country = CountryField()
    code = models.CharField(max_length = 3)
    base = models.BooleanField()

    class Meta
        ordering = ['code']

    def __str__(self)
        return (self.code)

    def get_absolute_url(self)
        return reverse('currency_detail', args = [str(self.id)])

I have serialized the model with the following code in serializers.py
from rest_framework import serializers
from currencies . models import Currency

class CurrencySerializer(serializers.ModelSerializer)
    class Meta
        model = Currency
        fields = ('name', 'code')

I created the following views.py
from django.http import HttpResponse, JsonResponse
from django.views.decorators.csrf import csrf_exempt
from rest_framework.renderers import JSONRenderer
from rest_framework.parsers import JSONParser

from currencies . models import Currency
from . serializers import CurrencySerializer


def currency_list(request)
    currency = Currency.objects.all()
    serializer = CurrencySerializer(currency, many = True)
    return JsonResponse(serializer.data, safe = False)

and provided the following in urls.py
from django.conf.urls import url
from . import views

urlpatterns = [
    url(r'^currencies/$', views.currency_list),
]

The URL is passing the information ok in JSON format. There are no authentications (I am not good enough yet). When I use the requests library and make a get request, it returns the following
[{name Krone, code DKK}, {name Pound Sterling, code GBP}, {name Cedi, code GHS}]

I would like to consume this information in a new project which will have a different database and post records with the following model
class JournalEntry(models.Model)
    date = DateField()
    currency = ForeignKey(consuming the json data so it renders as a dropdown menu in html)
    value = IntegerField()

Is there a good way to do something like this? I haven't found any responses that help me conceptualize this properly. Also it is to help me with my learning. I intend to implement more complicated projects with this API-based approach. Thanks. 
",['rest']
11170843,ActiveRecord is not updating ID for polymorphic association accessed by through after saving object,"I'm trying to create a set of models in which user's profile has one address assigned but user can have many addresses in his virtual address book. The user should be able to pick up the default address from all his addresses and assign it to profile as home_address.
The addresses can have many types which differs. There are home addresses but there are also company and bank addresses that have additional fields. That's why I have to use polymorphism.
I created the models
class Addresser < ActiveRecordBase

  belongs_to addressable,  polymorphic => true
  belongs_to address,      polymorphic => true

  attr_accessible address_id, address_type

end

class HomeAddress < ActiveRecordBase

  has_one addresser, as => address, inverse_of => address

  attr_accessible name, city, zip, street, state, country

end

class Profile < ActiveRecordBase

  has_one     home_address,  through => addresser,
                              source => address, source_type => 'HomeAddress', 
                              autosave => true

  has_one     addresser,     as => addressable, inverse_of => addressable, 
                              autosave => true

  attr_accessible name, gender

end

Everything is working almost fine but Rails is not updating one of the fields after saving the models
profile_data = {
    name    => 'Some User',
    gender => 'm'
}

address_data = {
   street => 'Streeting 7',
   country => 'PL',
   city => 'New Rails',
 }

my_profile = Profile.new(profile_data)

=> #

my_address = HomeAddress.new(address_data)

=> # #

my_profile.save!

 INSERT INTO `profiles` (`created_at`, `name`, `gender`, `updated_at`)
 VALUES ('2012-06-23 100751', 'Some User', 'm', '2012-06-23 100751')

 INSERT INTO `home_addresses` (`city`, `country`,`street`)
 VALUES ('New Rails', 'PL', 'Streeting 7')

 UPDATE `addressers` SET `addressable_id` = 1 WHERE `addressers`.`id` = 1

 COMMIT
=> true 

In the above the addressable_id is updated but address_id is not. That causes the constraint to be invalid and unusable after reopenning database session
Addresser.first

SELECT `addressers`.* FROM `addressers` LIMIT 1
=> # 

Since address_id is nil, the profile.home_address cannot be found.
Can I fix this without manually updating the address_id of addressable?
The architecture of my app requires me to build the whole object with some initial settings and do the atomic save, so building address and saving it before user (which owns the profile) is created is a weak option.
",['activerecord']
34993058,How add resource to M2M relationship in django-tastypie,"I try to build API for save some objects to user-favorite.
I have this class for user-profile
class Profile(AbstractBaseUser, PermissionsMixin)

    email =             models.EmailField(blank=False, null=False, unique=True)
    first_name =        models.CharField(blank=True, null=True, max_length=255)
    last_name =         models.CharField(blank=True, null=True, max_length=255)

    # some enother fields    

    USERNAME_FIELD =    'email'
    REQUIRED_FIELDS =   ['first_name', 'last_name']

And tastypie-API for profiles
class ProfileResource(ModelResource)

    class Meta
        queryset =  Profile.objects.all()
        resource_name = 'profiles'
        allowed_methods = ['get', 'patch']
        authentication = Authentication()#MultiAuthentication(ApiKeyAuthentication(), SessionAuthentication())
        authorization = Authorization()

And object with relation to profile
class News(models.Model)
    title =         models.CharField(blank=False, null=False, max_length=255, verbose_name=u'–ó–∞–≥–æ–ª–æ–≤–æ–∫')
    add_to_favorite=models.ManyToManyField('profiles.Profile', related_query_name='favorite_news', blank=True)

class NewsResource(ModelResource)
    add_to_favorite = fields.OneToManyField(
        'profiles.api.ProfileResource',
        attribute='add_to_favorite',
        full=False, blank=True, null=True)    
    class Meta
        queryset =  News.objects.all()
        resource_name = 'news'
        allowed_methods = ['get', 'patch']

Now I try to execute this request
{
  id 1,
  add_to_favorite[
    {id3}
  ]
}

And got the error IntegrityError column email is not unique.
But the column email is unique. And all email's in database is unique.
How to fix my models and resources to resolve this problem?
Thanx!
",['rest']
48063078,redirect all http POST request to specific instance in sharded system,"I have a system with multiple machines part of mongo sharded cluster. There is REST api to access the database and has GET POST methods to do so.
There is ha-proxy to load balance the HTTP requests across these machines.
In order to boost performance i am planning to tweak the behavior in such a way that all the POST REST requests (which are comparatively less in number) to PRIMARY instance and all the GET request getting load balanced through ha-proxy.
I tried various configuration schemes but i am not able to understand how to expose the POST logic to ha-proxy.
Current setup is as follows
CLIENT Machine - a simulator to generate REST requests
Multiple Server machines part of mongo sharded cluster
A machine running ha-proxy
this is my ha-proxy configuration
frontend  main *5000
    bind 10.60.100.1008080
    default_backend serverpool

backend serverpool
    balance     roundrobin
    mode  tcp
    server      sv1 7.7.7.18080 check
    server      sv2 7.7.7.28080 check

",['rest']
1978035,System Design / Architecture Best Approach,"I have a system, that has 3 general parts to aid my description.
1) DATABASE- to store all tables, this same database will store data for other services as well including a web application, silverlight etc... (Needs to be flexible, if on a remote server, can be exposed via a web service, if locally, can connect locally or via TCP to the windows service)
2) BLACK BOX - process ONE item at a time by injecting in the list of required items from the database, like a pipe, where u put in a set of conditions, values for a single item, and returns the results for that single processed item.
3) WINDOWS SERVICE- to retrieve data from the database, injects into the black box, saves results from black box to the database at predefined intervals.  The service might be sitting on a different server to the database.  Will log error and continue should an error occur.  
On average, the windows service will have to process about 5000 items, and it will take the black box about 1.5 second to process 5000 items.  
My questions are
a) Should the windows service get a batch list of items to process from the database, or should it get a list of ids, and in a loop get each individual items from the database before passing on to the black box?  Note that the same database is being used by other applications as well.  Tentatively, I am guessing the database should be a web service call of some sort.
b) Should an individual item be saved immediately after processing?  Or should it wait for the batch to finish processing before saving?  As saving each individual item after processing is good when the systems suddenly fails in the middle of the process, at least the processed ones are saved, but at the cost of performance due to its 5000 calls to the web service?
Any advice on an optimum solution?
Cheers
",['soa']
33894403,ActiveRecordRecordNotFound in CustomersController#new Couldn't find Business without an ID,"so I have looked at other instances of this error in other questions on SO and none seem to be helpful. So, my authentication system should allow a Business to sign up, and allow a user to sign up under their business. However, I'm getting a couldn't find business without ID error.
class CreateUsers < ActiveRecordMigration
  def change


    create_table users do |t|

      t.references company, foreign_key true


      t.timestamps
      t.string first_name
      t.string last_name

      t.string email
      t.string password_digest
      t.string remember_digest
      t.string role

    end


class CustomersController < ApplicationController

  def new

    set_business

    @customer = @business.customers.create(user_params)

  end

  def create

    @customer = Customer.new(customer_params)
    @customer.save!
    session[customer_id] = @customer.id
    redirect_to '/'
  rescue ActiveRecordRecordInvalid => ex
    render action 'new', alert ex.message
  end

  private
  def customer_params

    params.require(customer).permit(first_name, last_name, business_no, email, password_digest, business_id) 
  end

  def set_business

    @business = Business.find (params[business_id])

  end



HTML snippet Customer.new.html.erb

Sign Up

      
          
           First name %>
          
           Last name %>
          
           Email %>
          
          
           Password %>
          
      



class Business < ActiveRecordBase
  has_many customers

end

class Customer < ActiveRecordBase
  belongs_to business
end

How am I supposed to define the @business variable without getting this error so that a user can sign up under their business? I want them to select from a list of available companies on the form, which will then link them in the database when the user signs up. What am I doing wrong? I am very new to Ruby and I may need some good explanation to why this is happening. 
thank you for your time )
",['activerecord']
24931742,Spring authentication through REST Service,"I have a Webapp that consists of a REST API, and then another app that represents a frontend of this API. Both of this apps are developed using Spring.
Currently my REST api is not secured and data can be accessed directly by calling the REST endpoint without additional security info.
My frontend does have a login form (I'm using Spring Security for that), but does not have access to a database (the only access is through the REST endpoint). So the login process is done through an extension of the AuthenticationProvider that calls the REST api with the user and password and then responds with the authentication result. No authentication/authorization is kept on the REST side since to my knowledge this protocol should be stateless.
The problem is I need to incorporate ACL into my app, so that a user can only see those resources he's authorized to see (i.e. those he created). But given that my authentication process takes place on the frontend layer (which is where I keep a session attribute with the user info), I have two main problems

How can I secure my REST channel?
How can I know which user is making the request on every communication, without explicitly passing the userdetails in each API request? is this even possible?

",['rest']
56397947,Creating new collection and document with Firestore REST API returning HTTP 400,"Hello stackoverflow community,
I am using Firestore and not Realtime database for a test project I am working on.

As a starter, I am trying to create a new document inside an existing collection and project which I manually created through the web interface. My project id is newproject-30f72 and the already created collection name is testcollection. 
I have enabled the Email/Password authentication method, and I have registered a new email-id/password user. The rule I have for auth enabled write is as follows.

service cloud.firestore {
  match /databases/{database}/documents {
    match /{document=**} {
      allow read, write if request.auth.uid != null;
    }
  }
}

At this point, I am not sure, a barer token alone passed in the header is enough to validate the request.auth.uid != null, so most probably my rule could also be wrong, as I was using the simulator to auto generate the rule, but I verified that the rule is not causing the problem I am facing at the moment by disabling the rule completely.

I have enabled rules so that only authenticated users can write to firestore. (and by authentication, I mean the idToken for a specific email/password based user and not the apiKey for a web app. I don't know if this is possible though.)
I have enabled the Add Firebase to your web app / register app and that gave me a json object named firebaseConfig with the following details.


   var firebaseConfig = {
      apiKey some_api_key,
      authDomain newproject-30f72.firebaseapp.com,
      databaseURL <URL>
      projectId newproject-30f72,
      storageBucket newproject-30f72.appspot.com,
      messagingSenderId 111122223333,
      appId 11111web2222
   };  


I am using the apiKey from the above json object to get an idToken valid for some time, to write to the firestore database. The code for that is as below in python3.
import json
from urllib import request, error
from collections import defaultdict

firebase_apikey = 'some_api_key'
auth_request_url = <URL>

class auth
    def __init__(self, email str, password str)
        self.email = email
        self.password = password
        self.post_data = defaultdict()
        self.post_data['email'] = self.email
        self.post_data['password'] = self.password
        self.post_data['returnSecureToken'] = True
        self.headers = {Content-Type application/json}
        # print(POST DATA IS  + json.dumps(self.post_data))
        self.r = request.Request(auth_request_url,
                                 data=json.dumps(self.post_data).encode(),
                                 headers=self.headers)
        # self.url_open

    def get_auth_token(self)
        try
            self.url_open = request.urlopen(self.r)
        except Exception as e
            return e
        try
            return json.loads(self.url_open.read())
        except Exception as e
            return e


s = auth(someuser.somethingelse@gmail.com, somepassword)
response = s.get_auth_token()
id_token = response['idToken']
expires_in = response['expiresIn']



I got the idToken which is a 924 character long string.
Now I am trying to write to firestore with the idToken that I received and valid for 3600(seconds I presume) using the Authorization' 'Bearer header as follows.
firestore_project_url = <URL>
    'newproject-30f72')

headers = {
    'Content-type' 'application/json',
    'Authorization' 'Bearer %s' % id_token,
}

test_data = '''
{
    writes [{
        updateMask {
            fieldPaths [name]
        },
        update {
            name projects/newproject-30f72/databases/(default)/documents/testcollection/testdoc/,
            fields {
                name {
                    stringValue test
                }
            }
        }
    }]
}
'''

test_data_json_bytes = json.dumps(test_data).encode(utf-8)
req = request.Request(url=firestore_project_url,
                      data=test_data_json_bytes,
                      headers=headers,
                      method='POST')
print(headers)
f = request.urlopen(req)


I can see the headers as 
{'Content-type' 'application/json', 'Authorization' 'Bearer eyJhbGciOiJSUzI1NiIsI........'}

but I am getting a urllib.error.HTTPError HTTP Error 400 Bad Request error.
I was referring to Firebase Firestore REST example to check it using curl with custom headers to add the bearer token and to see if there is any possible verbosity, and I am seeing
*   Trying 74.125.68.95...
* TCP_NODELAY set
* Connected to firestore.googleapis.com (74.125.68.95) port 443 (#0)
* ALPN, offering h2
* ALPN, offering <URL>
* successfully set certificate verify locations
*   CAfile /etc/ssl/certs/ca-certificates.crt
  CApath none
* TLSv1.3 (OUT), TLS handshake, Client hello (1)
* TLSv1.3 (IN), TLS handshake, Server hello (2)
* TLSv1.3 (IN), TLS handshake, Encrypted Extensions (8)
* TLSv1.3 (IN), TLS handshake, Certificate (11)
* TLSv1.3 (IN), TLS handshake, CERT verify (15)
* TLSv1.3 (IN), TLS handshake, Finished (20)
* TLSv1.3 (OUT), TLS change cipher, Change cipher spec (1)
* TLSv1.3 (OUT), TLS handshake, Finished (20)
* SSL connection using TLSv1.3 / TLS_AES_256_GCM_SHA384
* ALPN, server accepted to use h2
* Server certificate
*  subject C=US; ST=California; L=Mountain View; O=Google LLC; CN=*.googleapis.com
*  start date May 14 133500 2019 GMT
*  expire date Aug  6 132000 2019 GMT
*  subjectAltName host firestore.googleapis.com matched cert's *.googleapis.com
*  issuer C=US; O=Google Trust Services; CN=Google Internet Authority G3
*  SSL certificate verify ok.
* Using HTTP2, server supports multi-use
* Connection state changed (HTTP/2 confirmed)
* Copying HTTP/2 data in stream buffer to connection buffer after upgrade len=0
* Using Stream ID 1 (easy handle 0x560e5884af30)
> POST /v1beta1/projects/newproject-30f72/databases/(default)/documents/testcollection3 HTTP/2
> Host firestore.googleapis.com
> User-Agent curl/7.64.1
> Accept */*
> {Content-type application/json, Authorization Bearer eyJhbGciOiJSUzI1NiIsImtpZCI6........}
> Content-Type application/json
> Content-Length 258
> 
* We are completely uploaded and fine
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4)
* TLSv1.3 (IN), TLS handshake, Newsession Ticket (4)
* old SSL session ID is stale, removing
* Connection state changed (MAX_CONCURRENT_STREAMS == 100)!
< HTTP/2 400 
< content-type text/html; charset=UTF-8
< referrer-policy no-referrer
< content-length 1555
< date Fri, 31 May 2019 143136 GMT
< 
* HTTP/2 stream 0 was not closed cleanly PROTOCOL_ERROR (err 1)
* stopped the pause stream!
* Connection #0 to host firestore.googleapis.com left intact
curl (92) HTTP/2 stream 0 was not closed cleanly PROTOCOL_ERROR (err 1)
* Closing connection 0


I was referring to the following links for references.
<URL>
<URL>
What I am trying to achieve is 

use the email/password auth to get authenticated to firestore
create collection and write docs to it.

Any help is greatly appreciated.
Thank you very much.
",['rest']
50431706,MVC custom login authentication,"Hi I'm developing an app in MVC and I have a problem with login, I want to know how can I manage the login depending on the user role.
While the moment the login works fine but I need to identify the role user for sending to different pages
I have a table in my database call Employee and one column is call IdPosition that is referred to another table call Position.
Here is my code
[HttpPost]
    public ActionResult Autorizacion(Pepitos.Models.Employee employee)
    {
        using (pepitosEntities db = new pepitosEntities())
        {
            var userDetails = db.Employees.Where(x => x.Username == employee.Username amp;amp; x.Password == employee.Password).FirstOrDefault();

            if (userDetails == null)
            {
                employee.ErrorLoginMensaje = Username or Password incorrect;
                return View(Login,employee);
            }
            else
            {
                Session[IdEmployee] = userDetails .IdEmployee;
                Session[name] = userDetails.Name;
                return RedirectToAction(EmployeesIndex, EmployeesHome);
            }
        }

    }

",['mvc']
42491958,How to use two different database in one app?,"Just asking, how to use two different databases (mysql, mongodb) in one app.
I have created two micro-services 

Authentication service
Messaging service for my chat app.

The authentication is done in node.js mongo
The messaging service in php and mysql using FCM.
At the moment i have two different android app
One authenticate user and the other send messaging with push notification.
Both information are stored in their own respective database.
How do i coming the two of them and allowing the mongodb to store user info only with GCM reg token and mysql to store chat rooms and channel.
If this question is kinda vague let me know, I will narrow it down.
thanks in advance 
",['microservices']
17065304,Best practices for Spring Transactions and generic DAOs  Services,"I work on a Java EE application with Spring and JPA (EclispeLink). We developed a user-friendly interface for administrating the database tables. As I know more about Spring and Transactions now, I decided to refactor my code to add better transaction management. The question is how to best deal with generic DAOs, generic services and Spring transactions?
Our current solution was

A generic BasicDAO which deals with all common database actions (find, create, update, delete...)
A Daoabstract-abstract-factory which contains a map of implementations of BasicDao for all entity types (which only need basic database actions) and which gets the entitymanager injected by spring to pass it to the daos
A generic BasicService which offers the common services (actually directly linked to the dao methods)
A Serviceabstract-abstract-factory which contains a map of implementations of BasicService for all entity types, which gets the daoabstract-abstract-factory injected and passes it to the services. It has a method getService(Class T) to provide the right service to the controllers.
Controllers corresponding to the right entity types which delegate their requests to a generic controller which handles the request parameters using reflection and retrieves the right service from the service abstract-abstract-factory's map to call the update/create/remove method.

Problem is that, when I add the @Transactionnal annotations on the generic Service and my serviceabstract-abstract-factory creates the typed services in its map, these services don't seem to have active transactions running.
1) Is it normal, due to the genericity and the fact that only spring-managed services can have transactions?
2) What is the best solution to solve my problem

Create managed typed services only implementing the generic service and inject them directly in my serviceabstract-abstract-factory?
Remove the service layer for these basic services? (but maybe I'll get the same problem with transactions on my dao generic layer...)
Other suggestions?

I read some questions related to these points on the web but couldn't find examples which went as far into genericity as here, so I hope somebody can advise me... Thanks in advance!
",['dao']
20547669,Passing SAML token to a web application,"I have an ASP.NET [MVC] application which has a claims based authentication scheme running. ADFS authenticates users and redirects back to the application domain with relevant token.
Now, I'd like to simulate this process from start to end. I was able to get a SAML 2.0 token object of type GenericXmlSecurityToken from ADFS via some powershell scripting but couldn't figure out how to create an SSL tunnel and pass the token to the application just to download the Index view. Any use of net.webclient ?
",['mvc']
32295827,When to have a DTO layer?,"I am developing a web application with AngularJS for the front-end and Java Play Framework for the back-end services. For database access I use Hibernate.
So far I have about 30 services which consume and produce JSON, and I send Hibernate objects directly instead of having a data transfer layer.
Currently I am facing recursive call issues because of two-way referencing of Hibernate entities. Those issues are already solved by some annotations and JSON Views, however configuration of those views for different service methods is becoming a real issue and annotating the entities accordingly for JSON conversion is really bloating the lovely simple entity objects.
Currently I am thinking of a DTO layer to ease the communication, however I am not sure if the development and performance overhead caused by preparing request and response DTO objects for each service really worth it. Is it a good idea?
",['dto']
7065403,Number of calls from Facade in Facade Pattern,"We are having a discussion about what should be placed in the facade layer and how many calls the facade layer should make to the underlying layers.
In our project we have an Orchestration layer that coordinates calls to services and databases. We also have a business layer with business rules and calculations.
Our facade layer has a security check, logging and error handling.
Now the question Should the facade have only a single call to the orchestration layer or is it Ok with multiple calls. If it is only a single call should these layers be merged into a single layer.
These are WCF services written in C#.
",['facade']
9277074,Query from database or from memory? Which is faster?,"I am trying to improve the performance of a Windows Service, developed in C# and .NET 2.0, that processes a great amount of files. I want to process more files per second.
In its process, for each file, the service does a database query to retrieve some parameters of the system. 
Those parameters change annually, and I am thinking that I would gain some performance, if a loaded those parameters as a singleton and refreshed this singleton periodically. Instead of make a database query for each file being processed, I would get the parameters from memory.
To complete the scenario  I am using Windows Server 2008 R2 64 Bits, SQL Server 2008 is the database, C# and .NET 2.0 as already mentioned.
I am right in my approach? What would you do? 
Thanks!
",['singleton']
20360505,Small API Security Best Practice,"I am in a situation where I make an iPhone app and a RESTful API (via a php script) to communicate with individual clients warehouse databases.
Currently I manually setup individual web servers with a self signed certificate. Create a user with a special long random password (it is hard coded into the app). Setup their web server so that my php script requires Basic Authentication and only grants access to the specific user.
On my app's side the username/password is hard coded and it ignores the fact that the server has a self signed certificate.
Is there anything wrong with this model?
",['rest']
43539614,Laravel Api.php in routes directory,"I am a bit confused, I have a web application having a login, Register, Logout. Some dashboard views etc(CRUD),  I want to make an api for this application too. 
Like an api which third party will use, Can update records, Can delete records etc.
Actually there should be some way which can be use by mobile app for CRUD.
I know we have that routes/api.php, But i am pretty confused that when to use it. Please explain the scenario, I am blank.
Update
Scenario
Application having views, authentication system etc, How an android app will be able to perform CRUD operations on the same application ? 
",['rest']
45158563,Database for P2P Application,"I need to create a software that follows the Peer-to-Peer distributed database architecture but I am unsure of which solution to use.
My first option is to SQLite which is free and doesn't rely on any services whatsoever compared to MS SQLServer. But can I rely SQLite for performance?
My second option is to use a full-fledged database solutions such as MySQL or MS SQLServer but I can't really rely on it if I want something service-free and independent can I?
Do you know any other database solution that fits my purpose?
My only is requirement is that it should be service free, independent and capable supporting large amount of data.
Edit It has to be not internet dependent, offline database.
",['p2p']
36913718,Zend Framework 2 - Controller instantiate Service via (modified?) abstract-abstract-factory,"I have an abstract service class SAbstract which is inherited by ConcreteServiceA and ConcreteServiceB. Now I am instantiating ConcreteServiceA in the abstract-abstract-factory class of my controller and inject the service in my controller. 
In a specific action in my controller I want to exchange ConcreteServiceA with ConcreteServiceB to change behavior. Because they have same interface (abstract class SAbstract) I could inject it in my controller as well (the services are a Strategy-Pattern).
But I don't want to instantiate ConcreteServiceB directly in my controller to keep my code clean (for easy refactoring and exchanging behavior).
A possible solution is to create a second abstract-abstract-factory for my controller which injects ConcreteServiceB instead of ConcreteServiceA but then I have duplicated lots of code which is not good...
Another solution would be to inject both services in my controller (but this smells like bad code).
Is a delegator abstract-abstract-factory the right way to do this? Then I have to implement setters in my controller...
Is there a better way?
I tried to schematically visualize my class relationships.
AbstractService - ConcreteServiceA
AbstractService - ConcreteServiceB
Controller ---> AbstractService
ControllerActionA ---> ConcreteServiceAexportAction()
ControllerActionB ---> ConcreteServiceBexportAction()

",['strategy-pattern']
19439843,JMeter throughput drops when hitting Amazon ELB,"I am hosting a web application on Amazon's AWS Servers. I am currently in the process of load testing the application with JMeter. My main problem seems to be that when I go through an Elastic Load Balancer (ELB) to hit the Amazon server's rather than hitting the servers directly - I seem to hit a cap in my throughput.
If I hit my web application directly - for each server I am able to achieve a throughput of 50 RPS per server.
If I hit my web application via Amazon's ELB - I am only able to achieve a max throughput of 50 RPS (total)
I was wondering if anyone else has experienced similar behavior when load testing using Jmeter via Amazon's ELB.
For more context my web application is a REST application which allows users to download content (~150 kb) via HTTP requests.
I am running Jmeter with the following flag -Dsun.net.inetaddr.ttl=0 and running it with 10 threads. I have tried running these tests with multiple clients on different machines.
Thanks for any help in advance.
",['rest']
28536522,Intercept and retry call by means of OkHttp Interceptors,"I need to retry request inside of OkHttp Interceptor. For example there is incoming request which needs Authorization token. If Authorization token is expired, server returns response with 403 code. In this case I am retrieving a new token and trying to make call again by using the same chain object.
But OkHttp throws an exception, which states that you cannot make two requests with the same chain object. 
java.lang.IllegalStateException network interceptor org.app.api.modules.ApplicationApiHeaders@559da2 must call proceed() exactly once

I wonder if there is a clean solution to this problem of retrying network request inside of OkHttp Interceptor?
public final class ApplicationApiHeaders implements Interceptor {
    private static final String AUTHORIZATION = Authorization;
    private TokenProvider mProvider;

    public ApplicationApiHeaders(TokenProvider provider) {
        mProvider = provider;
    }

    @Override
    public Response intercept(Chain chain) throws IOException {
        Token token = mProvider.getApplicationToken();
        String bearerToken = Bearer  + token.getAccessToken();

        System.out.println(Token  + bearerToken);
        Request request = chain.request();
        request = request.newBuilder()
                .addHeader(AUTHORIZATION, bearerToken)
                .build();

        Response response = chain.proceed(request);
        if (!response.isSuccessful() amp;amp; isForbidden(response.code())) {
            Token freshToken = mProvider.invalidateAppTokenAndGetNew();
            String freshBearerToken = freshToken.getAccessToken();

            Request newRequest = chain.request();
            newRequest = newRequest.newBuilder()
                    .addHeader(AUTHORIZATION, freshBearerToken)
                    .build();

            response = chain.proceed(newRequest);
        }

        return response;
    }

    private static boolean isForbidden(int code) {
        return code == HttpURLConnection.HTTP_FORBIDDEN;
    }
}

",['interceptor']
14055260,Can scheduled web request be authorized by MVC controllers?,"My web app has to do some calculations in the background. I've investigated multiple solutions and I would like to go for business logic instead of a SQL job that triggers all the calculations. After a few days of research I'm still not convinced what is the best solution for my case.
A lot of articles mention Quartz.NET, a separate windows service (but I think that's not an option on most shared web host services), a windows task, etc...
To keep the calculations in the business logic I would extend my web application with a dedicated 'task' controller that fires the calculations automatically and then returns a result of its actions. 
Q1 Calling the controller with a Quartz.NET timed web request will not be that hard, but how can I secure it? If I add the [Authorize] attribute to my 'task' controller it will block the request. (note that I use forms authentication on my internet web application) I don't want users on the internet to be able to launch my 'task' controller.
Q2 Also if what I'm thinking is correct that shared web host services don't support the installation of separate windows services or remote desktop connections, I'll have 2 options

hope there is support for windows tasks at the shared web host service (but can this be called with authorization credentials?)
start the Quartz.NET from my application_start (which is certainly not an ideal solution...) 

Thanks in advance
Kr
",['mvc']
34428046,Etags used in RESTful APIs are still susceptible to race conditions,"Maybe I'm overlooking something simple and obvious here, but here goes
So one of the features of the Etag header in a HTTP request/response it to enforce concurrency, namely so that multiple clients cannot override each other's edits of a resource (normally when doing a PUT request). I think that part is fairly well known.
The bit I'm not so sure about is how the backend/API implementation can actually implement this without having a race condition; for example
Setup

RESTful API sits on top of a standard relational database, using an ORM for all interactions (SQL Alchemy or Postgres for example).
Etag is based on 'last updated time' of the resource
Web framework (Flask) sits behind a multi threaded/process webserver (nginx + gunicorn) so can process multiple requests concurrently.

The problem

Client 1 and 2 both request a resource (get request), both now have the same Etag.
Both Client 1 and 2 sends a PUT request to update the resource at the same time. The API receives the requests, proceeds to uses the ORM to fetch the required information from the database then compares the request Etag with the 'last updated time' from the database... they match so each is a valid request. Each request continues on and commits the update to the database.
Each commit is a synchronous/blocking transaction so one request will get in before the other and thus one will override the others changes.
Doesn't this break the purpose of the Etag?

The only fool-proof solution I can think of is to also make the database perform the check, in the update query for example. Am I missing something?
P.S Tagged as Python due to the frameworks used but this should be a language/framework agnostic problem. 
",['rest']
1940654,Avoid SHOW FIELDS in ActiveRecord,"Is there any way to prevent ActiveRecord from issued a SHOW FIELDS to the database when it's not needed?
I'm working on database performance critical application, and just noticed that on a typical query my SELECT takes 0.5 ms and the related SHOW FIELDS takes 2 ms -- 4 times longer! Even more importantly, it's not needed because I'm already specifying the only column I want to retrieve
UsersAddress.find(all, conditions => {user_id => 1}, select => address_id)

UsersAddress Load (0.5ms) SELECT address_id FROM users_addresses WHERE (users_addresses.user_id = 1)
UsersAddress Columns (2.1ms) SHOW FIELDS FROM users_addresses

Granted, this only happens once each time some table is touched for the first time, but shouldn't it be avoidable complete? First of all, that info is already in my schema. Second, I don't need it.
Any ideas how to optimize this so that Rails won't run a SHOW FIELDS unless it really needs it?
Thanks!
",['activerecord']
41161769,Authorisation in microservices - how to approach domain object or entity level access control using ACL?,"I am currently building microservices based system on java Spring Cloud. Some microservices use PostgreSQL and some of them MongoDB. REST and JMS is used for communication. The plan is to use SSO and OAuth2 for authentication
The challenge I am facing is that authorisation have to be done on domain object/entity level. It means some kind of ACL (Access Control List) is needed. The best practice for this kind of architecture is to avoid something like this and have coarse grained security probably on application/service layer level in every microservice but unfortunately it is not possible.
My final idea is to use Spring Security ACL and have the ACL tables in shared database between all microservices. The database would be accessed only by Spring infrastructure or through Spring api. The DB schema looks stable and unlikely will change. In this case I would simply break the rule about sharing db between microservices.
I was considering different kinds of distributed solutions but left them 

One microservice with ACL and accessing it using rest - The problem is too many http calls and performance degradation. I would have to extend Spring Security ACL to replace db access by rest calls
ACL in every microservice for its own entities - Sounds quite reasonable but imagine a case having some read models of entities synchronised to some other microservices or same entity that exists in different bounded contexts (different microservices). ACLs can become really unmanageable and can be source of errors.
One microservice with ACL tables that are synchronised to other microservices as a read model. The problem is that there is no support in Spring Security ACL for MongoDB. I have seen some custom solutions on github and yes it is doable. But...when creating a new entity I have to create record in the microservice  that owns ACL and then it is asynchronously synchronised as a read model to microservice owning the entity. It does not sound as a easy solution
Choose some URL based access control on API gateway. But I would have to modify Spring Security ACL somehow. The API gateway would have to know too much about other services. Granularity of access control is bound to REST api granularity. Maybe I can not imagine all the consequences and other problems that would this approach bring
Finally the solution with shared db that I mentioned is my favorite. Actually it was the first one I have disqualified because it is ‚Äúshared‚Äù database. But after going through possibilities it seemed to me that this is the only one that would work. There is some more additional complexity in case I would like to use some kind of caching because distributed cache would be needed.

I would really use some advice and opinions how to approach the architecture because this is really tricky and a lot of things can go wrong here.
Many thanks,
Lukas
",['microservices']
40660163,Microservices dependence management - Governance or ddd?,"Background an international company with a federation model is transforming into Microservices due to chronic Monolithic pain. Autonomous teams with quick deployment is highly desirable. In spite of theory, services are indeed dependent on each other for higher functionality, but are autonomous (independently developed and deployed). Since this is a federation model and decentralized control, we cannot impose strict rules - just like the UN. Without a governance platform that will manage dependencies else due to the multiple versions in production in different countries, we foresee uncontrollable chaos.
Let's call set of Microservices that needs to collaborate a Compatibility Set. A service can be deployed but may not satisfy the higher functionality in its Compatibility Set.  For example MicroService A-4.3 is fully autonomous, deployed and working perfectly. However to satisfy BusinessFunctionality 8.6 it must work together with MicroService B-5.4 and MicroService C-2.9. Together (A-4.3 , B-5.4 and C-2.9) they form a Compatibility Set
There are two approaches to this dilemma. Microservice in real life where the rubber hits the road and the learning from experience begins...
Approach 1) Governance Platform
Rationale Federal model in an International company in 100+ countries. Which means Central IT can lay down the model but individual countries can choose their own destiny - and they frequently do. It frequently devolves to chaos and the Central IT team is on the hook. DDD is the solution for an ideal world where version inconsistencies do not derail functionality like releasing services which do not fit into the Compatibility set, individually blameless but together they fall apart or result in flawed or inconsistent functionality.

There is no homogeneity, there isn't even standardization of terminology
Developers are mixed skill, many junior, and many learning reactive programming and cloud native technologies
Bounded Context heavily depends on Shared Vocabulary and it can get subtle, but this is impossible to enforce and naive to assume in an International, mixed skill, fragmented scenario with multiple versions running
Standardization on a Single Business Model is not realistic in such a heterogeneous system (but ideal)

How what is Central IT to do when they're held responsible for this Chaos?
Enforce a Governance Platform
Create a Microservices governance system or framework to enforce dependency management. It verifies and enforces at design and run time dependencies on a particular Microservice through a manifest and performs some checks and balances to verify the service implementations being offered - the  Compatibility Set. 
Approach 2)  ddd (DDD)
DDD is about modelling domains that are constantly evolving, where domain experts (typically a business stakeholder, or perhaps an analyst) will work alongside developers to design the system. Within each domain, a ubiquitous language is formed, such that within that context, the same word always means the same thing. An important thing to realise is that in one part of your system, ‚ÄúOrder‚Äù might mean one thing, it might mean for example a list of products. In another part of your system, ‚ÄúOrder‚Äù might mean something else, it might mean a financial transaction that happened. This is where the model you describe can fall down, if my service needs to get a list of orders, perhaps there is a capability out there that supplies a list of orders, but which orders are they? The list of products or the financial transaction? Trying to coordinate as many developers as you have to all use the same language here is an impossible task that is doomed to fail.
In DDD, rather than trying to manage this at a system level and force every service to use the same definition of Order, DDD embraces the inherent complexity in coordinating very large deployments with huge numbers of developers involved, and allows each team to work independently, coordinating with other teams as needed, not through some centralised dependency management system. The term used in DDD is bounded contexts, where in one context, Order means one thing, and in another bounded context, Order can mean another thing. These contexts can function truly autonomously ‚Äì you describe your services as being autonomous, but if they have to match their definition of order with the entire system by registering and supplied dependencies to a central registry, then really they are tightly coupled to the rest of the system and what it considers an order to be ‚Äì you end up with all the painful coupling of a monolith, with all the pain of building a distributed system, and you won‚Äôt realise many of the benefits of microservices if you try to take this approach.
So a DDD based approach doesn‚Äôt ever try to take a heavy handed approach of enforcing dependencies or capabilities at the system level, rather, it allows individual teams to work without needing central coordination, if Service A needs to interact with Service B, then the team who manages Service A will work with the team that manages service B, they can build an interface between their bounded contexts, and come to an agreement on language for that interface. It is up to these teams to manage their dependencies with each other, at the system level things can remain quite opaque / unenforced.
Too often we see people implement ‚ÄúMicroservices‚Äù but end up with a system that is just as, if not more inflexible, and often more fragile, than a monolith. Also called a Minilith or Monolith 2.0 Microservices require a complete rethink of architecture and software development processes, and require not just allowing services to be autonomous and independently managed, but also for teams to be independent, not centrally managed. Centralising the management of dependencies and capabilities in a system is likely to be an inhibitor to successfully building a microservice based system.
Intelligent and Pragmatic comments invited...
Approach 1 (Governance) is pragmatic and tactical and intended to solve very real challenges. Question is - will it undermine the long term strategic DDD model of the Enterprise?
Approach 2 (DDD) is ideal and aspirational but doesn't address the very real challenges that we have to deal with right now. 
Opinions? Thought? Comments? 
","['ddd', 'microservices']"
45525753,RESTful API and bulk operations,"I have a middle tier which performs CRUD operations on a shared database.  When I converted the product to .NET Core I thought I'd also look at using REST for the API as CRUD is supposed to be what it does well.  It seems like REST is a great solution for single record operations, but what happens when I want to delete, say, 1,000 records?
Every professional multi-user application is going to have some concept of Optimistic Concurrency checking you can't have one user wipe out the work of another user without some feedback.  As I understand it, REST handles this with the HTTP ETag header record.  If the ETag send by the client doesn't match the server's tag, then you issue a 412 Precondition Failed.  So far, so good.  But what do I use when I want to delete 1,000 records?  The back-and-forth time for 1,000 individual calls is considerable, so how would REST handle a batch operation that involved Optimistic Concurrency?
",['rest']
8476450,Decoupling technology from domain objects,"My company has an application that allows users to perform a diagnostic medical test that measures circulating blood volume. This test involves using a gamma counter to measure/count the radiation in multiple blood samples. These samples are placed in a motorized carousel (i.e., sample changer) that moves the samples over the gamma counter to be counted.
Here‚Äôs what we believe our domain nouns are

Test (i.e., blood volume, quality control)
Patient
Sample (i.e., something to be counted)
Spectrum
Test execution context (i.e., specification of the samples and their order that correspond to a certain type of test)

We believe our domain verbs are

Moving the carousel to a given position
Obtaining a spectrum (i.e., counting a sample)
Running tests

As we understand ddd, the business logic should go in the domain. Our business logic resides mainly with what we‚Äôre calling a test execution controller. This controller uses a test execution context to determine how to move the samples into position and to have the gamma counter measure them.
The specific technologies that are giving us some confusion are Prism and WCF.
(1) Prism relies on an event aggregator to pass non-CLR events around the system. The test execution controller uses this to let other parts of the system know what‚Äôs going on (e.g., Sample 2A is being counted, there are 34 minutes remaining for the current test). Technically, the event aggregator is a technology that‚Äôs part of Prism, and domain objects/services are not supposed to rely on technology.
Question Is there a way to restructure things so that our domain service isn‚Äôt technology-dependent?
(2) We have two WCF services that allow us to communicate with the sample changer and gamma counter. Each service has a contract (i.e., an interface that‚Äôs decorated with WCF-specific attributes). At least with the contracts, we separate the concerns such that our main application depends on behavior, rather than a specific sample changer or gamma counter. However, WCF is a technology and the application code needs to know that this service we‚Äôre talking to is a WCF service (which is done by creating a proxy class). To satisfy DDD constraints, we end up having several similarly named classes/interfaces that seem redundant. Here‚Äôs an example

IGammaCounterService ‚Äì WCF contract that defines methods to communicate with a gamma counter. This interface is referenced by (1) the WCF side of things where the actual implementation lives, and (2) application code that talks to this service.
IGammaCounter ‚Äì set of properties/methods that defines the behavior for a gamma counter. (This is part of our domain.)
GammaCounterProxy ‚Äì class that implements the WCF service contract. This is what our application uses to communicate with the WCF service.
GammaCounter ‚Äì class that is used by the business logic. This is a GammaCounterProxy (via inheritance) and also implements IGammaCounter. (Note We use an inversion of control container ‚Äì specifically Unity ‚Äì to register this instance within our application.)

Question We have interfaces in the domain and on the WCF side that basically have the same method names. Is there a better/cleaner way to do this?
",['ddd']
39161175,Business rules as REST API or module,"I m building an application that contains 

A front end angularjs
A backend express application

The fact is that both are using the same business rules for validation, one time in front end, and the other, on the back part to maintain a good navigability (locking in front) and good business management (locking in back).
This way, I was wondering about a way to manage my business rules for both sides in one place.
This way, I've found two solutions 
- Create a npm module
PROS  This could work with versionning, accessible from both client and back side due to the javascript technology
CONST  Only available for javascript, and if I need, in the future, to add a new technology, I would have to make it for the technology concerned. There's also the fact that I have to make a remote request, and use the network. Exactly what I don't want to do with my client
- Create a REST API exposing only my business rules
PROS  accessible from both client and back side, from any technology
CONST  network latency, and need to manage another service from my client side
I was wondering what could be a good solution and why ?
",['rest']
40674685,How to refactor frontend JS to Angular 2 to play nicely with PHP MVC backend?,"I have a huge PHP MVC web application, which now uses for some click events and modal dialog rendering jQuery. To stay confident with modern frontend technologies, I would like to refactor the JavaScript code to run under Angular 2. But my main question is How can I do this? Angular 2 doesn't have controllers anymore, which really complicate things in my use case. I mainly just need some click event subscribing and modal dialog handling on the JavaScript side. The most part of the HTML is rendered in the PHP backend.
For example, let's say we have a news site (route index/news) with many news entries. Actually, this is completely done in the backend by fetching data from the database, load a helper for each news entry and output it in the view. If I would refactor this to a component, then I would have massively ajax requests for each news entry. I believe this is not the preferred way of using Angular 2. Also, what I really need is some interaction on buttons etc.. I think it is also not the meaning of Angular 2 to create a small template string with the buttons and an ngClick inside of that, just for having an ngClick on my button.
So, please tell me how I can integrate Angular 2 in a nice way, so that these two technologies play well with each other.
",['mvc']
42559380,"Uploading data from Excel to Database (Access), using ADODB / DAO, checking data for correct input mask","I'm trying to write a VBA code, that would upload data to Access database using  ADODB connection. The problem is that I want to check data integrity before upload, so checking for input mask format, allowed values, whether field is required, length of field, type of data. So far what I figured out, I would 

Let the user choose which database and what table to upload to (ADODB.OpenSchema)
Connect with DAO to get information about inputmask and other (at least input mask can be done only by DAO)
Connect to selected table, create empty recordset, disconnect (ADODB)
Test data to parameters while building batch recordset, and ignore lines with wrtong data
Upload data

Is there other commonly used way to test data for inputmask format, before uploading to database? Just give me directions, i'll google rest
See below what I have so far, if you are interested.
Thank you
 Option Explicit
Option Base 1

Sub opentest()

Dim file As String, table As String
Dim outputarray As Variant
Dim cancelwork As Boolean
Dim coll As Collection
Set coll = New Collection


Dim adSchemaTables As Long, adOpenDynamic As Long, adLockBatchOptimistic As Long, adUseClient As Long 'named methods/properties must be defined as numbers for late binding
adOpenDynamic = 2
adLockBatchOptimistic = 4
adSchemaTables = 20
adUseClient = 3




With Application.FileDialog(msoFileDialogFilePicker) 'lets user select database
    .Title = Select Database
    .AllowMultiSelect = False
    .Show

    If .SelectedItems.Count = 0 Then
            End
        Else
            file = CStr(.SelectedItems(1))
    End If

End With


Dim cnn As Object, rs As Object   ' late binding, should allow no need for ADO library reference in excel
Set cnn = createobject(ADODB.connection)
Set rs = createobject(ADODB.Recordset)

cnn.Open Provider=Microsoft.ACE.OLEDB.12.0;Data Source= amp; file amp; ; amp; Persist Security Info=False

Set rs = cnn.OpenSchema(adSchemaTables, Array(Empty, Empty, Empty, link)) 'for linked tables

Do While Not rs.EOF
    coll.Add CStr(rs(table_name))
    rs.MoveNext
Loop

Set rs = Nothing

Set rs = cnn.OpenSchema(adSchemaTables, Array(Empty, Empty, Empty, table)) 'for actual tables

Do While Not rs.EOF
    coll.Add CStr(rs(table_name))
    rs.MoveNext
Loop

Call ListBox(coll, table) 'lets the user select table where to upload

Set rs = Nothing
Set rs = createobject(ADODB.Recordset)
rs.CursorLocation = adUseClient

rs.Open select * from  amp; table amp;  where false, cnn, adOpenDynamic, adLockBatchOptimistic 'connection

Set rs.ActiveConnection = Nothing 'disconnecting to build data


Call dataload(rs, cancelwork) 'calling dataload function

If cancelwork = True Then
        Call closing(rs, cnn)
        End
End If


Set rs.ActiveConnection = cnn

rs.UpdateBatch 'uploading data



Call closing(rs, cnn)

End Sub


Sub closing(rs As Object, cnn As Object)


rs.Close
Set rs = Nothing
cnn.Close
Set cnn = Nothing

End Sub


Private Sub ListBox(ByVal coll As Collection, ByRef table As String)

Dim item As Variant

For Each item In coll
    ListBoxForm.ListBox1.AddItem (item)
Next item

ListBoxForm.Show
table = ListBoxForm.ListBox1.value

ListBoxForm.ListBox1.Clear

End Sub


Sub dataload(ByRef rs As Object, ByRef cancelwork As Boolean)
Dim loadarray() As Variant
Dim region As Range
Dim response As VbMsgBoxResult

On Error Resume Next
Set region = Application.InputBox(Prompt=Select data to upload, Type=8)
If region Is Nothing Then
        End
End If

loadarray = region

If (UBound(loadarray, 2) - LBound(loadarray, 1) + 1) > rs.Fields.Count Then
        MsgBox Number of columns to be uploaded is greater then number of columns in database, ending
        cancelwork = True
        Exit Sub
    ElseIf (UBound(loadarray, 2) - LBound(loadarray, 1) + 1) < rs.Fields.Count Then
        response = MsgBox(Number of columns to be uploaded is less then number of columns in database, vbOKCancel)
        If response = vbCancel Then
                cancelwork = True
                Exit Sub
        End If
End If

Set rs = recordsetload(rs, loadarray, region)


End Sub


Private Function recordsetload(rs As Object, loadarray As Variant, region As Range) As Object

Dim rowi As Long, columni As Long, rsrow As Long

For rowi = LBound(loadarray, 1) To UBound(loadarray, 1)
        rs.AddNew
        For columni = LBound(loadarray, 2) To UBound(loadarray, 2)
                rs.Fields(columni - 1).value = loadarray(rowi, columni)
        Next columni
Next rowi

Set recordsetload = rs

End Function


    Sub daotry2()
    Dim file As String

    With Application.FileDialog(msoFileDialogFilePicker)
        .Title = Select Database
        .AllowMultiSelect = False
        .Show

        If .SelectedItems.Count = 0 Then
                End
            Else
                file = CStr(.SelectedItems(1))
        End If

    End With

    Dim db As Object  'late binding without reference, seems to work, but might cause trouble, not tested
    Dim tbl As Object

    Dim dbe As Object
    Set dbe = CreateObject(DAO.DBEngine.120)  'depends on win version


    Set db = dbe.OpenDatabase(file)
    Set tbl = db.TableDefs(CAPEX)

    Debug.Print tbl.Fields(0).Properties(InputMask)
    Debug.Print tbl.Fields(0).Properties(Size)
    Debug.Print tbl.Fields(0).Properties(ValidationRule)
    Debug.Print tbl.Fields(0).Properties(Required)

    db.Close

    End Sub

",['dao']
38618531,How to allow access to API only for own pages?,"I'm developing Spring Boot web application, that provides REST API. Most of my pages(thymeleaf templates) use this API to communicate with back-end(using AJAX requests). I have read about different approaches such as Basic Authentication, OAuth2 etc. These approaches describe user authentication, after which users can access API. But i don't  want users to directly communicate with my API, using browser or REST client(i.e. postman chrome extension, that has access to browser's cookies, where access tokens are usually stored).
I have something like this
(1) User --> (2) MyOwnPages --> (3) RestAPI. 
Is there a way to prevent direct communication 1-3 ? Can i somehow determine that request was made from my pages(i.e. add to each request some sort of access token)? Are there any best practices?Thanks!
",['rest']
45394540,What's the recommended way to deal with Singletons cleanup in Android (Kotlin)?,"I have been having some weird issues in my Android app when closing it via back key and reentering, and found they are happening because variables in 2 Singleton classes I have are never re-initializing (The issue doesn't happen if manually killing the app from task manager).
Even after I call finish explicitly on Main activity onBackPressed and I can see onDestroy is called, the Singletons are still in memory.
I decided to do manual cleanup of these Singletons before destroying my Activity, the problem is using Kotlin I would need to make all their member variables nullable (?) and it would be a lot of hassle to remember to assign null to every variable, so for now I opted to handle the instantiation of the Singleton like this and just make null the whole instance while cleaning
class SingletonName {

    companion object {
        private var _instance SingletonName ? = null
        private var instance SingletonName ?
            get() {
                if (_instance == null) {
                    _instance = SingletonName ()
                }
                return _instance
            }
            set(value) {
                _instance = value
            }

        @JvmStatic fun get() SingletonName {
            return instance!! //avoid having to deal with nullable value in client code
        }
    }

    //need to make sure to call this before destroying main activity
    fun cleanup() {
        instance = null
    }
}

Client use
SingletonName.get().somefunc()

These seems more involved than it should, and I know this is not even thread safe, but keep in mind that simply using the 'object' keyword instead of 'class' will not work, as it will prevent any initialization taking place the second time I run the app (the constructor is not being called again and I can't force destroy the instance).
This makes me think it might be worth looking into Android dependency injection but I feel like at least one of my Singletons really needs to be accessed on a lot of places so it might not be an elegant solution either (Probably need to refactor it into smaller functionalities).
The main issue here is the way android handles destruction but I guess I can't change that, I don't see any reason why it keeps all the static values of non activity classes if the application activities are already destroyed.
The question is how do you deal with this cases regardless of the language used? or what do you think are the best practices in this case?
Edit Actually I just did a test with Dagger 2, and the same problem happens, if I use @Provides and @Singleton, the values of member variables on the provided object the second time launching the app are not null so I guess this needs to be dealt with explicitly unless I am missing some more annotations to tell Dagger that the instance should be released at the end of the app life-cycle.
",['singleton']
45092661,How to handle concurrent requests on the back-end of an Uber like app?,"Background
I am looking to design the back-end for an on-demand service app, akin to Uber. In this app, and most others like it, we have many buyers who send requests for a service that must be forwarded to many service-providers providers, etc. - all in real time.
I am planning to create a single REST API for the back-end, implemented in Javascript/Node over a single Postgres database. This back-end would mediate between the buyers and service-providers by receiving buyer requests, matching buyers with available service-provider based on custom criteria, forwarding the requests to service-providers, etc.
With a real-time on-demand service like this, there are many race-conditions that can occur i.e. when multiple buyers are matched with the same service-provider at the same time. I was thinking to handle all of these cases with a web-API flavor of optimistic concurrency control (inspired by this blog post).
Questions

Is a single REST API the right backend solution for this case?
Are there any schemes, algorithms, frameworks, solutions out there
that could handle concurrent service requests while also being
reasonable performant and scalable*?

*Scalable to a reasonable degree, i.e. up to a magnitude of 1000s rather that Uber's millions
",['rest']
19773753,Data Transfer Objects of entities with MN or 1N relationships,"I have 2 entities - movie and actor - that have MN relationship. When designing DTO objects for these entities I am not sure what's the correct way to go.
Movie
@Entity
@Table(name = Movies)
public class Movie extends AbstractBusinessObject {    

    private String name;
    private String short_info;    

    @ManyToMany
    private Map cast;

}

Actor
@Entity
@Table(name = Actors)
public class Actor extends Person{

    private String name;

    @ManyToMany(mappedBy = cast)
    private Set movies;

}

Now concerning the DTOs
I've come across two different ways how to deal with 1N and MN relationships.
Saving only IDs
public class MovieDto {    

    private String name;
    private String short_info;    

    // Long represents Actor's ID
    private Map cast;

}

However as said here I thought that Instead of performing many remote calls on EJBs, the idea was to encapsulate data in a value object, and this approach clearly breaks the rule.
Saving DTOs in DTOs
Another approach would be to store Actor's Dto, instead of its ID.
public class MovieDto {    

    private String name;
    private String short_info;

    private Map cast;

}

It seems to me that this approach would be faster, as I don't have to call the database everytime I need to show actor's name for example.
Is this assumption correct, or would it be better to store only IDs (even considering the space consumption of the second approach)?
Plus the second approach would result in a number of DTOs for one Entity. For instance, I don't need to know what movies has actor played in when looking at a movie page, but I need to it when looking at an actor page.
",['dto']
10080028,Best general-purpose message format for SOA?,"If I have a bunch of servers (eventually groups of servers), each being a different service (SOA), and I want them to be able to

Send requests, receive responses via TCP over a high-throughput, low-latency, unmetered network.
Use a common message format that

Is fast to encode and decode/parse
Supports lists and binary strings
Won't necessarily require updating all services at once (e.g. adding a field should not prevent the outdated services from reading the message and picking out all of the fields they are expecting)


Which format would you guys recommend? I'm currently looking into encoding messages as BSON, but would like to hear some suggestions.
Thanks -)
",['soa']
25611167,Do I need Oauth2 For my Web Apps API,"I am trying to wrap my brain around building an express.js / node.js based REST API. I have a couple of questions...

Do I NEED token based / oauth 1 or 2 security for my api if I'm only concerned about a web application right now (not necessarily phone apps)
Are there any resources to learn how to build this from scratch? I've read literally the first 3 pages of googling rest api with oauth2 authentication express.js and i'm still not grasping it.

",['rest']
47252277,"Firebase database REST API, get throws 401 error","I've spent all the afternoon researching and then checked the related answers and none of them solved my problem, Excuse me if it's duplicated as I didn't find it.
I have a realtime database for my android app. However, I would like to get the formatted json in a REST client (postman), just for comfort (so I can save the json locally for mock purposes).
Here are the rules
{
  rules {
    contents {
      .read true,
      .write false
    }
  }
}

In theory (if I'm not mistaken), I should be able to retrieve the data with
<URL>

But I get this error
Status Code 401 Unauthorized
Access-Control-Allow-Origin *
Cache-Control no-cache
Connection keep-alive
Content-Length 36
Content-Type application/json; charset=utf-8
Date Sun, 12 Nov 2017 180300 GMT
Server nginx
Strict-Transport-Security max-age=31556926; includeSubDomains; preload

I also followed this links explaining authentication in requests 
<URL>
<URL>
So I tried debugging my app, getting the tokenID for the logged user and immediately sending the request in my REST client
 mUser.getIdToken(true).addOnCompleteListener(new OnCompleteListener() {
            @Override
            public void onComplete(@NonNull Task task) {
                String token_id = task.getResult().getToken();
                Log.d(I'm using this, token_id);
            }
        });

And then
<URL>

But still, 401 error, permission denied.
I'm fairly new to firebase and REST clients.
Thanks in advance.
",['rest']
53710288,API Design Architechture - Reverse Gateway?,"We are building a large web api (200+ calls). After it got so big, we separated it out into multiple smaller api's. This made sense because we had multiple products that the customer might not have purchased. 
So we now have an api per product, however, each api needs the same basic architecture - the connection to the database and all of the custom logic for authentication and retrieving tokens needs to be the same for every api. We do not want them to have to get a new token for each api.
We thought about a gateway api, but we are using swashbuckle\swagger and I don't see a way for that to work with the gateway.
The current plan is to make a token api that does all of the token and authentication. The user would call the token api to get a token, and then, when the user calls each of the product apis, those apis would then call the token api to validate the token. Is this good idea? I'm worried about performance of the api when calling another api. We have a mobile app that will be hitting these api's heavily, along with normal customer usage.
",['rest']
41693536,Laravel - restful api,"I'm using the laravel framework. In my case, I need to save the data (login or register for example) in remote database on cloud. 
But the communications with database and laravel, I need to use a rest api. 
I have a php class in laravel with functions (login function for example) and in this function I have created the connection logic to my remote rest API (send email and password).
Now, I made connection to remote database and check if the email and password exists and return back a message (if true then I return the view, false i show a error message). 
Till this it works fine. But I have a problem. Because I am not using the laravel authentication mechanism in routes file. I am unable to use the middleware to prevent direct access to routes without login. What is the best way to add this security? 
I need your help. Thanks a lot.
Regards 
",['rest']
37640080,How to properly supply legacy Firebase JWT token as auth to the REST API?,"I want to use Firebase REST API with custom database authentication tokens.
I took a database secret from project settings at console.firebase.google.com. According to that page, this secret can be used to create custom database authentication tokens using a legacy Firebase token generator.
So I did what they say at <URL> under Generating a Token Without a Helper Library and at <URL>
header='{algHS256,typJWT}'
claims='{v0,iat1465114351,exp1465117951,d{uidtest}}'
b64header=`echo -n $header | base64 -w 0`
b64claims=`echo -n $claims | base64 -w 0`
echo -n $b64header.$b64claims.
echo -n $b64header.$b64claims | openssl sha256 -binary -hmac $SECRET | base64 -w 0

A token generated this way works properly (200 OK)
curl -v -o output.json -D output.txt $URL/test.json?auth=$TOKEN

But when I change just timestamps in the JWT claims,
claims='{v0,iat1465114158,exp1465117758,d{uidtest}}'

I'm getting 400 Bad Request with {error  Failed to validate MAC.} instead.
I noticed that

In the good JWT there are no + signs
In the bad JWT there is a + sign in the signature part

But even if I url-encode the auth parameter,
curl -v -o output.json -D output.txt -G --data-urlencode auth=$TOKEN $URL/test.json

it still fails the same way.
What do I do wrong?
",['rest']
34461967,Large application architecture,"I am trying to architect a large .NET application with at least 16 or 20 modules i am implementing this using Service Oriented Architecture SOA so for now i have only 4 services implemented for only one module. 
One of the four services is the core service which i need to be included in each module because this contains for example Logging , Security etc.. i have no problem to include this in each new service.
I am facing a lot of problems that i need an advice in it.

Do i put all my class libraries in one solution or separate them in multi solutions for now i have about 40 class library.
For database I am now have one database do i separate the database too or let it in one database.

Any guidance for helping me in putting an architect for my application to consider using SOA and high maintainability also not to confuse development team with this large architect  
",['soa']
47493648,Making Jersey API real-time,"I have a Jersey based RESTful API which primarily handles authentication and user management and uses MySQL database. I now need to add chat like features to my web app which probably will scale in the future. I know that there are good toolkits out there to achieving this - FeathersJS, Socket.io, Meteor but they will only force me to use JavaScript and target Node.js as the runtime. I don't want to maintain both Java and Node.js stacks and would like to stick with Jersey (or the Java ecosystem for that matter) as much as I can.
I will be using Angular on the client side.
Is this possible? If yes, what are the different options to help me exploit Jersey to the fullest to also support real-time capabilities?
",['rest']
13038646,WCF as BLL (Middle Tier) and Security techniques,"So bear with me, i am new at MVC and WCF. I already have a set of services (WCF) that exposes my BLL and I am trying to consume those from my MVC.net web application but i am unsure on how to perform security operations here.
These are my app requirements

Be able to consume WCF services using different credentials for every user on the web application
My BLL (WCF) needs to know what consumer is calling it (right now I only have the MVC app but i am planning to add iOS and Andriod calls to it, so later on i will add REST services to the WCF endpoints) Is there any design pattern for this out there? (or should i just use the soap header to include the caller ID? should i use some sort of caller secret or something?)
I need a security mechanism like Tokens or something so I dont have to pass the username and password on every call of the service method (WCF)

What i have so far

WCF uses a certificate and  and   with a custom username validator.
I have manually coded proxies using the contract interfaces instead of generated proxies But I hate the fact that i have to validate username and password every time a call is made to a WCF service. How in heaven can i use Tokens here? like to know if a given token sent on the soap header is valid or not yet expired? i have searched a lot and no tutorial/code/example is clear enough for me to actually start coding that ;(
I am trying to cache the Channelabstract-abstract-factory but should I? i mean, i will need to cache a channer abstract-abstract-factory per logged in user per contract ;( is that ok? what can i do here?

Thanks in advance!
",['mvc']
45146319,Spring - Make microservice only accessible internally,"How can I setup a microservice which can only be called by other internal services. The microservice should not be accessible in public, because it has access to databases with secret information. I already tried to secure the microservice with spring security but in this case I got problems with the FeignClient concerning authorization.
",['microservices']
29970527,Spring Security /j_spring_security_check without JSP,"I need clean URL rather than the extension appended. I'm using the Backbone.js framework in my UI. I have a view built that gathers a username and password and performs a restful request to /j_spring_security_check. 
For some reason, username and password are not being seen by the /j_spring_security_check end point.
Here is the request I'm performing in backbone 
loginModel.save( loginModel.toJSON(), {
    success _.bind(function(response) {
        Backbone.history.navigate('', {trigger true});
    }, this),
    error function() {
        console.log('test');
    }
});

I've tried making the request with the j_username and j_password as attributes of the model as such and setting the url to /j_spring_security_check.
I've also tried passing the params directly in the url as such 
/jspring_security_check?j_username=Xamp;j_password=Z

Both ways get into my auth providers authenticate method but the Credentials and Principal are both blank strings so the auth fails.
When I make my requests I can see in the browser's developer tools that request payload gets setnt down 
{j_username a, j_password a} j_password a j_username a

What is the correct way to make a request to /j_spring_security_check without using a JSP form?
",['rest']
13262631,Immutable data model for an WPF application with MVVM implementation,"I have an application which has a data tree as a databackend. To implement the the MVVM pattern I have a logic layer of classes which encapsulate the data tree. Therefore the logic also is arranged in a tree. If the input is in a valid state the data should be copied to a second thread which works as a double buffer of the last valid state. Therefore one way would be cloning. 
Another approach would be to implement the complete data backend to be immutable. This would imply to rebuild the whole data tree if something new is entered. My question is, is there a practical way to do this? I'm stuck at the point where I have to reassign the data tree efficently to the logic layer.
**UPDATE - Some Code
What we are doing is to abstract hardware devices which we use to run our experiments. Therefore we defined classes like chassis, sequence, card, channel, step. Those build a tree structure like this
                            Chassis
                          /      \
                   Sequence1      Sequence2
                   /    |    \
              Card1   Card2  Card3
             /     \
     Channel1      Channel2
    /        \
Step1        Step2

In code it looks like this
public class Chassis{

readonly var List Sequences = new List();

}

public class Sequence{

readonly var List Cards = new List();

}

and so on. Of course each class has some more properties but those are easy to handle. My Problem now is that List is a mutable object. I can call List.Add() and it changed. Ok there is a ReadOnlyList but I'm not sure if it implements the immutability the right way. Right as in copy by value not reference and not just blocking to write to it by blocking the set methods. 
The next problem is that the amount of sequences and step can vary. For this reason I need an atomic exchange of list elements. 
At the moment I don't have any more code as I'm still thinking if this way would help me and if it is possible at all to implement it in a reasonable amount of time.
",['mvvm']
1752632,Tests for Evaluating an Application Stack or Framework,"I'm looking for a set of scenarios that can be used to assess the overall elegance, strengths and weaknesses of a given MVC framework.
For instance, one such test could be how cleanly authorization is handled when it affects elements in the presentation layer. If the user has permission to see elements within an object, is that decision made in the view or the business logic. Are the two conflated, such that business logic is in code that affects layout of the displayed object?
There are other problems within this general domain, and, given that MVC has been around since 1979, I'm sure that there are books that deal with this sort of thing. However, I'm not looking for yet another reference on patterns in enterprise architecture. I'm looking for a compendium of problems and pitfalls. So, if you've any test scenarios that you like to throw a framework up against, or if you have any suggestions for books that deal with this sort of thing, I'd be grateful were you to share them.
",['mvc']
6822255,security handling in wcf web api and wcf jquery support,"What are the security options in wcf next (wcf web api and wcf jquery support) ? And if a client requesting to a wcf service by jquery, how can wcf dedect if it's really my client code or a spider app / my altered js (requesting with parameter combinations) that is crawling my database ?
Best Regards,
Serdar Irmak
",['rest']
54646337,Authorization in controller,"I have fallowing code for authorization, i want to add role authorization, lets say 3 types of users. 
    In database I have User (id, username, password, UserRole).
    I watched many tutorials but nothing that I found helpful for this kind of problem.
 public class LoginController  Controller
    {
        // GET Login
        [HttpGet]
        public ActionResult Login()
        {
            return View();
        }


        [HttpPost]
        [ValidateAntiForgeryToken]
        [OutputCache(NoStore = true, Duration = 0, VaryByParam = None)]
        public ActionResult Login(LoginModel model)
        {

            if (ModelState.IsValid)
            {
                User user = model.login(model.UserName,model.Password);
                if (user != null)
                {
                    FormsAuthentication.SetAuthCookie(model.UserName, true);

                    this.Session[user] = user;
                    return RedirectToAction(Index, Home);
                }
                else
                {
                    ModelState.AddModelError(, Niste uneli ispravne podatke!);
                }
            }
            return View(Login, model);
        }



        [Authorize]
        public ActionResult Logout()
        {
            FormsAuthentication.SignOut();
            this.Session[user] = null;
            this.Session.Abandon();
            return RedirectToAction(Index, Home);
        }


    }

Now I have [Authorize] in every controller, I want to be able to have [Authorize(Roles = temp)] , [Authorize(Roles = admin)] and so on.
",['mvc']
29957080,Ruby Exposing MySQL query ability to users via RESTful API,"There are similar posts like this on the internet, but they seem to be targeted towards lower level languages like Java. NetBeans for example seems to have this kind of functionality. 
Here is what I want to do
I have a large dataset of items. I want to create a RESTful API that would enable my users to perform complex queries to retrieve data from the MySQL database on my backend. 
The API needs to be able to

SELECT a table to retrieve values from
Be able to use common MySQL aggregate functions such as COUNT, SUM,
and AVG on the results
Create WHERE conditions

Security is not an issue as this my simply an MVP for now. On a future iteration I will take security into consideration. Are there any Ruby gems which provide a framework for constructing this kind of system?
I am open to using either Sinatra or Rails for this system.
",['rest']
11553201,What is better single or multiple routes for REST service?,"I have multi-tenant SaaS application and on startup I setup routes like this
<URL> 
<URL>
<URL> 
<URL>
<URL> 
<URL>
<URL> 
<URL>

When I add new customer I have to recycle pool so routes rebuild. I'm not sure if that's the best approach for what I'm doing...
I can create just 2 routes 
<URL> 
<URL>

And then pass AccountId in HTTP header along with my auth information. Would it be cleaner? What do you think about performance, having less routes should be benefitial, correct?
",['rest']
6433480,RESTful actions/services that don't correspond to an entity?,"I like RESTful for its simplicity and how it avoids the cruft of normal 'enterprise' systems like SOAP, or the binary-hardness of DCOM and RPC.
But REST seems more suited to database entities than more abstract services. I was wondering if you could advise me on how you'd do these situations
For example, suppose I have a RESTful web-service for a normal database system (say, a dairy shopping site), so I'd have /products/eggs/battery and /products/milk/skimmed
Doing an INSERT would be achieved by making a POST to /products/eggs.
But how would you do a clear all command? The DELETE verb is only suitable for single entities. And a DELETE /products/milk implies deletion of the milk product category itself rather than just all products within the milk category. And what if you want to accomplish both?
Another question I have relates to web-service actions that are not related to an entity. For example, if I'm designing a web-service for a password database, I'd have operations like GET /passwords/stackoverflow.com which is fine, but I would also have operations to disable the website in case of intrusion detection. Under the 'old school' web-service model I'd have a method simply named disableWebsite, however I can't create a HTTP verb called DISABLE and a resource called /website (so the request would be DISABLE /website). What's the solution here?
Finally, how do you reconcile HTML Forms with RESTful? Web forms can only make GET requests using querystrings or POST. If I have a search form I want it to request /products/search/{query} but right now the request would look like /products/search?query={query}. 
",['rest']
51618042,How to authenticate on a users that were made using ASP.NET Forms Authentication,"My company maintains a legacy ASP.NET webforms application which uses Forms Authentication for access to the site. We are looking to build a mobile application which would utilize a stateless REST API with token based access. The problem is that the user's passwords were generated on the site and are hashed in the User database. I need a way to authenticate against those hashed passwords by somehow accessing the Forms Authentication's authenticate method or build some adapter/middlewear to broker the exchange.
We have done much research on this problem and haven't found any viable solutions as of yet. Any help would be very appreciated.
",['rest']
34355595,Approach for web application to act as Restfull application,"we are trying to develop a web application where controllers(Servlets) should act as restfully services , initially browser will act as client and then in future there could be third party applications which will be consuming services from the same controllers.
All controllers will return JSON data and angular JS will use this and display content in browser for the web application and for the third party application they will directly invoke rest services.
My question are as follows

If i am developing Restful service then should I not use HTTP-session
i.e should my controllers be completely stateless  
If my application should be stateless then how will I overcome the
shortage of    HTTP-session object ( how do i carry the user specific
data which    could be required in different screen)
How will the authentication    be handled for the third party
application , should user provide    credentials in each request ?

",['rest']
51582565,Creating a Web Frontend using a REST API built for mobile application,"I have a REST API built with Slim framework. The API contains all the Models of the databases and has various endpoints that are accessed by my mobile apps. Now I want to build two different Web Frontend, 

A frontend that does the same things as the mobile app.
A frontend that lets admins access and modify limited data on the database

For the first one, the API already supports everything I need. For the second one, I have to edit my current API app to support these new types of modifications and also have an API authentication method for admins.
My questions are,
1) Will going through API for the frontend be slower compared to direct access code
2) If I were to provide direct access to just the admins, I have two options, 

build a new app and reuse all the models. And this means including all my models manually in the new app.
Edit the current API and have admin access controller return views instead of json (which I think is a bad practice)

I have checked some other answers on stack overflow, and although most recommend going through API, it is slower than executing directly.
My current thinking is to let the #1 frontend go through API as all the endpoints already exist. For the #2, as no API endpoints exist, and I will still have a build new controllers, I will just make a separate project that uses the same models as the API project, but this will mean having a web frontend being served directly from the API server itself. 
Edit I know I am kind of answering my own question, but what I want to know is the best design practice to do this.
",['rest']
7655312,How to use activerecord-sqlserver-adapter with TinyTDS *and* an Integrated Security connection on Windows *without* saving a password in plain text,"I'm trying to use Rails 3.1. with the activerecord-sqlserver-adapter (3.1.1) and tiny_tds (0.4.5) on a Windows machine.  In reading about TinyTDS and it's use of FreeTDS it looks like I can use Integrated Security (aka Windows Integrated security/NTLM) by putting a domain-qualified name as the user name (e.g. DOMAIN\userbob).  But the docs still want me to type my domain user's password in the database.yml file.  That's bad practice because it's insecure and doesn't take advantage of single-sign on, which is part of the point for Integrated Security.
Can I connect without saving a password in plain text in a file?  e.g.
developement
    adapter sqlserver
    mode dblib
    dataserver localhost
    database dev_db
    username DOMAIN\userbob
#    password no_no_please_dont_make_me_type_it_here

But, even if I put a password I get the following error
TinyTdsError Unable to connect Adaptive Server is unavailable or does not exist
    from C/Ruby192/lib/ruby/gems/1.9.1/gems/tiny_tds-0.4.5-x86-mingw32/lib/tiny_tds/client.rb60in `connect'
    from C/Ruby192/lib/ruby/gems/1.9.1/gems/tiny_tds-0.4.5-x86-mingw32/lib/tiny_tds/client.rb60in `initialize'

I know my server is running and the current user context can connect because this works
sqlcmd -S localhost -d dev_db -E

Any insights?  Is it possible?  If not, it should be.
",['activerecord']
33006570,How do I test restful APIs with constantly changing and random user defined data,"I'm developing a clean-up API (github.com/Shadowys/btapi) for a Mediawiki application, Baka-Tsuki to pull meaningful data from the novel project pages like author, volume lists and cover images. The pages are user-defined and formatted in various ways decided by the translator(user). The pages are also updated and created daily, with the creation of new formats occurring sporadically. However, the API parser is able to handle most, if not all of the current pages, no matter their format.
Baka-Tsuki is not going to change into a database-based application in the near future, since the wiki is currently the most user friendly and cost-effective way to share translations, and we don't have enough developers to constantly work on a new application.
I'm looking into using mocha to automate testing of the API but as the input data constantly changes, testing is nearly impossible without checking every page available. I've looked at twitter and facebook testing methods but they have constantly formatted user input.
Is this case, which testing method should I refer to? Should I run the test simply based on the types returned, and the availability of the values returned or do I have to make a copy test-page to stimulate testing?
",['rest']
31670099,"Search users by first, middle and last name","In my Rails project I have a table that looks like this
  create_table people, force cascade do |t|
    t.string   first_name,  limit 255
    t.string   last_name,   limit 255
    t.string   middle_name, limit 255
    t.datetime created_at,              null false
    t.datetime updated_at,              null false
  end

and I have a query that search by first_name or by last_name
Person.where(lower(people.first_name) LIKE lower(q) OR lower(people.last_name) LIKE lower(q), q 'Melanie')

And the question is is there any way to refactor this query to search by first_name, last_name, and middle_name? My database is Postgresql.
EDIT
When I have Person with first_name Bill and last_name Gates, and as q I set 'Bill Gates' it will not search proper record. I want to fetch that record.
",['activerecord']
52924247,"Pass messages between requests with a REST API (JSON, XML, HTML...)","Let's imagine a REST API that can return JSON, XML, HTML and other formats.
In case of a browser web client without JavaScript enabled, the API return HTML. Tokens are used for authentication and authorization.
In a classic website project, it can happen that a redirection need to be made from a page A to another page B. It can be used for example to display a welcome message or an error message in another page. In this case, to display a message (flash for example) from page A on the page B, we would normally use session. Two simple (and minify) examples in express (but the concept is the same in other technologies)
// With session directly
const session = require('express-session');

app.use(session({ /* ... */ });

function (req, res, next) {
  req.session.message = 'Welcome, you are connected';
  return res.redirect('/');
}

${ session.message }

// With a library as connect-flash
const flash = require('connect-flash');

app.use(flash());

function (req, res, next) {
  req.flash('error', {
    message 'An error!',
  });
  return res.redirect('/login');
}

${ flash.message }

Now, based on REST principles, to respect the stateless constraints, it should not use sessions which store a state between two requests. 
My question is  How a stateless web server should normally pass messages between two requests ? (in case of a redirection)

Session  Not stateless as required
DB ?
Query string ?
Cookie ?
Other ?

Note  I know how implement these solutions but i am asking for a right way to do that in the case of a stateless web server. How normally REST API implement it ?
Following this question, I have two (optionnal) misunderstandings. 
Based on this stack overflow answer 

That does not preclude other services that the web server talks to
  from maintaining state about business objects such as shopping carts,
  just not about the client's current application/session state.

What does other services means here ?
Based on this comment from the same answer 

The authentication can be implicit in the state, do you think that
  facebook does a database access on every request of its REST API? Or
  Google for that matter? hint no

What does it means by implicit in the state ? If it is that they use token or a similar authentication process, then they should make a database access each time to get a fresh user, no ?
Thank you in advance.
",['rest']
13989320,Many Page views counter with a @Singleton,"AFAIK @Singleton EJB is suited to count page views, with something like
@Singleton
public class CounterBean {
    private int hits = 1;

    // Increment and return the number of hits
    public int getHits() {
        return hits++;
    }
}

That works fine for a web application of one page, What if the web app has let's say 1K pages, and we want to show the counter for each view each time it's loaded. 
Would a @Singleton be appropriated for this? I mean, Would this be efficient? (Having many beans to update frequently a single instance)
My guess a single instance to manage all the web pages counter is not efficient. Imagine thousands of @RequestScoped beans updating a Map  in a @Singleton, will lead to heavy concurrency...  
For updating persisting values on redeployments, I was thinking in using @PostConstruct (pull from database), @PreDestroy (push to database) annotations.
Page view counter is to be shown in each view.
The number of web pages is dynamic. 
I understand that Google Analytics does this job, but the question is how to make this in Java EE. 
App Server Jboss 7.1
",['singleton']
23724358,How to get current customer id magento rest api,"I want to use magento rest api authorization for my web application customers, I found in docs that there is /customers/customerId request, to get information about user, but I can't understand, how to get customerId to make this request. Is there such a method in Magento REST API and if not, how I can get authorized customer Id via REST API.
",['rest']
24220884,node.js - REST API security. SSL or OAuth2?,"I am building a nodejs express REST API. I have the following setup.
API server(nodejs) returns data from mongodb.
Webserver(nodejs) hosting angular web application.
Little bit of google-ing told me I should use OAuth2 for securing my REST API.
Some links also suggested me to use SSL.
I am not clear whether SSL is alternative solution to OAuth2 or I should use it along with OAuth2 for increased security?
If I use SSL for communication between my Webserver and API server! Do I still need to use OAuth2?
I am a first time API builder. I am so sorry if this question sounds vague.
",['rest']
37639209,Implementing sessions and security in REST web apps?,"Please Note
This is a long post.
Not sure if the title of the post is even suitable (
Down-voters please provide some constructive feedback to improve this post before you take-off. 
==========================================================
I am implementing a simple REST API in Java which exposes 3 services

Allows clients to register their applications. POST /register


Request

{
display_name  MyAwesomeApplication 
}


Response

{
application_id  abc123def123... ,
application_secret  abc123def123... ,
display_name  MyAwesomeApplication 
}


Allows applications to authenticate before sending log messages. POST /auth

This endpoint uses a simplified version of Basic Authentication

Header

Name                         Value
Authorization                application_idapplication_secret


Response

{
access_token  c47026d9¬≠90bf¬≠4480¬≠a259¬≠a953bc103495 
}


Sends log messages.  POST /log


Header

Name                         Value
Authorization                access_token


Request

{
application_id  abc123def123... ,
logger  com.logger.service.Uploader ,
level  Error ,
message  The communication pipeline is broken. 
}


Response

{
success  true|false
}

So, far I have implemented these functional requirements successfully, but I have no clue how to implement non-functional requirements like
1. The sensitive data must be encrypted.
2. Only one active session per application(user of my web service) is allowed.
3. The session lifetime must be configurable in the database.
4. All log requests must be handled asynchronously.
5. Log endpoint requires authentication through an access token.
6. Implement a rate-limiting request to avoid possible attacks, allowing only 60 requests per minute by application. If you use up your 60 api calls then you will receive ‚Äúrate limit exceeded‚Äù message and must wait 5 minutes before can make requests again.
Can someone please point me to some resources/tutorials targeted to these use cases? 
I have read practically everything I could get my hands on in SO and google and the more I am reading the more I am getting confused. May be instead of trying to learn these skills in terms of REST, I should just try to implement them in a very basic client-server web app, please suggest if this should be the case.
This is my first REST web app, so please consider me a complete noob and guide accordingly.
",['rest']
1033779,ddd with nhibernate and sql server,"I have a reference application that I use to work through DDD issues, and my current focus is on persistence. An alternate title for this post could have been DDD / TDD persistence tools and methods, but that is a (very) broad topic and I do have a specific question on SQL Server.
I'm going to outline my current tool set in this paragraph as background, so feel free to skip it to just answer the question. I'm using NHibernate, Fluent NHibernate, Rhino, Visual Studio 2008 and SQL Server. My current thinking is to use NHibernate to generate the db after any data mapping change, look at the generated tables in VS 2008, and see if my persistence mapping tests all pass. I had originally wanted to use SQLite as the test db, but I am skeptical that it is an accurate gauge of correct mapping in some ways (like referential integrity). I then tried using SQL Ce, but found it frustrating to eye ball the generated tables with VS. That's why I'm now figuring to just use SQL Server in the first place.
The following command object generates the db
public class GenerateNewDb_SqlServer  ICommand
    {
        public GenerateNewDb_SqlServer(Configuration cfg)
             base(string.Format(Update a Sql Server Database))
        {
            _cfg = cfg;
        }

        public override void Execute()
        {
            try
            {
                var schema = new SchemaExport(_cfg);
                schema.Create(true, true);
            }
            catch (Exception ex)
            {
                Console.WriteLine(Schema Export Error Message  + ex);
            }
        }
    }

The problem is that old database objects are still there. I need to somehow delete the whole sql server db each time before using the NHibernate schema tool to create it. Can someone please tell me how to do that in code?

Is there something off the NHibernate.Cfg.Configuration object I can use to drop the db? What would the code look like?
Cheers,
Berryl
",['ddd']
33728813,Is an Empty Table for implementing Reverse Polymorphism and ActiveRecordBase okay?,"I have spent a lot of thought on this situation and cannot figure out what the best modeling system is
There is a Test. A test can have a variety of of TestItems. These TestItems can (currently) consist of TrueFalseQuestions, MultipleChoiceQuestions, ShortAnswerQuestions, and TestInfo.
All of the models will implement some sort of Printable module. They will all be printable, but each model handles its printing in a different way. All models will also have a position as they are sortable in relation to all other models. All models can belong to a test.
All models of type XXXQuestion will print numbers when they print. The TestInfo will not do that.
MultipleChoiceQuestions will have Answers as children.
I have tried creating a TestItem class that uses reverse polymorphism and a shareable question module
class TestItem < ActiveRecordBase
  belongs_to test
  belong_to item, polymorphic true

  db_fields main_text, position, item_id, item_type

  def sort(params)
    ...
  end
end

module QuestionPrintable
  def get_print_number
    ...
  end

  def print
    raise NotImplementedError
  end
end

module Question
  def self.included(klass)
    klass.class_eval do
      include QuestionPrintable

      has_one test_item, as item, dependent destroy
      delegate test, main_text to test_item
    end
  end
end

class MultipleChoiceQuestion < ActiveRecordBase
  include Question

  has_many answers

  def print
    number = get_print_number
    ...
  end
end

This would work, except that some models (like TrueFalseQuestion) would not actually expand the TestItem class. They would have no extra information in the TrueFalseQuestions table, but they would implement methods unique to TrueFalseQuestions.  I realize I could also wrap a TestItem in a TrueFalseQuestion wrapper whenever it's instantiated but then I would need to store the kind of the question on the TestItem to know when to do that. So, in some sense, the TrueFalseQuestion < ActiveRecordBase class is actually storing the kind implicitly just by existing. I don't know if that is a valid use of ActiveRecordBase.
All the questions do share the printing features of a number (and several behaviors I anticipate needing, just not quite yet) that are not shared with other types of TestItems (i.e. TestInfo). Additionally, some Question types will store extra data right now. And I believe that all of them will store more data as this problem evolves. So I do think that abstraction is helpful. Is it okay to have an table that more or less exists to allow the implementation of a polymorphic ActiveRecord model?
Also, having the text on the TestItem prevents a crazy amount of joins to display the main text of all items for a test.
The big difficulty, is if I do this a different way (for example not having a TestItem class and just a bunch of shared modules or storing these all as TestItems with a kind attribute), I need to start switching behavior on the class type or an attribute, and I try to avoid any code that tests on class type or has so much behavior switch based on a attribute value.
I think in general those solutions can be achieved with duck typing, which would work with my empty ActiveRecord class, but this one just has me puzzled.
EDIT
Another solution that occurred to me, that would prevent switching on kind would be to use some sort of kind value in the TestItem and use it to create a wrapper
class TestItem < ActiveRecordBase
  belongs_to test

  attr_accessor main_text, position, kind

  def wrapped_object
    klass = kind.constantize
    klass.new(_needed_params)
  end
end

class TrueFalseQuestion # DO NOT INHERIT
  attr_accessor kind, position

  def print
    ...
  end
end

I left out the various modules to not distract from the general solution, those can be easily implemented.
So now my potential debate is

Empty Database Tables


Positives


No wrappers needed
More extendable in the future

Negatives


It's an empty table....
Possible YAGNI


Method that returns wrapped object


Positives


Solves the immediate problem without introducing extra database tables
Allows for all the same abstractions in the previous solution

Negatives


Relies on the kind attribute (maybe not bad in this case?)
If the domain changes this could easily become too complex to maintain



",['activerecord']
2010621,MVC dbml and weborb for .net performance,"We have a flex application that runs along side a mvc .net application. Our flex app communicates with .net via Weborb. We recently put our entire database schema into a single dbml file. Previously we had the database schema split out into several dbmls. The problem we have run into since consolodating into one dbml is that our weborb calls in the flex are taking 300 to 400 ms longer than they did when we had several dbmls. 
This doesn't seem to make sense to us at all. Anyone have any insight?
",['mvc']
37702372,Efficiently communicating between frontend and backend sites without exposing backend,"I'm trying to figure out whether my current approach will lead me into performance issues into the future, before developing further with this design, and whether there are better ways of doing this. I think this makes the most sense if I provide some context on the design first
Current Design
I currently have my environment designed with two separate servers, let's call them frontend and backend.

Frontend
This server is open to the world. Customers access this site to view our product, make purchases, and will soon be able to view their account related information.
Backend
This server is where all information is held in a database.

Communication
The only way that the frontend currently needs access to the backend, is when the user authenticates with their license and downloads our product. To do this, the frontend calls a PHP script, which sends a JSON request to the backend server via curl_exec. The response from the backend tells the frontend how to handle that download request (e.g. license invalid).
Reasoning
The reason for this design is to avoid exposing the backend details to the user. Client-side, all the user sees is a request being sent to the frontend server. If the frontend server is ever compromised, anyone reading through how the frontend is built has no access to the backend DB, unless they know exactly what parameters to send to the backend API. Even then, it only gives access to a very low subset of information, depending on what the API exposes.
The Problem
The only time this cross-server communication happens right now is when a user tries to download our products using their license details. Relatively speaking, the traffic through this API between both servers is relatively low.
My concerns are that I want to build a user control panel. From here they can log in with their license/account, they can view their active licenses, access details on previous orders they made, etc. This already means all these pieces of information are only available through the backend, so I'll need to expose them through the API - which is fine. The issue here is that every request the user makes through the control panel (even just refreshing the page) will build up a lot of traffic between both servers. 
Questions
From the experience of developers here, is this communication design scalable? I'm worried I'm building around a bottleneck, which will just result in a slow user interface, since the frontend would end up waiting on a lot of requests it tunnelled through to the backend. 
What are your thoughts? Has anyone faced a similar challenge? How did you overcome that challenge? What is the best practice to achieving this kind of requirement? I hope this question doesn't come across as too vague.
",['rest']
8702135,How to expose JAX-RS DTOs from entities for REST-Clients?,"I have a Java EE 6 web application that offers it's data via a JAX-RS REST web service.
The entities are annotated with the JPA annotations as well as with the javax.xml.bind JAX annotations.
My aim is to assemble a client-jar out of my web-app project that contains the JAX-RS annotated DTO classes to be used for JAX unmarshalling in clients of my web-app.
Putting the raw entities in the client jar is not an option because of the JPA annotations, which would lead to bogus dependencies for the client.
Is there a way for doing this without writing the JAX-RS classes twice, for the web-app and the clients?
I thought of annotation processing and killing all JPA annotations in the entities, that's quite techy, but not very handy.
My second idea is to extract an interface of the needed getters/setters of the entities. The question here is how to handle the JAX annotations that are placed at the class members and at the getters.
Both ways seem to work somehow. But is there a general purpose solution for that task?
Hint yes, i'm aware of the way to expose the JPA-Entities directly via rest and its coupling drawbacks to evolution etc =)
",['rest']
16496471,Simulate p2p network traffic on a single computer,"What is the best way to simulate a network in Java?
I'm in the early stages of a networked peer to peer project, and to determine some of the required characteristics of the clients I'd like to be able to simulate 100+ instances concurrently on my PC. 
Ideally I'd like to create a simulation version of the sockets, with their own inputs and output streams. Eventually, I'm going to use these streams for data transfer instead of just moving data around between java objects, so what I'm wanting to simulate is the kind of latency, data loss and other errors you might get in an actual network.
Ideally these simulation methods would be very close to the actual stream standards of java.net.*, so I wouldn't need to do much of a rewrite in order to move from simulation to the actual client.
Can anyone point me in the right direction?
",['p2p']
11216484,Media data upload and performance,"I need to create RESTful API for uploading media data. I need to be able to handle hundreds (thousands) of simultaneous requests. Once data is uploaded to my server, we are going to store it on Amazon S3 and populate some meta data into database. Could you advice in a few questions
1) Which language is better for these kind of tasks ? (I'm familiar with PHP and Perl) 
2) What about server? (nginx ?)
3) We need to be able to scale easily in case there are a lot of requests
4) Anything else you could point out and advice ?
Thank you
",['rest']
32915964,Spring - RestTemplate Error calling a https rest service (Certificate error),"I call in tomcat war a rest web service. I do the web service invocation with this
    public UsuarioDTO validarDatosToken(String token, boolean incluirRoles) throws ModeloException, DAOException {

        RestTemplate restTemplate = new RestTemplate();
        UserRestVO page = restTemplate.getForObject(<URL> UserRestVO.class);

        if (page != null amp;amp; page.getStatusResult() != null amp;amp; page.getStatusResult().getStatusCode().equals(OK) amp;amp; page.getUser() != null) {
            ------------
            return datos;
        } else {
            throw new ModeloException(ErroresGeneralesEnum.ERROR_TOKEN_CADUCADO);
        }
    }
}


public Authentication authenticateReal(Authentication authentication) throws AuthenticationException {

    String username = authentication.getName();
    String password = (String) authentication.getCredentials();

    UsuarioDTO usuario = null;
    try {
        usuario = usuariosService.validarDatosToken(username, true);


    } catch (Exception e) {
        e.printStackTrace();
        Logger.getLogger(CustomAuthenticationProvider.class.getName()).error(e);

        throw new BadCredentialsException(Username not found.);
    }



}

The following error is produced when web service is called. I try to do a lot of things but notting works
I think that the problem is with the certificate but i dont solve it.
¬øDo you have any idea?

org.springframework.web.client.ResourceAccessException I/O error on GET request for <URL> Error constructing implementation (algorithm Default, provider SunJSSE, class sun.security.ssl.SSLContextImpl$DefaultSSLContext); nested exception is java.net.SocketException java.security.NoSuchAlgorithmException Error constructing implementation (algorithm Default, provider SunJSSE, class sun.security.ssl.SSLContextImpl$DefaultSSLContext)
      at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java567)
      at org.springframework.web.client.RestTemplate.execute(RestTemplate.java512)
      at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java243)
      at custom.service.usuarios.impl.UsuariosServiceImpl.validarDatosToken(UsuariosServiceImpl.java69)
      at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
      at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java57)
      at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java43)
      at java.lang.reflect.Method.invoke(Method.java606)
      at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java317)
      at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java190)
      at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java157)
      at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java98)
      at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java262)
      at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java95)
      at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java179)
      at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java207)
      at com.sun.proxy.$Proxy33.validarDatosToken(Unknown Source)
      at custom.view.filter.CustomAuthenticationProvider.authenticateReal(CustomAuthenticationProvider.java48)
      at custom.view.filter.CustomAuthenticationProvider.authenticate(CustomAuthenticationProvider.java37)
      at org.springframework.security.authentication.ProviderManager.authenticate(ProviderManager.java156)
      at custom.view.filter.UsernamePasswordAuthenticationFilter.attemptAuthentication(UsernamePasswordAuthenticationFilter.java103)
      at org.springframework.security.web.authentication.AbstractAuthenticationProcessingFilter.doFilter(AbstractAuthenticationProcessingFilter.java211)
      at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java342)
      at org.springframework.security.web.authentication.logout.LogoutFilter.doFilter(LogoutFilter.java110)
      at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java342)
      at org.springframework.security.web.context.request.async.WebAsyncManagerIntegrationFilter.doFilterInternal(WebAsyncManagerIntegrationFilter.java50)
      at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java107)
      at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java342)
      at org.springframework.security.web.context.SecurityContextPersistenceFilter.doFilter(SecurityContextPersistenceFilter.java87)
      at org.springframework.security.web.FilterChainProxy$VirtualFilterChain.doFilter(FilterChainProxy.java342)
      at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java192)
      at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java160)
      at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java344)
      at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java261)
      at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java243)
      at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java210)
      at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java225)
      at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java123)
      at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java472)
      at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java168)
      at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java98)
      at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java927)
      at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java118)
      at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java407)
      at org.apache.coyote.<URL>
      at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java579)
      at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java312)
      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java1145)
      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java615)
      at java.lang.Thread.run(Thread.java745)
  Caused by java.net.SocketException java.security.NoSuchAlgorithmException Error constructing implementation (algorithm Default, provider SunJSSE, class sun.security.ssl.SSLContextImpl$DefaultSSLContext)
      at javax.net.ssl.DefaultSSLSocketabstract-abstract-factory.throwException(SSLSocketabstract-abstract-factory.java198)
      at javax.net.ssl.DefaultSSLSocketabstract-abstract-factory.createSocket(SSLSocketabstract-abstract-factory.java205)
      at sun.net.www.protocol.<URL>
      at sun.net.NetworkClient.doConnect(NetworkClient.java162)
      at sun.net.www.<URL>
      at sun.net.www.<URL>
      at sun.net.www.protocol.<URL>
      at sun.net.www.protocol.<URL>
      at sun.net.www.protocol.<URL>
      at sun.net.www.protocol.<URL>
      at sun.net.www.protocol.<URL>
      at sun.net.www.protocol.<URL>
      at org.springframework.<URL>
      at org.springframework.<URL>
      at org.springframework.<URL>
      at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java551)
  Caused by java.io.IOException Invalid keystore format
      at sun.security.provider.JavaKeyStore.engineLoad(JavaKeyStore.java650)
      at sun.security.provider.JavaKeyStore$JKS.engineLoad(JavaKeyStore.java55)
      at java.security.KeyStore.load(KeyStore.java1214)
      at sun.security.ssl.TrustManagerabstract-abstract-factoryImpl.getCacertsKeyStore(TrustManagerabstract-abstract-factoryImpl.java221)
      at sun.security.ssl.SSLContextImpl$DefaultSSLContext.getDefaultTrustManager(SSLContextImpl.java528)
      at sun.security.ssl.SSLContextImpl$DefaultSSLContext.(SSLContextImpl.java495)
      at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
      at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java57)
      at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java45)
      at java.lang.reflect.Constructor.newInstance(Constructor.java526)
      at java.security.Provider$Service.newInstance(Provider.java1240)
      ... 64 more

",['rest']
6088494,Iterating over a Scala wrapped list,"I need to encapsulate a list in a separate Object in Scala acting as a wrapper class for my collection. I need this to implement some methods to act with the list (in detail I need to find objects in the List which are associated with other object in the list).
So first of all my code
object Axons {
    var axonList=List[Axon]();
    var pos=0;
    def init(al List[Axon]) {
        axonList= al;
    }
    def reverse() List[Axon]  = axonList.reverse
    def get(count Int) = axonList(count)
    def getList() List[Axon] = axonList
    def length() Int = axonList.length

}

Now iterating happens like
for (axon 
This looks kinda ugly to me, but I could not figure out how to implement an Iterator which is usable multiple times to iterate over the collection.
Another approach, just using the plain list, is to define a function which uses fold to shrink the list just holding the objects I want to have.
What you think is a more common way?
Filter to a seperate list just holding needed objects or using an iterator.
In my opinion it would be cleaner to encapsulate my Axons collection in a seperate object, from a software desing point of view.
What you think fits best for the problem?
(If you ask yourself what I'm doing and what an axon is; its a part of a neural network <URL> and the Axons collection wraps the connections between a source and a destination neuron)
thanks and kind regards
=================================================
Solution from Felix
object Axons extends Traversable[Axon] {
    var axonList=List[Axon]();
    def init(al List[Axon]) {
        axonList= al;
    }
    def reverse() List[Axon]  = axonList.reverse
    def get(count Int) = axonList(count)

        //look here!
    def foreach[U](f Axon=> U) Unit = axonList.foreach(f)
    //end ... 
    def length() Int = axonList.length
    def findAxonsBySource(sourceNeuron Neuron) List[Axon] = {
        axonList collect { 
            case axon Axon if axon.getSourceNeuron == sourceNeuron  => axon 
            }
    }
}

",['iterator']
6197691,Is it ideal to call 3 times to the webservice to get data in RESTful model or once and get all it together - IN MOBILE APPLICATION?,"We are developing a mobile application(iPhone, Android, WM) which mainly connects with the server using RESTful services. We are in the process of developing the webservices which are RESTful. The question here is .. we have a details window for the customer where he sees his basic info, comments by others, his comments, votes etc. All these are stored in different tables in database. 
The Urls are designed like this now..
/User// -- To get basic info
/User//Comments -- To get the comments
/User//Votes -- to get the votes

Is it ideal to call 3 times to the server from the mobile app and get info separately or get everything together in one call in proper xml/json format? The concern here is the performance and also we dont want to break the the importance of RESTful webservices?
What do you suggest?
",['rest']
1224450,Is it possible to use a Strategy pattern for data structure with no common ancestor?,"I have two data structure classes (this is a simplified version of my code) 

Animal Has one property  ‚Äúint Age‚Äù 
Person Has one property ‚ÄúDateTime Birthday‚Äù

What I am trying to accomplish is to compile ‚ÄúUploading‚Äù (persisting to database), which is common across all different data structure classes.
So mainly my goal is to have a small Upload method that looks like 
   foreach (TypeName typeName in Enum.GetValues(typeof(TypeName)))
   {
      IDataPopulator populator = 
            new Dataabstract-abstract-factory().CreateDataPopulator(typeName);
         populator.Populate(string.Empty);
   }

But the problem is that, populator returns an object instances of different types, which I am having trying to encapsulate since they have no common properties.
(IDataPopulator.TResult Populate(string data) in the code below)
Is there a way to get around this? Or does Strategy pattern not fit for this kind of scenario? 
Here is the code I‚Äôve been working with
public class Program
{
    public static void Main()
    {
        foreach (TypeName typeName in Enum.GetValues(typeof(TypeName)))
        {
            IDataPopulator populator = new Dataabstract-abstract-factory().CreateDataPopulator(typeName);
            populator.Populate(string.Empty);
        }
    }
}

public enum TypeName { Person, Animal }
public class Person { public DateTime Birthday { get; set; } }
public class Animal { public int Age { get; set; } }

public interface IDataPopulator
{
    TResult Populate(string data);
}

class AnimalDataPopulator  IDataPopulator
{
    public Animal Populate(string data)
    {
        // create an instance of Animal using data
    }
}

class PersonDataPopulator  IDataPopulator
{
    public Person Populate(string data)
    {
        // create an instance of Person using data
    }
}

public class Dataabstract-abstract-factory
{
    public IDataPopulator CreateDataPopulator(TypeName typeName)
    {
        switch (typeName)
        {
            case TypeName.Person
                return new PersonDataPopulator();
            case TypeName.Animal
                return new AnimalDataPopulator();
            default
                throw new ArgumentOutOfRangeException(typeName);
        }
    }
}

public class UploadContext
{
    private readonly IUploader _Uploader;
    public UploadContext(IUploader uploader) { _Uploader = uploader; }
    public void Upload() { _Uploader.Upload(); }
}

public interface IUploader
{
    void Upload();
}

class PersonUploader  IUploader
{
    private Person _Person;
    public PersonUploader(Person person) { _Person = person; }
    public void Upload()
    {
        Console.WriteLine(Uploading person...);
    }
}
class AnimalUploader  IUploader
{
    private Animal _Animal;
    public AnimalUploader(Animal animal) { _Animal = animal; }
    public void Upload()
    {
        Console.WriteLine(Uploading animal...);
    }
}

",['strategy-pattern']
34133533,How to compare performance Web Service implemented in two or more framework?,"At the University I have project to do Performance comparison of two or more Web services implemented in different framework. So is a good idea to compare Axis2, CXF and Metro (All three will use SOAP) or is it better to compare sevice that uses the SOAP with service that uses REST (eg Axis2 and Jersey)?
How can I measure the performance all services on two computers in the home network? Should I measure response time by the client class?
",['rest']
1237241,Live ID with MVC with out ASP.NET Membership,"Does anyone know is there a way to implement Windows Live ID authentication into your ASP.NET MVC site. I am moving a project from Web Forms to a MVC solution and do not want to rebuild the database so ASP.NET Membership mentioned in windows-live-id-in-asp-net-mvc is not a valid solution.
And just to avoide this question the customer not want to use Open ID.
",['mvc']
5826210,Rails Order with nulls last,"In my Rails app I've run into an issue a couple times that I'd like to know how other people solve
I have certain records where a value is optional, so some records have a value and some are null for that column.
If I order by that column on some databases the nulls sort first and on some databases the nulls sort last.
For instance, I have Photos which may or may not belong to a Collection, ie there are some Photos where collection_id=nil and some where collection_id=1 etc. 
If I do Photo.order('collection_id desc) then on SQLite I get the nulls last but on PostgreSQL I get the nulls first.
Is there a nice, standard Rails way to handle this and get consistent performance across any database?
",['activerecord']
17286333,Spring/REST Application with HOT Deployment Groovy script does not load dynamically from applicationContext.xml on tomcat startup at runtime,"I am in the process of converting an already exisiting Java Web application into a RESTful web application using Spring MVC and Groovy.
One of the main features I wanted to achieve was HOT DEPLOYMENT.
I chose groovy because I did not want to make changes to the already implemented Business logic(handlers) and also if I had to ever make changes to the groovy code after deployment, I could easily do that without restarting the server(ie. at runtime). 
This can be done because Spring supports Dynamic reloading of groovy scripts(beans). It reloads classes of dynamic languages if they are changed.
I am using Spring annotations to map request URL's to controller methods and the application is deployed in tomcat 6.0.35.
This is the web.xml file
//web.xml

        
        

         
         
              rest
              org.springframework.web.servlet.DispatcherServlet
              1
         
         
              rest
              /service/*
         
        
        
            org.springframework.web.context.ContextLoaderListener
            

            
        
            30
        
    

This groovy file is the controller to which the DispatcherServlet maps the request.
// UserController.groovy

@Controller
class UserController 
 {
    // This is the method to which the HTTP request is submitted to based on the mapping of the 
    // action field of the form ie. /service/user/login/auth.json
    @RequestMapping(value=/user/login/auth.{extension[a-zA-Z]+}, method=RequestMethod.POST)
    @ResponseBody
    public String authenticate(
    @PathVariable String extension,
    @RequestParam(value=username, required=true) String username,
    @RequestParam(value=password, required=true) String password) 
    {
        // UserResource makes the backend calls, authenticates a user and returns the result.
        def user = new UserResource()
        def result = user.login(nameusername, userPasswordpassword)

        // Output the result of the query. Method makeView makes a JSON response of the result
        // and sends to the client(browser) 
        def builder = makeView(extension) 
        {
            it.login(actionresult.action, messageresult.message)
        }
    }
  }

The Spring configuration file is as follows where I have used the langgroovy tag which supports dynamic languages. I have also mentioned the refresh time to be 5 seconds, so that any changes made to those groovy files at runtime can be seen every 1 second and the classes are reloaded. 
//applicationContext.xml




    
    

     

    
    
    

    
    
        
        
    



I have configured my Buildpath and groovy compiler accordingly, so that all the groovy scripts directly get copied to the target folder instead of getting compiled to class files.
THE MAIN PROBLEM 
When I deploy this project in a tomcat server, it loads all the Spring beans required including the ScriptProcessor. Now, when I go to my browser, load the form, and try to submit the authentication form, I get the following error in Tomcat log
152009 WARN - No mapping found for HTTP request with URI [/service/user/login/auth.json] in DispatcherServlet with name 'rest'

I have also made changes in $TOMCAT_DIR/conf/context.xml to antilock resources and JARS

.
.
.

However, if I configure my project to compile those groovy scripts into bytecode classes, comment out the langgroovy tag in applicationContext.xml, and then restart the server, the groovy scripts get compiled into class files and the request is serviced perfectly. Authentication takes place. 
Also, if I configure the dynamic beans in my applicationContet.xml using the following two lines instead of the  tag, my beans DO get created dynamically at runtime and the URLs do get mapped to the respective controller methods because of the annotations.



   


But I do not know how to create the bean refreshing functionality with this style. So I guess there is an issue with the way the  tag processes the groovy scripts.
I would really appreciate some help on this. I have searched all over the internet and read an infinite number of tutorials, and followed the exact procedure mentioned there. But I cant find out whats going wrong.
Please help me solve this problem.
Thank you.
",['rest']
7261490,Should authorization be part of the model or controller?,"I'm writing a web application with some ACL requirements a user can make changes to some items, some items may be editable by several users, administrator can edit anything and a manager can edit everything within her organization etc. 
I'm using the Play! framework, and by the looks of the Secure module, it seems that the place to put authorization concerns is in the Controllers. However, it seems to me that the authorization issues are part of the business logic, and therefore should be in the model. Furthermore, I'm starting to see duplicated logic in the controllers that I need to refactor out.
On the other hand, adding authorization to the model means that I'd have to have some way of getting the current user from within the model, which doesn't seem right. Alternatively, I could add a current_user parameter to every model method, but that seems even worse.
So what is the common practice? Can/should I put authorization code in the model, or keep it in the controller?
",['mvc']
32876844,Restful Server Response triggered Via Client,"This question might sound a bit abstract,answered (but did my search didn't stumble on a convenient answer) or not specific at all ,but I will try to provide as much information as I can.
I am building a mobile application which will gather and send sensory data to a remote server. The remote server will collect all these data in a mySQL database and make computations (not the mysql database ,another process/program) . What I wanna know is 
After some updates in the database , is it doable to send a response from a RESTful Server to a certain client (the one who like did the last update probably) ,using something like a background thread? Or this should be done via socket connection through server-client response?
Some remarks
I am using javaEE, Spring MVC with hibernate and tomcat (cause I am familiar with the environment though in a more asynchronous manner).
I thought this would be a convenient way because the SQL schema is not much complicated and security and authentication issues are not needed (it's a prototype). 
Also there is a front-end webpage that will have to visualize these data, so such a back-end system would look like a good option for getting the job done fast.
Lastly I saw this solution 
Is there a way to #39;listen#39; for a database event and update a page in real time?
My issue is that besides the page I wanna update the client's side with messages from the RESTful server.
If all these above are unecessary and a more simple client-server application will prove better and less complex please be welcome to inform me.
Thank you in advance.
",['rest']
17446822,c# multiple server - multiple clients latency,"I have customized system. System configuration is below. 
I have WinForm Application on Windows 7 P, C#, and .Net 2.0.
It is server-client application. I have multiple server system almost 60 systems. My application create multiple clients to connect each server. 
Each clients has sending/receiving backgroundworker. If only one client send multiple commands (25 commands) to only one server, then It tooks 3 secs. However, If each client send multiple commands to each servers, then It tooks 18 secs, not 3 secs. 
Is there any reason ? 
Update 
a PC has Network Card for 4 channel. each channel has connected with 10 mores server controller. 
Edited
I have solved this issue. The main root cause to implement Server code with BGW(Backgroundworker). I have changed from BGW to thread - receiving and sending function.
I get the fast response with 25 commands for each client. Even I connected 50 clients, I got same time response for whole clients. 
",['client-server']
9333963,"Why am I getting this error, 'NoneType' object has no attribute 'csrf_exempt'?","I am attempting to invoke /save_calendar, mapped to pim_calendar.save_calendar(), which begins
@csrf_exempt
@login_required
def save_calendar(request)
    functions.ensure_profile_exists(request.user)
    now = time.localtime(time.time())
    if request.POST.has_key('description') and request.POST['description']
        description = request.POST['description']
    else
        description = 'Unspecified event'
   ...

The error is posted below, and this is the only @csrf_exempt function at present (although others may follow suit).
How am I passing a NoneType to the csrf_exempt decorator?

AttributeError at /save_calendar
'NoneType' object has no attribute 'csrf_exempt'
Request Method POST
Request URL    <URL>
Django Version 1.3.1
Exception Type AttributeError
Exception Value    
'NoneType' object has no attribute 'csrf_exempt'
Exception Location /usr/local/Cellar/python/2.7/lib/python2.7/site-packages/django/views/decorators/csrf.py in wrapped_view, line 40
Python Executable  /usr/local/bin/python
Python Version 2.7.0
Python Path    
['/Users/jonathan/pim',
 '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/distribute-0.6.14-py2.7.egg',
 '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/pip-0.8.1-py2.7.egg',
 '/usr/local/Cellar/python/2.7/lib/python27.zip',
 '/usr/local/Cellar/python/2.7/lib/python2.7',
 '/usr/local/Cellar/python/2.7/lib/python2.7/plat-darwin',
 '/usr/local/Cellar/python/2.7/lib/python2.7/plat-mac',
 '/usr/local/Cellar/python/2.7/lib/python2.7/plat-mac/lib-scriptpackages',
 '/usr/local/Cellar/python/2.7/lib/python2.7/lib-tk',
 '/usr/local/Cellar/python/2.7/lib/python2.7/lib-old',
 '/usr/local/Cellar/python/2.7/lib/python2.7/lib-dynload',
 '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages',
 '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/PIL',
 '/usr/local/lib/python2.7/site-packages',
 '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/setuptools-0.6c11-py2.7.egg-info']
Server time    Fri, 17 Feb 2012 130505 -0600
Traceback Switch to copy-and-paste view

/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/django/core/handlers/base.py in get_response
                    for middleware_method in self._view_middleware
                        response = middleware_method(request, callback, callback_args, callback_kwargs)
                        if response
                            break
                if response is None
                    try
                        response = callback(request, *callback_args, **callback_kwargs) ...
                    except Exception, e
                        # If the view raised an exception, run it through exception
                        # middleware, and if the exception middleware returns a
                        # response, use that. Otherwise, reraise the exception.
                        for middleware_method in self._exception_middleware
                            response = middleware_method(request, e)
‚ñ∂ Local vars
Variable    Value
exceptions  

e   
AttributeError('NoneType' object has no attribute 'csrf_exempt',)
callback_args   
()
receivers   
[(, None)]
middleware_method   
>
self    

settings    

request 
,
POST,
COOKIES{'csrftoken' 'a4bad057271d130082f6f30c6ae39697',
 'sessionid' 'a25c3081a67d1968e9fc760f4e7048de'},
META{'Apple_PubSub_Socket_Render' '/tmp/launch-VcFoHA/Render',
 'Apple_Ubiquity_Message' '/tmp/launch-8KfrWM/Apple_Ubiquity_Message',
 'COMMAND_MODE' 'unix2003',
 'CONTENT_LENGTH' '50',
 'CONTENT_TYPE' 'application/x-www-form-urlencoded',
 'CSRF_COOKIE' 'a4bad057271d130082f6f30c6ae39697',
 'DISPLAY' '/tmp/launch-Q2SUMz/org.x0',
 'DJANGO_SETTINGS_MODULE' 'pim.settings',
 'GATEWAY_INTERFACE' 'CGI/1.1',
 'HOME' '/Users/jonathan',
 'HTTP_ACCEPT' '*/*',
 'HTTP_ACCEPT_CHARSET' 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
 'HTTP_ACCEPT_ENCODING' 'gzip,deflate,sdch',
 'HTTP_ACCEPT_LANGUAGE' 'en-US,en;q=0.8',
 'HTTP_CONNECTION' 'keep-alive',
 'HTTP_COOKIE' 'csrftoken=a4bad057271d130082f6f30c6ae39697; sessionid=a25c3081a67d1968e9fc760f4e7048de',
 'HTTP_HOST' 'localhost8000',
 'HTTP_ORIGIN' '<URL>
 'HTTP_REFERER' '<URL>
 'HTTP_USER_AGENT' 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.46 Safari/535.11',
 'HTTP_X_REQUESTED_WITH' 'XMLHttpRequest',
 'LANG' 'en_US.UTF-8',
 'LOGNAME' 'jonathan',
 'OLDPWD' '/Users/jonathan/pim/accounts',
 'PATH' '/Users/jonathan/bin/usr/local/bin/usr/bin/bin/usr/sbin/sbin/usr/local/bin/usr/X11/bin',
 'PATH_INFO' u'/save_calendar',
 'PWD' '/Users/jonathan/pim',
 'PYTHON_PATH' '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/usr/local/Cellar',
 'QUERY_STRING' '',
 'REMOTE_ADDR' '127.0.0.1',
 'REMOTE_HOST' '',
 'REQUEST_METHOD' 'POST',
 'RUN_MAIN' 'true',
 'SCRIPT_NAME' u'',
 'SECURITYSESSIONID' '186a5',
 'SERVER_NAME' '1.0.0.127.in-addr.arpa',
 'SERVER_PORT' '8000',
 'SERVER_PROTOCOL' 'HTTP/1.1',
 'SERVER_SOFTWARE' 'WSGIServer/0.1 Python/2.7',
 'SHELL' '/bin/bash',
 'SHLVL' '1',
 'SSH_AUTH_SOCK' '/tmp/launch-KCcDNI/Listeners',
 'TERM' 'xterm-256color',
 'TERM_PROGRAM' 'Apple_Terminal',
 'TERM_PROGRAM_VERSION' '303',
 'TERM_SESSION_ID' '821787AF-B996-4691-BE4F-87C8BEEECE48',
 'TMPDIR' '/var/folders/_2/fbtyy5751sg2b_5frn86qls00000gq/T/',
 'TZ' 'America/Chicago',
 'USER' 'jonathan',
 '_' '/usr/local/bin/python',
 '__CF_USER_TEXT_ENCODING' '0x1F700',
 'wsgi.errors' ', mode 'w' at 0x100556270>,
 'wsgi.file_wrapper' ,
 'wsgi.input' ,
 'wsgi.multiprocess' False,
 'wsgi.multithread' True,
 'wsgi.run_once' False,
 'wsgi.url_scheme' '<URL>
 'wsgi.version' (1, 0)}>
callback    

resolver    

urlresolvers    

callback_kwargs 
{}
response    
None
urlconf 
'pim.urls'
/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/django/contrib/auth/decorators.py in _wrapped_view
    that takes the user object and returns True if the user passes.
    
    def decorator(view_func)
        @wraps(view_func, assigned=available_attrs(view_func))
        def _wrapped_view(request, *args, **kwargs)
            if test_func(request.user)
                return view_func(request, *args, **kwargs) ...
            path = request.build_absolute_uri()
            # If the login url is the same scheme and net location then just
            # use the path as the next url.
            login_scheme, login_netloc = urlparse.urlparse(login_url or
                                                        settings.LOGIN_URL)[2]
            current_scheme, current_netloc = urlparse.urlparse(path)[2]
‚ñ∂ Local vars
Variable    Value
test_func   
 at 0x102303e60>
login_url   
None
args    
()
request 
,
POST,
COOKIES{'csrftoken' 'a4bad057271d130082f6f30c6ae39697',
 'sessionid' 'a25c3081a67d1968e9fc760f4e7048de'},
META{'Apple_PubSub_Socket_Render' '/tmp/launch-VcFoHA/Render',
 'Apple_Ubiquity_Message' '/tmp/launch-8KfrWM/Apple_Ubiquity_Message',
 'COMMAND_MODE' 'unix2003',
 'CONTENT_LENGTH' '50',
 'CONTENT_TYPE' 'application/x-www-form-urlencoded',
 'CSRF_COOKIE' 'a4bad057271d130082f6f30c6ae39697',
 'DISPLAY' '/tmp/launch-Q2SUMz/org.x0',
 'DJANGO_SETTINGS_MODULE' 'pim.settings',
 'GATEWAY_INTERFACE' 'CGI/1.1',
 'HOME' '/Users/jonathan',
 'HTTP_ACCEPT' '*/*',
 'HTTP_ACCEPT_CHARSET' 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
 'HTTP_ACCEPT_ENCODING' 'gzip,deflate,sdch',
 'HTTP_ACCEPT_LANGUAGE' 'en-US,en;q=0.8',
 'HTTP_CONNECTION' 'keep-alive',
 'HTTP_COOKIE' 'csrftoken=a4bad057271d130082f6f30c6ae39697; sessionid=a25c3081a67d1968e9fc760f4e7048de',
 'HTTP_HOST' 'localhost8000',
 'HTTP_ORIGIN' '<URL>
 'HTTP_REFERER' '<URL>
 'HTTP_USER_AGENT' 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.46 Safari/535.11',
 'HTTP_X_REQUESTED_WITH' 'XMLHttpRequest',
 'LANG' 'en_US.UTF-8',
 'LOGNAME' 'jonathan',
 'OLDPWD' '/Users/jonathan/pim/accounts',
 'PATH' '/Users/jonathan/bin/usr/local/bin/usr/bin/bin/usr/sbin/sbin/usr/local/bin/usr/X11/bin',
 'PATH_INFO' u'/save_calendar',
 'PWD' '/Users/jonathan/pim',
 'PYTHON_PATH' '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/usr/local/Cellar',
 'QUERY_STRING' '',
 'REMOTE_ADDR' '127.0.0.1',
 'REMOTE_HOST' '',
 'REQUEST_METHOD' 'POST',
 'RUN_MAIN' 'true',
 'SCRIPT_NAME' u'',
 'SECURITYSESSIONID' '186a5',
 'SERVER_NAME' '1.0.0.127.in-addr.arpa',
 'SERVER_PORT' '8000',
 'SERVER_PROTOCOL' 'HTTP/1.1',
 'SERVER_SOFTWARE' 'WSGIServer/0.1 Python/2.7',
 'SHELL' '/bin/bash',
 'SHLVL' '1',
 'SSH_AUTH_SOCK' '/tmp/launch-KCcDNI/Listeners',
 'TERM' 'xterm-256color',
 'TERM_PROGRAM' 'Apple_Terminal',
 'TERM_PROGRAM_VERSION' '303',
 'TERM_SESSION_ID' '821787AF-B996-4691-BE4F-87C8BEEECE48',
 'TMPDIR' '/var/folders/_2/fbtyy5751sg2b_5frn86qls00000gq/T/',
 'TZ' 'America/Chicago',
 'USER' 'jonathan',
 '_' '/usr/local/bin/python',
 '__CF_USER_TEXT_ENCODING' '0x1F700',
 'wsgi.errors' ', mode 'w' at 0x100556270>,
 'wsgi.file_wrapper' ,
 'wsgi.input' ,
 'wsgi.multiprocess' False,
 'wsgi.multithread' True,
 'wsgi.run_once' False,
 'wsgi.url_scheme' '<URL>
 'wsgi.version' (1, 0)}>
kwargs  
{}
redirect_field_name 
'next'
view_func   

/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/django/views/decorators/csrf.py in wrapped_view
def csrf_response_exempt(view_func)
    
    Modifies a view function so that its response is exempt
    from the post-processing of the CSRF middleware.
    
    def wrapped_view(*args, **kwargs)
        resp = view_func(*args, **kwargs)
        resp.csrf_exempt = True ...
        return resp
    return wraps(view_func, assigned=available_attrs(view_func))(wrapped_view)
def csrf_view_exempt(view_func)
    
    Marks a view function as being exempt from CSRF view protection.
‚ñ∂ Local vars
Variable    Value
resp    
None
args    
(,
POST,
COOKIES{'csrftoken' 'a4bad057271d130082f6f30c6ae39697',
 'sessionid' 'a25c3081a67d1968e9fc760f4e7048de'},
META{'Apple_PubSub_Socket_Render' '/tmp/launch-VcFoHA/Render',
 'Apple_Ubiquity_Message' '/tmp/launch-8KfrWM/Apple_Ubiquity_Message',
 'COMMAND_MODE' 'unix2003',
 'CONTENT_LENGTH' '50',
 'CONTENT_TYPE' 'application/x-www-form-urlencoded',
 'CSRF_COOKIE' 'a4bad057271d130082f6f30c6ae39697',
 'DISPLAY' '/tmp/launch-Q2SUMz/org.x0',
 'DJANGO_SETTINGS_MODULE' 'pim.settings',
 'GATEWAY_INTERFACE' 'CGI/1.1',
 'HOME' '/Users/jonathan',
 'HTTP_ACCEPT' '*/*',
 'HTTP_ACCEPT_CHARSET' 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
 'HTTP_ACCEPT_ENCODING' 'gzip,deflate,sdch',
 'HTTP_ACCEPT_LANGUAGE' 'en-US,en;q=0.8',
 'HTTP_CONNECTION' 'keep-alive',
 'HTTP_COOKIE' 'csrftoken=a4bad057271d130082f6f30c6ae39697; sessionid=a25c3081a67d1968e9fc760f4e7048de',
 'HTTP_HOST' 'localhost8000',
 'HTTP_ORIGIN' '<URL>
 'HTTP_REFERER' '<URL>
 'HTTP_USER_AGENT' 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.46 Safari/535.11',
 'HTTP_X_REQUESTED_WITH' 'XMLHttpRequest',
 'LANG' 'en_US.UTF-8',
 'LOGNAME' 'jonathan',
 'OLDPWD' '/Users/jonathan/pim/accounts',
 'PATH' '/Users/jonathan/bin/usr/local/bin/usr/bin/bin/usr/sbin/sbin/usr/local/bin/usr/X11/bin',
 'PATH_INFO' u'/save_calendar',
 'PWD' '/Users/jonathan/pim',
 'PYTHON_PATH' '/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/usr/local/Cellar',
 'QUERY_STRING' '',
 'REMOTE_ADDR' '127.0.0.1',
 'REMOTE_HOST' '',
 'REQUEST_METHOD' 'POST',
 'RUN_MAIN' 'true',
 'SCRIPT_NAME' u'',
 'SECURITYSESSIONID' '186a5',
 'SERVER_NAME' '1.0.0.127.in-addr.arpa',
 'SERVER_PORT' '8000',
 'SERVER_PROTOCOL' 'HTTP/1.1',
 'SERVER_SOFTWARE' 'WSGIServer/0.1 Python/2.7',
 'SHELL' '/bin/bash',
 'SHLVL' '1',
 'SSH_AUTH_SOCK' '/tmp/launch-KCcDNI/Listeners',
 'TERM' 'xterm-256color',
 'TERM_PROGRAM' 'Apple_Terminal',
 'TERM_PROGRAM_VERSION' '303',
 'TERM_SESSION_ID' '821787AF-B996-4691-BE4F-87C8BEEECE48',
 'TMPDIR' '/var/folders/_2/fbtyy5751sg2b_5frn86qls00000gq/T/',
 'TZ' 'America/Chicago',
 'USER' 'jonathan',
 '_' '/usr/local/bin/python',
 '__CF_USER_TEXT_ENCODING' '0x1F700',
 'wsgi.errors' ', mode 'w' at 0x100556270>,
 'wsgi.file_wrapper' ,
 'wsgi.input' ,
 'wsgi.multiprocess' False,
 'wsgi.multithread' True,
 'wsgi.run_once' False,
 'wsgi.url_scheme' '<URL>
 'wsgi.version' (1, 0)}>,)
view_func   

kwargs  
{}



Request information

GET
No GET data
POST
Variable    Value
yearly  
u'on'
monthly 
u'on'
calendar    
u'true'
description 
u'hhh'
FILES
No FILES data
COOKIES
Variable    Value
csrftoken   
'a4bad057271d130082f6f30c6ae39697'
sessionid   
'a25c3081a67d1968e9fc760f4e7048de'
META
Variable    Value
RUN_MAIN    
'true'
HTTP_REFERER    
'<URL>
SERVER_PROTOCOL 
'HTTP/1.1'
SERVER_SOFTWARE 
'WSGIServer/0.1 Python/2.7'
TERM_PROGRAM_VERSION    
'303'
REQUEST_METHOD  
'POST'
LOGNAME 
'jonathan'
USER    
'jonathan'
HTTP_ORIGIN 
'<URL>
PATH    
'/Users/jonathan/bin/usr/local/bin/usr/bin/bin/usr/sbin/sbin/usr/local/bin/usr/X11/bin'
QUERY_STRING    
''
HOME    
'/Users/jonathan'
DISPLAY 
'/tmp/launch-Q2SUMz/org.x0'
TERM_PROGRAM    
'Apple_Terminal'
LANG    
'en_US.UTF-8'
HTTP_ACCEPT_CHARSET 
'ISO-8859-1,utf-8;q=0.7,*;q=0.3'
TERM    
'xterm-256color'
SHELL   
'/bin/bash'
TZ  
'America/Chicago'
HTTP_COOKIE 
'csrftoken=a4bad057271d130082f6f30c6ae39697; sessionid=a25c3081a67d1968e9fc760f4e7048de'
SERVER_NAME 
'1.0.0.127.in-addr.arpa'
REMOTE_ADDR 
'127.0.0.1'
SHLVL   
'1'
SECURITYSESSIONID   
'186a5'
wsgi.url_scheme 
'<URL>
_   
'/usr/local/bin/python'
SERVER_PORT 
'8000'
PATH_INFO   
u'/save_calendar'
CONTENT_LENGTH  
'50'
TERM_SESSION_ID 
'821787AF-B996-4691-BE4F-87C8BEEECE48'
HTTP_X_REQUESTED_WITH   
'XMLHttpRequest'
SSH_AUTH_SOCK   
'/tmp/launch-KCcDNI/Listeners'
wsgi.input  

Apple_PubSub_Socket_Render  
'/tmp/launch-VcFoHA/Render'
HTTP_HOST   
'localhost8000'
SCRIPT_NAME 
u''
wsgi.multithread    
True
HTTP_CONNECTION 
'keep-alive'
TMPDIR  
'/var/folders/_2/fbtyy5751sg2b_5frn86qls00000gq/T/'
HTTP_ACCEPT 
'*/*'
wsgi.version    
(1, 0)
HTTP_USER_AGENT 
'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_7_3) AppleWebKit/535.11 (KHTML, like Gecko) Chrome/17.0.963.46 Safari/535.11'
GATEWAY_INTERFACE   
'CGI/1.1'
wsgi.run_once   
False
CSRF_COOKIE 
'a4bad057271d130082f6f30c6ae39697'
OLDPWD  
'/Users/jonathan/pim/accounts'
wsgi.multiprocess   
False
HTTP_ACCEPT_LANGUAGE    
'en-US,en;q=0.8'
wsgi.errors 
', mode 'w' at 0x100556270>
__CF_USER_TEXT_ENCODING 
'0x1F700'
Apple_Ubiquity_Message  
'/tmp/launch-8KfrWM/Apple_Ubiquity_Message'
PWD 
'/Users/jonathan/pim'
PYTHON_PATH 
'/usr/local/Cellar/python/2.7/lib/python2.7/site-packages/usr/local/Cellar'
DJANGO_SETTINGS_MODULE  
'pim.settings'
CONTENT_TYPE    
'application/x-www-form-urlencoded'
wsgi.file_wrapper   
''
REMOTE_HOST 
''
HTTP_ACCEPT_ENCODING    
'gzip,deflate,sdch'
COMMAND_MODE    
'unix2003'
Settings
Using settings module pim.settings
Setting Value
YEAR_MONTH_FORMAT   
'F Y'
USE_L10N    
True
USE_THOUSAND_SEPARATOR  
False
LANGUAGE_CODE   
'en-us'
ROOT_URLCONF    
'pim.urls'
MANAGERS    
()
DEFAULT_CHARSET 
'utf-8'
STATIC_ROOT 
'/Users/jonathan/pim/../pim/static/'
TEST_DATABASE_CHARSET   
None
MESSAGE_STORAGE 
'django.contrib.messages.storage.user_messages.LegacyFallbackStorage'
DATABASE_HOST   
''
IGNORABLE_404_STARTS    
('/cgi-bin/', '/_vti_bin', '/_vti_inf')
SEND_BROKEN_LINK_EMAILS 
False
URL_VALIDATOR_USER_AGENT    
'Django/1.3.1 (<URL>
STATICFILES_FINDERS 
('django.contrib.staticfiles.finders.FileSystemFinder',
 'django.contrib.staticfiles.finders.AppDirectoriesFinder')
SESSION_COOKIE_DOMAIN   
None
SESSION_COOKIE_NAME 
'sessionid'
COMMENTS_MODERATORS_GROUP   
None
TIME_INPUT_FORMATS  
('%H%M%S', '%H%M')
DATABASES   
{'default' {'ENGINE' 'django.db.backends.sqlite3',
             'HOST' '',
             'NAME' 'dev.db',
             'OPTIONS' {},
             'PASSWORD' '********************',
             'PORT' '',
             'TEST_CHARSET' None,
             'TEST_COLLATION' None,
             'TEST_MIRROR' None,
             'TEST_NAME' None,
             'TIME_ZONE' 'America/Chicago',
             'USER' ''}}
TEST_DATABASE_NAME  
None
FILE_UPLOAD_PERMISSIONS 
None
FILE_UPLOAD_HANDLERS    
('django.core.files.uploadhandler.MemoryFileUploadHandler',
 'django.core.files.uploadhandler.TemporaryFileUploadHandler')
DEFAULT_CONTENT_TYPE    
'text/html'
APPEND_SLASH    
True
FIRST_DAY_OF_WEEK   
0
DATABASE_ROUTERS    
[]
DIRNAME 
'/Users/jonathan/pim/../pim'
STATICFILES_STORAGE 
'django.contrib.staticfiles.storage.StaticFilesStorage'
CACHES  
{'default' {'BACKEND' 'django.core.cache.backends.locmem.LocMemCache',
             'LOCATION' ''}}
SERVER_EMAIL    
'root@localhost'
SESSION_COOKIE_PATH 
'/'
USE_X_FORWARDED_HOST    
False
IGNORABLE_404_ENDS  
('mail.pl', 'mailform.pl', 'mail.cgi', 'mailform.cgi', 'favicon.ico', '.php')
MIDDLEWARE_CLASSES  
('django.middleware.common.CommonMiddleware',
 'django.contrib.sessions.middleware.SessionMiddleware',
 'django.middleware.csrf.CsrfViewMiddleware',
 'django.contrib.auth.middleware.AuthenticationMiddleware',
 'django.contrib.messages.middleware.MessageMiddleware')
USE_I18N    
True
THOUSAND_SEPARATOR  
','
SECRET_KEY  
'********************'
LANGUAGE_COOKIE_NAME    
'django_language'
FILE_UPLOAD_TEMP_DIR    
None
TRANSACTIONS_MANAGED    
False
LOGGING_CONFIG  
'django.utils.log.dictConfig'
TEMPLATE_LOADERS    
('django.template.loaders.filesystem.Loader',
 'django.template.loaders.app_directories.Loader')
TEMPLATE_DEBUG  
True
AUTHENTICATION_BACKENDS 
('django.contrib.auth.backends.ModelBackend',)
TEST_DATABASE_COLLATION 
None
FORCE_SCRIPT_NAME   
None
CACHE_BACKEND   
'locmem//'
SESSION_COOKIE_SECURE   
False
CSRF_COOKIE_DOMAIN  
None
FILE_CHARSET    
'utf-8'
DEBUG   
True
SESSION_FILE_PATH   
None
DEFAULT_FILE_STORAGE    
'django.core.files.storage.FileSystemStorage'
INSTALLED_APPS  
['django.contrib.auth',
 'django.contrib.contenttypes',
 'django.contrib.sessions',
 'django.contrib.sites',
 'django.contrib.messages',
 'django.contrib.staticfiles',
 'django.contrib.admin',
 'pim',
 'pim_accounts',
 'pim_calendar',
 'pim_scratchpad']
LANGUAGES   
(('ar', 'Arabic'),
 ('az', 'Azerbaijani'),
 ('bg', 'Bulgarian'),
 ('bn', 'Bengali'),
 ('bs', 'Bosnian'),
 ('ca', 'Catalan'),
 ('cs', 'Czech'),
 ('cy', 'Welsh'),
 ('da', 'Danish'),
 ('de', 'German'),
 ('el', 'Greek'),
 ('en', 'English'),
 ('en-gb', 'British English'),
 ('es', 'Spanish'),
 ('es-ar', 'Argentinian Spanish'),
 ('es-mx', 'Mexican Spanish'),
 ('es-ni', 'Nicaraguan Spanish'),
 ('et', 'Estonian'),
 ('eu', 'Basque'),
 ('fa', 'Persian'),
 ('fi', 'Finnish'),
 ('fr', 'French'),
 ('fy-nl', 'Frisian'),
 ('ga', 'Irish'),
 ('gl', 'Galician'),
 ('he', 'Hebrew'),
 ('hi', 'Hindi'),
 ('hr', 'Croatian'),
 ('hu', 'Hungarian'),
 ('id', 'Indonesian'),
 ('is', 'Icelandic'),
 ('it', 'Italian'),
 ('ja', 'Japanese'),
 ('ka', 'Georgian'),
 ('km', 'Khmer'),
 ('kn', 'Kannada'),
 ('ko', 'Korean'),
 ('lt', 'Lithuanian'),
 ('lv', 'Latvian'),
 ('mk', 'Macedonian'),
 ('ml', 'Malayalam'),
 ('mn', 'Mongolian'),
 ('nl', 'Dutch'),
 ('no', 'Norwegian'),
 ('nb', 'Norwegian Bokmal'),
 ('nn', 'Norwegian Nynorsk'),
 ('pa', 'Punjabi'),
 ('pl', 'Polish'),
 ('pt', 'Portuguese'),
 ('pt-br', 'Brazilian Portuguese'),
 ('ro', 'Romanian'),
 ('ru', 'Russian'),
 ('sk', 'Slovak'),
 ('sl', 'Slovenian'),
 ('sq', 'Albanian'),
 ('sr', 'Serbian'),
 ('sr-latn', 'Serbian Latin'),
 ('sv', 'Swedish'),
 ('ta', 'Tamil'),
 ('te', 'Telugu'),
 ('th', 'Thai'),
 ('tr', 'Turkish'),
 ('uk', 'Ukrainian'),
 ('ur', 'Urdu'),
 ('vi', 'Vietnamese'),
 ('zh-cn', 'Simplified Chinese'),
 ('zh-tw', 'Traditional Chinese'))
DATABASE_ENGINE 
''
DATABASE_NAME   
''
COMMENTS_FIRST_FEW  
0
PREPEND_WWW 
False
AUTH_PROFILE_MODULE 
'pim_accounts.UserProfile'
SESSION_COOKIE_HTTPONLY 
False
DATABASE_PORT   
''
DEBUG_PROPAGATE_EXCEPTIONS  
False
MONTH_DAY_FORMAT    
'F j'
LOGIN_URL   
'/accounts/login/'
SESSION_EXPIRE_AT_BROWSER_CLOSE 
False
TIME_FORMAT 
'P'
DATE_INPUT_FORMATS  
('%Y-%m-%d',
 '%m/%d/%Y',
 '%m/%d/%y',
 '%b %d %Y',
 '%b %d, %Y',
 '%d %b %Y',
 '%d %b, %Y',
 '%B %d %Y',
 '%B %d, %Y',
 '%d %B %Y',
 '%d %B, %Y')
CSRF_COOKIE_NAME    
'csrftoken'
EMAIL_HOST_PASSWORD 
'********************'
PASSWORD_RESET_TIMEOUT_DAYS 
'********************'
CACHE_MIDDLEWARE_ALIAS  
'default'
SESSION_SAVE_EVERY_REQUEST  
False
ADMIN_MEDIA_PREFIX  
'/static/admin/'
NUMBER_GROUPING 
0
SESSION_ENGINE  
'django.contrib.sessions.backends.db'
CSRF_FAILURE_VIEW   
'django.views.csrf.csrf_failure'
COMMENTS_SKETCHY_USERS_GROUP    
None
LOGIN_REDIRECT_URL  
'/accounts/profile/'
LOGGING 
{'disable_existing_loggers' False,
 'handlers' {'mail_admins' {'class' 'django.utils.log.AdminEmailHandler',
                              'level' 'ERROR'}},
 'loggers' {'django.request' {'handlers' ['mail_admins'],
                                'level' 'ERROR',
                                'propagate' True}},
 'version' 1}
CACHE_MIDDLEWARE_KEY_PREFIX 
''
LOCALE_PATHS    
()
TEMPLATE_STRING_IF_INVALID  
''
COMMENTS_ALLOW_PROFANITIES  
False
LOGOUT_URL  
'/accounts/logout/'
EMAIL_USE_TLS   
False
TEMPLATE_DIRS   
('/Users/jonathan/pim/../pim/templates',)
FIXTURE_DIRS    
()
EMAIL_HOST  
'localhost'
DATE_FORMAT 
'N j, Y'
MEDIA_ROOT  
'/Users/jonathan/pim/../pim/media/'
ADMINS  
()
FORMAT_MODULE_PATH  
None
DEFAULT_FROM_EMAIL  
'webmaster@localhost'
STATICFILES_DIRS    
()
MEDIA_URL   
'/media/'
DATETIME_FORMAT 
'N j, Y, P'
EMAIL_SUBJECT_PREFIX    
'[Django] '
SITE_ID 
1
DISALLOWED_USER_AGENTS  
()
ALLOWED_INCLUDE_ROOTS   
()
DECIMAL_SEPARATOR   
'.'
SHORT_DATE_FORMAT   
'm/d/Y'
DATABASE_USER   
''
TEST_RUNNER 
'django.test.simple.DjangoTestSuiteRunner'
TIME_ZONE   
'America/Chicago'
FILE_UPLOAD_MAX_MEMORY_SIZE 
2621440
EMAIL_BACKEND   
'django.core.mail.backends.smtp.EmailBackend'
DEFAULT_TABLESPACE  
''
TEMPLATE_CONTEXT_PROCESSORS 
('django.contrib.auth.context_processors.auth',
 'django.core.context_processors.debug',
 'django.core.context_processors.i18n',
 'django.core.context_processors.media',
 'django.core.context_processors.static',
 'django.contrib.messages.context_processors.messages')
SESSION_COOKIE_AGE  
1209600
SETTINGS_MODULE 
'pim.settings'
USE_ETAGS   
False
LANGUAGES_BIDI  
('he', 'ar', 'fa')
DEFAULT_INDEX_TABLESPACE    
''
INTERNAL_IPS    
()
STATIC_URL  
'/static/'
EMAIL_PORT  
25
SHORT_DATETIME_FORMAT   
'm/d/Y P'
ABSOLUTE_URL_OVERRIDES  
{}
DATABASE_OPTIONS    
{}
CACHE_MIDDLEWARE_SECONDS    
600
BANNED_IPS  
()
DATETIME_INPUT_FORMATS  
('%Y-%m-%d %H%M%S',
 '%Y-%m-%d %H%M',
 '%Y-%m-%d',
 '%m/%d/%Y %H%M%S',
 '%m/%d/%Y %H%M',
 '%m/%d/%Y',
 '%m/%d/%y %H%M%S',
 '%m/%d/%y %H%M',
 '%m/%d/%y')
DATABASE_PASSWORD   
'********************'
ADMIN_FOR   
()
COMMENTS_BANNED_USERS_GROUP 
None
EMAIL_HOST_USER 
''
PROFANITIES_LIST    
'********************'
You're seeing this error because you have DEBUG = True in your Django settings file. Change that to False, and Django will display a standard 500 page.

",['decorator']
8459296,ActiveRecord has_one and has_many relation with the same foreign_key,"I have two models, Story and Chapter. A story has_many chapters, one of those is a chapter which serves as its first chapter. I used to have a foreign key start_id in the stories table to indicate which chapter is the first. Hovewer, the the database schema had to be changed a little, now every chapter has a code. If the code is '1a', then that is first chapter of the story which owns the chapter.
The following seems to work, including #create_start
has_many chapters, dependent => destroy, inverse_of => story
has_one start, class_name => 'Chapter', foreign_key => 'story_id', conditions => {code => '1a'}

This way, the foreign key start_id of the stories table is unneeded, and #start still remains an association, with all the benefits (I need #start as an association, because I use CanCan with associations for authorization).
Does my approach has any drawbacks that I currently fail to realize, or I am relatively safe with it?
",['activerecord']
15390727,PasswordBox and MVVM,"We have the following scenario

MVVM userinterface where a user can place his password (actually a PasswordBox)
Server that shall do some work 
Server connects to some Database that requires authentification

And I already read this Question on PasswordBox in MVVM
But there is no answer on how to do! Just lots over never ever do that.
What is the correct way of passing a password around?
How to resolve the security issues?
There is no proper way of Binding to the PasswordBox and
the Password shall not be stored somewhere, okay.
So, what is the MVVM way of doing such things?
Even if the pattern is broken, is there a good way to achieve such things?
Thought of a Func to retrieve it, but without Binding this
will get a mess... 
Update
Same for initialising the PasswordBox from a (hopefully encrypted) password store.
Isn't that breaking the MVVM pattern? The User does not want to enter the password
each time he starts the application or wants to work with the database I believe.
",['mvvm']
31931895,What is a safest method for delegating user roles through devise?,"On a rails app I'm working on I have authentication setup with devise. I have added an additional attribute the the user model called 'role'. It is simply an integer value which controls what exactly a user can do.
The issue I'm facing is I am not sure how exactly how to assign these roles safely.  Obviously I can't just put a field in the sign up form for it. The safest way I can think of is to force the value to 0 on all accounts and when creating new admin accounts I would manually set it in the database, but this seems sloppy any ideas?
",['activerecord']
55601089,How should I handle RESTful authentication while using JWT tokens?,"I have read many articles and viewed many videos but there are a lot of contradictions. I try to avoid any external libraries and build the system from scratch, I have read about oAuth 2 but it is more confusing.
This is the flow that I think is ok untill now

User fills a form using email and password and submits it.
Server verifies the password if it matches and responds back with a <URL> cookie with a signed jwt token that expires in like 10
minutes. (I know I have to protect it against csrf attacks)
User gets logged in and every new request he is making to the server he will send the cookie in the header automatically and the
server will verify the token.

Everything is fine but I have encountered some issues and have some questions
I want the user to stay logged in even after opening a new session so there is no need to login after the token expired or when he closes the browser.
What should happen if the access token expired?
There should be a refresh token attached to the user in database that gets added when the user logs in with an expiration of ex 7 days, then the server will respond with a cookie containing that refresh token?
On the new request while access token is expired,the user will send the refresh cookie to the server, if it matches the user database refresh token,server will respond with a separate cookie that will renew the access token?
If there is a refresh token where should you store it and what format? (cookie,database or where?)
Should I keep the user logged in based on this refresh token cookie?If is it <URL> I can't read it and set the state that user is logged in. How should I do it?
I heard about that revoking the jwt token is problematic. How would you fix it?
How would you do this whole thing?Please explain the workflow, I try to avoid localstorage,as I read everywhere that is not safe for sensitive data.
",['rest']
6821238,Rails Domain model decoupling of Activerecord,"I have been reading the book SQL Antipatterns Avoiding the Pitfalls of Database Programming especially around the magic beans anti pattern. In it shows a diagram decoupling activerecords by using a domain model and has example in PHP, but not Rails, it refers to this as HAS-A aggregation between domain models and views/controllers and HAS-A composition between domain models and activerecords (I presume this is UML speak).  
In Rails it seems to be common place to make thin controllers fat models by using model methods, these methods may manipulate other associated models so that only one model can be used in any given controller. However, I wonder if there is a practice which includes total decoupling in Rails? 
That is, to create a tableless model or other class to be used as a domain model acting as a layer between controllers and activerecord objects (which in turn are mapped to tables) so that controllers have better isolation and don't need to know anything about the underlying database and its structure. It also gives the option to move away from CRUD methods which don't explain the application requirements which they apply, another criticism in the book.
","['activerecord', 'ddd']"
46546626,Spring boot - POST method not allowed,"I'm dwelling with this problem... I have a Spring Boot application wit a S2S communication. I have a @RestController method which should accept POST request.
This is the controller
@RestController
public class PaymentRestController {

@PostMapping(/util/paymentResponse)
    public void savePaymentResponse(@RequestParam boolean transaction_status, @RequestParam String usedToken,
            @RequestParam String transaction_message, @RequestParam String authCode,
            @RequestParam String transactionCode, @RequestParam String orderId, HttpServletRequest request) {
//business logic
}

}

If i hit this link i get a 405 error, method not allowed
At first time i found that the request was blocked by the CSFR Filter which is enabled on the web application, so I have configured my security in this way
@Configuration
@ComponentScan(it.besmart)
@EnableWebSecurity
public class SecurityConfiguration extends WebSecurityConfigurerAdapter{

    @Autowired
    @Qualifier(customUserDetailsService)
    UserDetailsService userDetailsService;

    @Autowired
    CustomSuccessHandler customSuccessHandler;

    @Autowired
    CustomAuthenticationFailureHandler customAuthenticationFailureHandler;

    @Autowired
    DataSource dataSource;

    private final static Logger logger = Loggerabstract-abstract-factory.getLogger(SecurityConfiguration.class);

    @Autowired
    public void configureGlobalService(AuthenticationManagerBuilder auth) throws Exception {
        auth.userDetailsService(userDetailsService).passwordEncoder(passwordEncoder());

    }

    @Bean
    public PasswordEncoder passwordEncoder() {
        return new BCryptPasswordEncoder();
    }

    @Bean
    public SwitchUserFilter switchUserFilter() {
        SwitchUserFilter filter = new SwitchUserFilter();
        filter.setUserDetailsService(userDetailsService);
        filter.setSuccessHandler(customSuccessHandler);
        filter.setFailureHandler(customAuthenticationFailureHandler);
        return filter;
    }

        protected void configure(HttpSecurity <URL> throws Exception {
            logger.debug(Webapp security configured);


            http

            .authorizeRequests()
                    .antMatchers(/,  /home, /contacts, /faq, /privacy, /register, /registrationConfirm, /util/**, /resendRegistrationToken,/park**, /oauth/authorize, /error)
                    .permitAll()
                    .antMatchers(/profile**, /edit**,/payment**, /plate**,/notification**, /addPaymentMethod**, /logout/impersonate**)
                    .access(hasRole('USER') or hasRole('NOPAYMENT'))
                    .antMatchers(/book**, /manage**)
                    .access(hasRole('USER'))
                    .antMatchers(/admin**, /login/impersonate**).access(hasRole('ADMIN'))
                    .antMatchers(/updatePassword).hasAuthority(CHANGE_PASSWORD_PRIVILEGE)

                    .and().formLogin().loginPage(/?login=login).loginProcessingUrl(/)                   .successHandler(customSuccessHandler).failureHandler(customAuthenticationFailureHandler).usernameParameter(email).passwordParameter(password).and().rememberMe().rememberMeParameter(remember-me).tokenRepository(persistentTokenRepository()).tokenValiditySeconds(86400).and().exceptionHandling().accessDeniedPage(/accessDenied)

                    .and().csrf().ignoringAntMatchers( /util**)
                    .and().logout().logoutRequestMatcher(new AntPathRequestMatcher(/logout))
                    .logoutSuccessUrl(/?logout=true).permitAll()


                    .and().addFilterAfter(switchUserFilter(), FilterSecurityInterceptor.class);

        }

In this way i'm not getting the CSRF token exception, but still getting the 405 error.
It's not even a problem of POST because if i change to GET the request and the mapping, i still take the 405 error... And if i try to send a POST, i see in the header response that the Allowed method is POST, if i send it in GET i see allowed method POST... weird
I don't know where to see...
",['rest']
4088586,"Utility Class within an Automated Testing Project - Static, Singleton, or Other Design?","I've searched quite a bit about this on stack overflow and think this question is different enough to merit a new question.
For integration tests, I need to enable the Distributed Transaction Coordinator service (SQL Server) so that I can use the database rollback feature of MSTestExtensions. 
So I need methods like as follows
public void StartService(string serviceName)
public void StopService(string serviceName)
public void RestartService(string serviceName)

It would be very easy to make a static class. The work to make this class a singleton in c# is not hard either.
So does it really matter if one uses a singleton or a static class here? It seems trivial to me, but perhaps one is more appropriate for this type of thing?
I don't think I need to use interfaces, polymorphism, extensibility, or the ability to pass this class that contains these methods around. So such benefits of Singletons are not really helpful in this case. In the end the only advantages I can see is lazy loading of the class and not having to add static to every method.
",['singleton']
24329007,ZeroMQ + Java performance on pub/sub,"Googled without luck, my problem is as the title. I got only around 50K message per second for some < 64 bytes message, with only a simple pub/sub test sending a const string through. The same box demonstrates quite stable performance regardless if I am doing TCP// or INPROC//, or under Windows or Ubuntu.
The hardware and software configuration is
i5-4670 3.4G x 4 Core
16GB 1666Mhz RAM
Windows 7 64bit
JDK 1.8.05
ZeroMQ 3.2.3
jzmq 2.2.2
And the sample program is as below where I created 2 threads, 1 doing pub and 1 doing sub. Delivering the message 1000 times and wait till the subscriber receive them all. The performance is constantly around 30 ms, which is only 1/10 of the performance I assume ZeroMQ should deliver. The code demonstrates same performance running stand-alone in IDE and running as a JUnit test.
Could anyone give me some hint on this?
EDIT1 Seems if I enlarge the message count to 5000 I got a core dump from JVM. That looks to me a hint to the real problem, though I don't think I got anything wrong in the threading model. What can be the culprit?
public class ZMQReadynessTest {

private ZMQ.Context context;

@Before
public void setUp() {
    ZMQLoader.initialize();
    context = ZMQ.context(2);
}

@Test
public void testSimpleMessage() {
    final int totalCount = 1000;
    String topic = tcp//127.0.0.131216;
    final CountDownLatch startLatch = new CountDownLatch(1);
    final CountDownLatch latch = new CountDownLatch(totalCount);

    // create a simple subscriber
    final ZMQ.Socket subscribeSocket = context.socket(ZMQ.SUB);
    subscribeSocket.connect(topic);
    subscribeSocket.subscribe(TestTopic.getBytes());

    Thread subThread = new Thread() {

        @Override
        public void run() {
            try {
                try {
                    Thread.sleep(1000);
                } catch (InterruptedException e) {
                    e.printStackTrace();
                    fail();
                }

                startLatch.countDown();
                ByteBuffer buffer = ByteBuffer.allocateDirect(100);

                while (latch.getCount() > 0) {

                    // get the message
                    int count = 0;
                    if ((count = subscribeSocket.recvZeroCopy(buffer, buffer.remaining(), 0)) > 0) {

                        // another receive for content
                        count = subscribeSocket.recvZeroCopy(buffer, buffer.remaining(), 0);
                        buffer.flip();

                        byte[] b = new byte[count];
                        buffer.get(b);
                        assertEquals(This is test string, new String(b));

                        latch.countDown();
                        buffer.clear();
                    }
                }
            } catch (Exception e) {
                e.printStackTrace();
                System.out.println(latch.getCount());
            } finally {
                subscribeSocket.close();
            }
        }
    };

    // create a simple publisher - wait 3 sec to make sure its ready
    ZMQ.Socket publishSocket = context.socket(ZMQ.PUB);
    publishSocket.bind(tcp//*31216);

    try {
        subThread.start();
        try {
            startLatch.await();
        } catch (InterruptedException e) {
            e.printStackTrace();
            fail();
        }

        // publish a sample message
        long before = System.currentTimeMillis(), after;
        try {
            for (int i = 0; i < totalCount; i++) {
                publishSocket.send(NotTestTopic.getBytes(), ZMQ.SNDMORE | ZMQ.DONTWAIT);
                publishSocket.send(Not received.getBytes(), 0);
                publishSocket.send(TestTopic.getBytes(), ZMQ.SNDMORE | ZMQ.DONTWAIT);
                publishSocket.send(This is test string.getBytes(), ZMQ.DONTWAIT);
            }

            latch.await(10000, TimeUnit.MILLISECONDS);
        } catch (InterruptedException e) {
            e.printStackTrace();
            fail();
        } finally {
            after = System.currentTimeMillis();
            publishSocket.close();
        }

        assertEquals(latch.getCount(), 0);
        System.out.println(String.valueOf(totalCount) +  messages took  + (after - before) +  ms.);
    } finally {
        publishSocket.close();
        subscribeSocket.close();
    }
}

}
",['publish-subscribe']
26197021,Connect to OpenMRS remotely,"How to make http authentication in REST API call from javascript
I have a question that involves using OpenMRS. I have linked the page in my question. My question is 
how do you remotely connect to the database that is embedded in the system that comes with the standalone download that you can get with OpenMRS. We are trying to access the system outside the web based interface that retrieves the information using the REST API associated with this system.  In the link above they are using base64 coded password and username inside setRequestHeader. What is the purpose of putting it in that code format? And is it exactly  then encoded base64 to get the letter number combination? 
",['rest']
31462929,What's the best way to share user accounts between the application and an engine?,"I have a website that has User and Group models and all is well. The User and Group models are two types of accounts that we have and they are currently used for contact information, authentication and authorization.
Now I'm building out the subscription part of the site so we can start billing users (and groups/organizations) who subscribe to our premium services. I've opted to put this new code in a Rails Engine because I hope to deploy the engine only to an environment on a host that is reachable via our VPN, like so
mount BillingEngine, at => '/billing' if Rails.env.admin?

I've got three models that I'm working with to manage subscriptions
module Billing
  class PricingPlan < ActiveRecordBase
    has_many subscriptions
  end
end

module Billing
  class Subscription < ActiveRecordBase
    belongs_to pricing_plan
    belongs_to subscriber, polymorphic => true

    # Used for eager loading
    belongs_to users,  foreign_key => 'subscriber_id', class_name => 'User'
    belongs_to groups, foreign_key => 'subscriber_id', class_name => 'Group'

    has_many   payments
  end
end

module Billing
  class Payments < ActiveRecordBase
    belongs_to subscription
  end
end

The BillingSubscription.subscriber part is what is currently vexing me. As you can see, I'm currently reaching across the engine boundary to get ahold of the User and Group models that live in my application, but that feels icky.
I thought about creating BillingUser and BillingGroup AR models so that the engine and application can be completely isolated from one another, but it seems a bit weird to duplicate information between two models that are, for now, in the same database (e.g. first_name, last_name, email, etc.)...plus I'd have to duplicate information between them, which is a recipe for disaster, I'm sure.
I also thought about using some kind of wrapping model to abstract away the actual implementation, something like this
module Billing
  class User < User
  end
end

But if I recall correctly, I ran into problems with the polymorphic behavior I'm after and/or problems with rspec mocking and stubbing so I abandoned that approach.
I'd appreciate any guidance. I've made numerous trips to Google searching for answers but nothing I've seen so far seems directly applicable.
UPDATE
Using Carl Zulauf's suggestion, I came up with the following
# File app/models/concerns/billing/subscribable.rb

require 'active_support/concern'

module Billing
  module Subscribable
    extend ActiveSupportConcern

    included do
      has_one subscription, {
        class_name  => 'BillingSubscription',
        foreign_key => 'subscriber_id',
        as          => subscriber
      }

      base = self
      BillingSubscription.class_eval do
        belongs_to base.name.tableize.to_sym, {
          foreign_key => 'subscriber_id',
          class_name  => base.to_s
        }
      end
    end
  end
end

Which I then invoke thusly
class User < ActiveRecordBase
  include BillingSubscribable

  can_subscribe
end

This works...so long as I load User before I call BillingSubscription.eager_load users...which seems really dicey. Got any suggestions for me?
UPDATE #2
I wound up creating an initializer to handle this. This works, but if there are any better options, I'm all ears.
# File config/initializers/setup_billing.rb

User.class_eval do
  include BillingSubscribable
end

Group.class_eval do
  include BillingSubscribable
end

",['activerecord']
7951313,Securing Grails REST service for use with mobile applications,"I am busy doing some research into using REST services with mobile applications and would appreciate some insight. The scenario is as  follows.
Consider a web application that provides a service to users. The web application will also be the main interaction point for the users. This will be done in Grails, and secured with Spring Security.
Now, we want to provide a REST service so that users can use the service via mobile applications. Since Grails has such nice support for making the existing web application RESTful, we will use the built-in Grails support for that.
My question now is, what would be the best way to secure the REST service interface so that it can be use from mobile applications (native- iOS, Andriod, WM7, BB).
The information exchanged are highly sensitive, so the more secure, the better.
Thanks
",['rest']
41030778,Rest Webservice vs Web application?,"I have recently gone through rest web services(mainly spring). But I did not find much difference between  rest based web service and web application. 
In rest based web service, we have @RestControllerand in web application we have @Controller. The one difference  from dev perspective I know is in rest that we have more
verbs like PUT, DELETE etc. but in web app we mainly use POST/GET .  That is from receiver side. Even sender will just sends the http request for rest like sent in web application
Both maps the incoming url with method , mentions return format etc.
Yes there will be difference in authentication as in web application it will be form based authentication but web service it will be different like header based or something else.
So is there any major difference in protocol/sender/receiver or any perspective ?
",['rest']
45607999,Get Users role in xamarin.android,"I have made a xamarin.android app that uses login authentication with WebAPI and Azure, its working successfully.
Now I want to get the right of the user either he is admin or reader from my database.
Please guide me through.
Here is my login code.
 public HttpResponseMessage Xamarin_login(string username, string password) {
        var user = db.UserCredentials.Where(x => x.UName == username amp;amp; x.UIPassword == password).FirstOrDefault();

        if (user == null) {
            return Request.CreateResponse(HttpStatusCode.Unauthorized, Please Enter valid UserName and Password);
        } else { 
            return Request.CreateResponse(HttpStatusCode.Accepted, Success);
        }
}

",['rest']
23931093,How to protect the resources of a user in a REST API with FOSRestBundle and FOSOauthServerBundle?,"I'm developing a RESTful web service in Symfony2 with FOSRest and FOSOauthServer bundles (... and many others). My problem is that with an access token of other user, the api gives response instead of a 403 status code. For example
I have two users stored on database
userA with tokenA
userB with tokenB
Example Request
<URL>
Current Response
{
   products {
    0 { ... } 
    1 { ... }
  }
}

But I'm requesting products of user A with an access token of user B. How could I check if access token provided is of the products' owner??
My security.yml file
security
    encoders
        FOS\UserBundle\Model\UserInterface sha512

    role_hierarchy
        MY_ROLE
            # ...
        ROLE_ADMIN       ROLE_USER
        ROLE_SUPER_ADMIN [ROLE_USER, ROLE_SONATA_ADMIN, ROLE_ADMIN, ROLE_ALLOWED_TO_SWITCH]
        SONATA
            - ROLE_SONATA_PAGE_ADMIN_PAGE_EDIT
    providers
        fos_userbundle
            id fos_user.user_provider.username_email

    firewalls            
        admin
            pattern            /admin(.*)
            context            user
            form_login
                provider       fos_userbundle
                csrf_provider  form.csrf_provider
                login_path     /admin/login
                use_forward    false
                check_path     /admin/login_check
                failure_path   null
            logout 
                path           /admin/logout
            anonymous          true                

        # FOSOAuthBundle and FOSRestBundle    
        oauth_token
            pattern    ^/oauth/v2/token
            security   false

#        oauth_authorize commented because there are not oauth login form on this app
#            pattern    ^/oauth/v2/auth
            # Add your favorite authentication process here

        api
            pattern    ^/api
            fos_oauth  true
            stateless  true
            anonymous  false

        # This firewall is used to handle the public login area
        # This part is handled by the FOS User Bundle
        main
            # ...

    access_control
        # ...

        # API (FOSRestBundle and FOSOAuthBundle)
        - { path ^/api, roles [IS_AUTHENTICATED_FULLY] }

My routing.yml on ApiBundle
# API Endpoints
app_api_user_get_products
    pattern /{username}/products
    defaults { _controller ApiBundleUsergetProducts, _format json }
    methods GET

My UserController.php
get('offset');
//        $offset = null == $offset ? 0  $offset;
//        $limit = $paramFetcher->get('limit');

        try {
            // estructure and exclude fields strategy <URL>
            $data = array('products' => array());
            foreach ($user->getCatalog() as $p) {
                if ($p->getAvailable() == true) {
                    $product = $p->getProduct();
                    $data['products'][] = array(
                        'id' => $product->getId(),
                        'reference' => $product->getReference(),
                        'brand' => $product->getBrand(),
                        'description' => $product->getDescription(),
                        // ...
                    );
                }
            }
        } catch (\Exception $e) {
            throw new HttpException(CodesHTTP_INTERNAL_SERVER_ERROR, $e->getTraceAsString());
        }

        // New view
        $view = new View($data);
        $view->setFormat('json');

        return $this->handleView($view);
    }
}

Thank you very much for the help!
",['rest']
41484495,How exatly works JWT token security management using REST API?,"I am studying RESTfull API management and I am finding some difficult to understand how exactly the security is handled by the API KEY concept.
So from what I have understand studying on some tutorial I have the following situation
The user that want to use my API have to register and, after the registration, he obtain his personal API KEY (that is something like to a long random string).
So this secret is stored in the database with its secret, so after the user registration I will have something like this into a database table (correct me if I am doing wrong assertion because I am absolutly not sure about it)
|    USER    |         API_KEY         |    API_SECRET   |
|    user1   | dfdsf3dsfsdg35gsgg4fdgd | SECRET1         |
|    user2   | vbgggh3bfdgdf2gfdgd5vbb | SECRET2         |
|    user3   | gfgdfgd57bfgdfg9dgfd2vg | SECRET3         |

Where the USER column contains the registerd user.
The API_KEY contains the obtained api key that have to be inserted into the application devloped by this user.
The API_SECRET what exactly is? From what I have understand is something that is automatically generated when the API KEY is generated, or is something like a password specified by the user during the registration prcess? This point is pretty obscure for me. What exactly is it?

Now let consider how a client perform an autorization on the API server.
It send a JWT (JSON WEB TOKEN), that could be something like XXXXX.YYYYY.ZZZZZ
It is divided in 3 differend section
1) YYYYY HEADER.  BASE64 ENCODED. CONTIENE METADATA.
Something like
{
    type  JWT,
    alg  HMAC
}

It will be encoded in base64 and so it is generated the XXXXX section.
2) YYYYY PAYLOAD that contains the claims, something like this
{
    exp  2828288,              // REGISTERED
    iss myApiProvided.com,   // REGISTERED
    name Andrea              // PUBLIC
}

It will be encoded in base64 and so it is generated the YYYYY section.
3) ZZZZZ SIGNATURE It is created in the following way

Create a string by the concatenation of the previous XXXXX + . + YYYYY (both are base64 encoded).
Then is generating the  hashing of the previous signature using the SECRET. So from what I have understand basically in this way I have an encrypted version of the signature. Is it correct?

And here I have my secondo doubt from what I have understand this hashing have to be generate by the client that send the token attacched to the request. So is this hashing made at client side? If yes it means that the client know the SECRET but it seems me strange.
How exactly works? 
",['rest']